{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=0,1\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yu/tensorflow-py3.6/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import glob\n",
    "import itertools\n",
    "import lmdb\n",
    "import h5py\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "###%matplotlib inline\n",
    "\n",
    "from nilearn import signal,image,masking\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import cross_val_score, train_test_split,ShuffleSplit\n",
    "from keras.utils import np_utils\n",
    "\n",
    "import lmdb\n",
    "import tensorflow as tf\n",
    "from tensorpack import dataflow\n",
    "from tensorpack.utils.serialize import dumps, loads\n",
    "\n",
    "try:\n",
    "    # import cnn_graph\n",
    "    from cnn_graph.lib import models, graph, coarsening, utils\n",
    "except ImportError:\n",
    "    print('Could not find the package of graph-cnn ...')\n",
    "    print('Please check the location where cnn_graph is !\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['body0b_wm' 'body2b_wm' 'face0b_wm' 'face2b_wm' 'place0b_wm' 'place2b_wm'\n 'tool0b_wm' 'tool2b_wm']\nCollecting trial info from file: /home/yu/PycharmProjects/HCP_data/temp_res_new/WM_event_labels_1200R_LR_RL_new.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2148, 408) 2148 1079 2148\neach trial contains 39 volumes/TRs for task WM\nCollecting event design files for subjects and saved into matrix ...\n (2148, 408)\n"
     ]
    }
   ],
   "source": [
    "pathdata = '/home/yu/PycharmProjects/HCP_data/'\n",
    "pathout = pathdata + \"temp_res_new/\"\n",
    "\n",
    "modality = 'WM' #'MOTOR'\n",
    "###dict for different types of movement\n",
    "motor_task_con = {\"rf\": \"foot_mot\",\n",
    "                  \"lf\": \"foot_mot\",\n",
    "                  \"rh\": \"hand_mot\",\n",
    "                  \"lh\": \"hand_mot\",\n",
    "                  \"t\": \"tongue_mot\"}\n",
    "wm_task_con   =  {\"2bk_body\":   \"body2b_wm\",\n",
    "                  \"2bk_faces\":  \"face2b_wm\",\n",
    "                  \"2bk_places\": \"place2b_wm\",\n",
    "                  \"2bk_tools\":  \"tool2b_wm\",\n",
    "                  \"0bk_body\":   \"body0b_wm\",\n",
    "                  \"0bk_faces\":  \"face0b_wm\",\n",
    "                  \"0bk_places\": \"place0b_wm\",\n",
    "                  \"0bk_tools\":  \"tool0b_wm\"}\n",
    "\n",
    "task_contrasts = wm_task_con #motor_task_con\n",
    "target_name = np.unique(pd.Series(list(task_contrasts.values())))\n",
    "#target_name = np.unique(pd.Series(list(task_contrasts.values())).str.split('_',expand = True)[0])\n",
    "print(target_name)\n",
    "\n",
    "mmp_atlas = pathdata + \"HCP_S1200_GroupAvg_v1/\"+\"Q1-Q6_RelatedValidation210.CorticalAreas_dil_Final_Final_Areas_Group_Colors.32k_fs_LR.dlabel.nii\"\n",
    "AtlasName = 'MMP'\n",
    "block_dura = 1\n",
    "TR = 0.72\n",
    "\n",
    "##############################################\n",
    "#####start collecting data for classification algorithm\n",
    "EVS_files = []\n",
    "pathfmri = Path(pathdata + 'aws_s3_HCP1200/FMRI/')\n",
    "for ev in pathfmri.glob('tfMRI_' + modality + '_??/*combined_events_spm_' + modality + '.csv'):\n",
    "   EVS_files.append(str(ev))\n",
    "\n",
    "ev_filename = \"_event_labels_1200R_LR_RL_new.txt\"\n",
    "events_all_subjects_file = pathout+modality+ev_filename\n",
    "if os.path.isfile(events_all_subjects_file):\n",
    "    trial_infos = pd.read_csv(EVS_files[0],sep=\"\\t\",encoding=\"utf8\",header = None,names=['onset','duration','rep','task'])\n",
    "    Duras = np.ceil((trial_infos.duration/TR)).astype(int) #(trial_infos.duration/TR).astype(int)\n",
    "\n",
    "    print('Collecting trial info from file:', events_all_subjects_file)\n",
    "    subjects_trial_labels = pd.read_csv(events_all_subjects_file,sep=\"\\t\",encoding=\"utf8\")\n",
    "    ###print(subjects_trial_labels.keys())\n",
    "\n",
    "    subjects_trial_label_matrix = subjects_trial_labels.values.tolist()\n",
    "    trialID = subjects_trial_labels['trialID']\n",
    "    sub_name = subjects_trial_labels['subject'].tolist()\n",
    "    coding_direct = subjects_trial_labels['coding']\n",
    "    print(np.array(subjects_trial_label_matrix).shape,len(sub_name),len(np.unique(sub_name)),len(coding_direct))\n",
    "\n",
    "Trial_dura = np.unique(Duras)[0]\n",
    "\n",
    "print('each trial contains %d volumes/TRs for task %s' % (Trial_dura,modality))\n",
    "print('Collecting event design files for subjects and saved into matrix ...\\n' , np.array(subjects_trial_label_matrix).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data from file: /home/yu/PycharmProjects/HCP_data/temp_res_new/WM_MMP_ROI_act_1200R_test_Dec2018_ALL.lmdb\nSearch each key for every fmri file...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2149,)\n(405, 360)\n"
     ]
    }
   ],
   "source": [
    "from tensorpack.utils.serialize import dumps, loads\n",
    "import lmdb\n",
    "lmdb_filename = pathout+modality+\"_MMP_ROI_act_1200R_test_Dec2018_ALL.lmdb\"\n",
    "\n",
    "## read lmdb matrix\n",
    "print('loading data from file: %s' % lmdb_filename)\n",
    "matrix_dict = []\n",
    "fmri_sub_name = []\n",
    "lmdb_env = lmdb.open(lmdb_filename, subdir=False)\n",
    "try:\n",
    "    lmdb_txn = lmdb_env.begin()\n",
    "    listed_fmri_files = loads(lmdb_txn.get(b'__keys__'))\n",
    "    listed_fmri_files = [l.decode(\"utf-8\") for l in listed_fmri_files]\n",
    "    print('Stored fmri data from files:')\n",
    "    print(len(listed_fmri_files))\n",
    "except:\n",
    "    print('Search each key for every fmri file...')\n",
    "\n",
    "with lmdb_env.begin() as lmdb_txn:\n",
    "    cursor = lmdb_txn.cursor()\n",
    "    for key, value in cursor:\n",
    "        #print(key)\n",
    "        if key == b'__keys__':\n",
    "            continue\n",
    "        pathsub = Path(os.path.dirname(key.decode(\"utf-8\")))\n",
    "        if any('REST' in string for string in lmdb_filename.split('_')):\n",
    "            fmri_sub_name.append(pathsub.parts[-3] + '_' + pathsub.parts[-1].split('_')[-2][-1] + '_' + pathsub.parts[-1].split('_')[-1])\n",
    "        else:\n",
    "            #fmri_sub_name.append(pathsub.parts[-3] + '_' + pathsub.parts[-1].split('_')[-1])\n",
    "            subname_info = os.path.basename(key.decode(\"utf-8\")).split('_')\n",
    "            fmri_sub_name.append('_'.join((subname_info[0],subname_info[2],subname_info[3])))\n",
    "        data = loads(lmdb_txn.get(key)).astype('float32', casting='same_kind')\n",
    "        if any('REST' in string for string in lmdb_filename.split('_')):\n",
    "            if data is None or data.shape[0] != Trial_Num:\n",
    "                print('fmri data shape mis-matching between subjects...')\n",
    "                print('Check subject:  %s with only %d Trials \\n' % (fmri_sub_name[-1], data.shape[0]))\n",
    "                del fmri_sub_name[-1]\n",
    "            else:\n",
    "                matrix_dict.append(np.array(data))\n",
    "        else:\n",
    "            matrix_dict.append(np.array(data))\n",
    "lmdb_env.close()\n",
    "\n",
    "subjects_tc_matrix = matrix_dict\n",
    "subname_coding = fmri_sub_name\n",
    "print(np.array(subjects_tc_matrix).shape)\n",
    "print(subjects_tc_matrix[0].shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-clean the fmri and event data to make sure the matching shapes between two arrays!\nWarning: Mis-matching subjects list between fmri-data-matrix and trial-label-matrix\n(2149,) (2148, 408)\nEvent files and fmri data are miss-matching for subject: \n197348 : 196952\nDue to missing event files for subject : 196952_WM_LR\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done matching data shapes: (2148, 405, 360) (2148, 405)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2148, 405)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2148, 405, 360)\n['body0b_wm' 'body2b_wm' 'face0b_wm' 'face2b_wm' 'place0b_wm' 'place2b_wm'\n 'rest' 'tool0b_wm' 'tool2b_wm']\n"
     ]
    }
   ],
   "source": [
    "def preclean_data_for_shape_match(subjects_tc_matrix,subjects_trial_label_matrix, fmri_sub_name, ev_sub_name):\n",
    "    print(\"Pre-clean the fmri and event data to make sure the matching shapes between two arrays!\")\n",
    "    Subject_Num = np.array(subjects_tc_matrix).shape[0]\n",
    "    Trial_Num, Region_Num = subjects_tc_matrix[0].shape\n",
    "    if len(fmri_sub_name) != len(ev_sub_name):\n",
    "        print('Warning: Mis-matching subjects list between fmri-data-matrix and trial-label-matrix')\n",
    "        print(np.array(subjects_tc_matrix).shape,np.array(subjects_trial_label_matrix).shape)\n",
    "        subj = 0\n",
    "        if len(fmri_sub_name) > len(ev_sub_name):\n",
    "            for ev,subcount in zip(ev_sub_name, range(Subject_Num)):\n",
    "                ###remove fmri files if the event design is missing\n",
    "                while fmri_sub_name[subj].split('_')[0] < str(ev):\n",
    "                    print(\"Event files and fmri data are miss-matching for subject: \")\n",
    "                    print(ev, ':', fmri_sub_name[subj].split('_')[0])\n",
    "                    print(\"Due to missing event files for subject : %s\" % fmri_sub_name[subj])\n",
    "                    del fmri_sub_name[subj]\n",
    "                    del subjects_tc_matrix[subj]\n",
    "                    subj += 1\n",
    "                else:\n",
    "                    if subj > Subject_Num:\n",
    "                        ev_sub_name.remove(ev)\n",
    "                        del subjects_trial_label_matrix[subcount]\n",
    "                    if fmri_sub_name[subj].split('_')[0] == str(ev): subj += 1\n",
    "            subjects_trial_label_matrix[subj:] = []\n",
    "            ev_sub_name[subj:] = []\n",
    "\n",
    "        elif len(fmri_sub_name) < len(ev_sub_name):\n",
    "            for fmri_file,subcount in zip(fmri_sub_name, range(len(ev_sub_name))):\n",
    "                ###remove fmri files if the event design is missing\n",
    "                while str(ev_sub_name[subj]) < fmri_file.split('_')[0]:\n",
    "                    print(\"Event files and fmri data are miss-matching for subject: \")\n",
    "                    print(ev_sub_name[subj], ':', fmri_file.split('_')[0])\n",
    "                    print(\"Due to missing fmri data for subject : %s\" % str(ev_sub_name[subj]))\n",
    "                    del ev_sub_name[subj]\n",
    "                    del subjects_trial_label_matrix[subj]\n",
    "                    subj += 1\n",
    "                else:\n",
    "                    if subj > len(ev_sub_name):\n",
    "                        fmri_sub_name.remove(fmri_file)\n",
    "                        del subjects_tc_matrix[subcount]\n",
    "                        subj = 0\n",
    "                    if str(ev_sub_name[subj]) == fmri_file.split('_')[0]: subj += 1\n",
    "            subjects_tc_matrix[subj:] = []\n",
    "            fmri_sub_name[subj:] = []\n",
    "\n",
    "    for subj in range(min(len(fmri_sub_name),len(ev_sub_name))):\n",
    "        try:\n",
    "            tsize, rsize = np.array(subjects_tc_matrix[subj]).shape\n",
    "            tsize2 = len(subjects_trial_label_matrix[subj])\n",
    "        except:\n",
    "            print(subj==Subject_Num-1)\n",
    "            print('The end of SubjectList...\\n')\n",
    "        if tsize != Trial_Num or tsize2 != Trial_Num:\n",
    "            if tsize2 > Trial_Num:\n",
    "                ##print('Cut event data for subject %s from %d to fit event label matrix' % (fmri_sub_name[subj],tsize2))\n",
    "                subjects_trial_label_matrix[subj][Trial_Num:] = [] \n",
    "            else:\n",
    "                print('Remove subject: %s due to different trial num: %d in the fmri data' % (fmri_sub_name[subj],tsize))\n",
    "                del subjects_tc_matrix[subj]\n",
    "                del subjects_trial_label_matrix[subj]\n",
    "            \n",
    "        if rsize != Region_Num:\n",
    "            print('Remove subject: %s due to different region num: %d in the fmri data' % (fmri_sub_name[subj],rsize))\n",
    "            del subjects_tc_matrix[subj]\n",
    "            del subjects_trial_label_matrix[subj]\n",
    "\n",
    "    print('Done matching data shapes:',np.array(subjects_tc_matrix).shape,np.array(subjects_trial_label_matrix).shape)\n",
    "    return subjects_tc_matrix, subjects_trial_label_matrix\n",
    "\n",
    "subjects_tc_matrix_new, subjects_trial_label_matrix_new = \\\n",
    "    preclean_data_for_shape_match(subjects_tc_matrix,subjects_trial_label_matrix,subname_coding, sub_name)\n",
    "Subject_Num = np.array(subjects_tc_matrix_new).shape[0]\n",
    "print(np.array(subjects_trial_label_matrix_new).shape)\n",
    "print(np.array(subjects_tc_matrix_new).shape)\n",
    "print(np.unique(subjects_trial_label_matrix_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(312, 2148, 360) (312, 2148)\n",
      "Samples of Subjects for training: 1546 and testing 430 and validating 172 with 8 classes\n",
      "sample size for training and testing:  (536016, 360) (536016,)\n"
     ]
    }
   ],
   "source": [
    "def subject_cross_validation_split_trials(tc_matrix, label_matrix,target_name, sub_num=None, block_dura=18, n_folds=10, testsize=0.2, valsize=0.1,randomseed=1234):\n",
    "    ##randomseed=1234;testsize = 0.2;n_folds=10;valsize=0.1\n",
    "    from sklearn import preprocessing\n",
    "    from sklearn.model_selection import cross_val_score, train_test_split,ShuffleSplit\n",
    "    \n",
    "    Subject_Num, Trial_Num, Region_Num = np.array(tc_matrix).shape\n",
    "    rs = np.random.RandomState(randomseed)\n",
    "    if not sub_num or sub_num>Subject_Num:\n",
    "        sub_num = Subject_Num\n",
    "    if not block_dura:\n",
    "        block_dura = 18 ###12s block for MOTOR task\n",
    "\n",
    "    fmri_data_matrix = []\n",
    "    label_data_matrix = []\n",
    "    for subi in range(Subject_Num):\n",
    "        label_trial_data = np.array(label_matrix[subi])\n",
    "        condition_mask = pd.Series(label_trial_data).isin(target_name)\n",
    "        ##condition_mask = pd.Series(label_trial_data).str.split('_', expand=True)[0].isin(target_name)\n",
    "        fmri_data_matrix.append(tc_matrix[subi][condition_mask, :])\n",
    "        label_data_matrix.append(label_trial_data[condition_mask])\n",
    "    fmri_data_matrix = np.array(fmri_data_matrix).astype('float32', casting='same_kind')\n",
    "    label_data_matrix = np.array(label_data_matrix)\n",
    "    ##cut the trials into blocks\n",
    "    chunks = int(np.floor(label_data_matrix.shape[-1] / block_dura))\n",
    "    fmri_data_block = np.array(np.array_split(fmri_data_matrix, chunks, axis=1)).mean(axis=2).astype('float32',casting='same_kind')\n",
    "    label_data_block = np.array(np.array_split(label_data_matrix, chunks, axis=1))[:, :, 0]\n",
    "    print(fmri_data_block.shape,label_data_block.shape)\n",
    "\n",
    "    train_sid_tmp, test_sid = train_test_split(range(sub_num), test_size=testsize, random_state=rs, shuffle=True)\n",
    "    fmri_data_train = np.array([fmri_data_block[:, i, :] for i in train_sid_tmp]).astype('float32', casting='same_kind')\n",
    "    fmri_data_test = np.array([fmri_data_block[:, i, :] for i in test_sid]).astype('float32', casting='same_kind')\n",
    "    # print(fmri_data_train.shape,fmri_data_test.shape)\n",
    "\n",
    "    label_data_train = np.array([label_data_block[:, i] for i in train_sid_tmp])\n",
    "    label_data_test = np.array([label_data_block[:, i] for i in test_sid])\n",
    "    # print(label_data_train.shape,label_data_test.shape)\n",
    "\n",
    "    ###transform the data\n",
    "    scaler = preprocessing.StandardScaler().fit(np.vstack(fmri_data_train))\n",
    "    ##fmri_data_train = scaler.transform(fmri_data_train)\n",
    "    X_test = scaler.transform(np.vstack(fmri_data_test))\n",
    "    nb_class = len(np.unique(label_data_block))\n",
    "    Y_test = label_data_test.ravel()\n",
    "    # print(X_test.shape,Y_test.shape)\n",
    "\n",
    "    from sklearn.model_selection import ShuffleSplit\n",
    "    valsplit = ShuffleSplit(n_splits=n_folds, test_size=valsize, random_state=rs)\n",
    "    X_train_scaled = []\n",
    "    X_val_scaled = []\n",
    "    Y_train_scaled = []\n",
    "    Y_val_scaled = []\n",
    "    for train_sid, val_sid in valsplit.split(train_sid_tmp):\n",
    "        ##preprocess features and labels\n",
    "        X = np.array(np.vstack([fmri_data_train[i, :, :] for i in train_sid]))\n",
    "        Y = np.array([label_data_train[i, :] for i in train_sid]).ravel()\n",
    "        # print(X.shape, Y.shape)\n",
    "        X_train_scaled.append(scaler.transform(X))\n",
    "        Y_train_scaled.append(Y)\n",
    "\n",
    "        X = np.array(np.vstack([fmri_data_train[i, :, :] for i in val_sid]))\n",
    "        Y = np.array([label_data_train[i, :] for i in val_sid]).ravel()\n",
    "        # print(X.shape, Y.shape)\n",
    "        X_val_scaled.append(scaler.transform(X))\n",
    "        Y_val_scaled.append(Y)\n",
    "\n",
    "    print('Samples of Subjects for training: %d and testing %d and validating %d with %d classes' % (\n",
    "    len(train_sid), len(test_sid), len(val_sid), nb_class))\n",
    "    return X_train_scaled, Y_train_scaled, X_val_scaled, Y_val_scaled, X_test, Y_test\n",
    "\n",
    "    \n",
    "##########################################\n",
    "Subject_Num, Trial_Num, Region_Num = np.array(subjects_tc_matrix_new).shape\n",
    "if Trial_Num != np.array(subjects_trial_label_matrix_new).shape[1]:\n",
    "    print('Miss-matching trial infos for event and fmri data')\n",
    "if Subject_Num != np.array(subjects_trial_label_matrix_new).shape[0]:\n",
    "    print('Adjust subject numbers for event data')\n",
    "    subjects_trial_label_matrix = np.array(subjects_trial_label_matrix_new[:Subject_Num])\n",
    "else:\n",
    "    subjects_trial_label_matrix = np.array(subjects_trial_label_matrix_new)\n",
    "\n",
    "    \n",
    "block_dura = 1\n",
    "##split data into train, val and test in subject-level\n",
    "X_train, Y_train, X_val, Y_val, X_test, Y_test = \\\n",
    "subject_cross_validation_split_trials(subjects_tc_matrix_new, subjects_trial_label_matrix,target_name,block_dura=block_dura)\n",
    "\n",
    "from sklearn import preprocessing\n",
    "X_train_all = np.array(np.vstack((X_train[0], X_val[0])))\n",
    "Y_train_all = np.array(np.concatenate((Y_train[0], Y_val[0]), axis=0))\n",
    "print('sample size for training and testing: ', X_train_all.shape, Y_train_all.shape)\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(np.unique(Y_train_all))\n",
    "Y_train_int = le.transform(Y_train_all)\n",
    "Y_test_int = le.transform(Y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "each trial contains 39 volumes/TRs for task WM\nfirst cut: (8, 39, 360) (8, 39)\nsecond cut: (8, 360) (8,)\nfinalize: reshape data into size: (8, 360) (8,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2148, 8, 360) (2148, 8)\nfmri data for train and test: (80, 8, 360) (20, 8, 360)\nlabel data for train and test (80, 8) (20, 8)\nSamples of Subjects for training: 72 and testing 20 and validating 8 with 8 classes\nsample size for training and testing:  (640, 360) (640,)\n"
     ]
    }
   ],
   "source": [
    "def subject_cross_validation_split_trials_new(tc_matrix, label_matrix,target_name, sub_num=None, block_dura=18, n_folds=10, testsize=0.2, valsize=0.1,randomseed=1234):\n",
    "    ##randomseed=1234;testsize = 0.2;n_folds=10;valsize=0.1\n",
    "    from sklearn import preprocessing\n",
    "    from sklearn.model_selection import cross_val_score, train_test_split,ShuffleSplit\n",
    "        \n",
    "    Subject_Num, Trial_Num, Region_Num = np.array(tc_matrix).shape\n",
    "    rs = np.random.RandomState(randomseed)\n",
    "    if not sub_num or sub_num>Subject_Num:\n",
    "        sub_num = Subject_Num\n",
    "    if not block_dura:\n",
    "        block_dura = 18 ###12s block for MOTOR task\n",
    "        \n",
    "    global Trial_dura\n",
    "    print('each trial contains %d volumes/TRs for task %s' % (Trial_dura,modality))\n",
    "    \n",
    "    fmri_data_matrix = []\n",
    "    label_data_matrix = []\n",
    "    for subi in range(Subject_Num):\n",
    "        label_trial_data = np.array(label_matrix[subi])\n",
    "        condition_mask = pd.Series(label_trial_data).isin(target_name)\n",
    "        ##condition_mask = pd.Series(label_trial_data).str.split('_', expand=True)[0].isin(target_name)\n",
    "        \n",
    "        tc_matrix_select = np.array(tc_matrix[subi][condition_mask, :])\n",
    "        label_data_select = np.array(label_trial_data[condition_mask])\n",
    "        ##print(tc_matrix_select.shape,label_data_select.shape)\n",
    "        \n",
    "        \n",
    "        le = preprocessing.LabelEncoder()\n",
    "        le.fit(target_name)\n",
    "        label_data_int = le.transform(label_data_select)\n",
    "        \n",
    "        ##cut the trials\n",
    "        chunks = int(np.floor(len(label_data_select)/Trial_dura))\n",
    "        label_data_trial_block = np.array(np.split(label_data_select, np.where(np.diff(label_data_int))[0]+1))\n",
    "        if label_data_trial_block.shape[0] != chunks:\n",
    "            print(\"Wrong cutting of event data...\")\n",
    "            print(\"Should have %d block-trials but only found %d cuts\" % (chunks,label_data_trial_block.shape[0]))   \n",
    "        label_data_trial_block = np.array([label_data_trial_block[i][:Trial_dura] for i in range(chunks)]) \n",
    "    \n",
    "        fmri_data_block = np.array_split(tc_matrix_select,np.where(np.diff(label_data_int))[0]+1,axis=0)\n",
    "        fmri_data_block = np.array([fmri_data_block[i][:Trial_dura,:] for i in range(chunks)])\n",
    "        if subi==1: print('first cut:',fmri_data_block.shape,label_data_trial_block.shape)\n",
    "        \n",
    "        ##cut each trial to blocks\n",
    "        chunks = int(np.ceil(Trial_dura / block_dura))\n",
    "        if Trial_dura % block_dura:\n",
    "            fmri_data_block = np.array(np.vstack(np.array_split(fmri_data_block, chunks, axis=1)[:-1])).mean(axis=1).astype('float32',casting='same_kind')\n",
    "            label_data_trial_block = np.array(np.vstack(np.array_split(label_data_trial_block, chunks, axis=1)[:-1]))[:,0]\n",
    "        else:\n",
    "            fmri_data_block = np.array(np.vstack(np.array_split(fmri_data_block, chunks, axis=1))).mean(axis=1).astype('float32',casting='same_kind')\n",
    "            label_data_trial_block = np.array(np.vstack(np.array_split(label_data_trial_block, chunks, axis=1)))[:,0]\n",
    "        if subi==1: print('second cut:',fmri_data_block.shape,label_data_trial_block.shape)    \n",
    "        ##label_data_test = le.transform(label_data_trial_block[:,0]).flatten()\n",
    "        if subi==1: print('finalize: reshape data into size:',fmri_data_block.shape,label_data_trial_block.shape)\n",
    "       \n",
    "        fmri_data_matrix.append(fmri_data_block)\n",
    "        label_data_matrix.append(label_data_trial_block)\n",
    "    fmri_data_matrix = np.array(fmri_data_matrix).astype('float32', casting='same_kind')\n",
    "    label_data_matrix = np.array(label_data_matrix)\n",
    "    print(fmri_data_matrix.shape,label_data_matrix.shape)\n",
    "    \n",
    "    \n",
    "    ########spliting into train,val and testing\n",
    "    train_sid_tmp, test_sid = train_test_split(range(sub_num), test_size=testsize, random_state=rs, shuffle=True)\n",
    "    fmri_data_train = np.array([fmri_data_matrix[i] for i in train_sid_tmp]).astype('float32', casting='same_kind')\n",
    "    fmri_data_test = np.array([fmri_data_matrix[i] for i in test_sid]).astype('float32', casting='same_kind')\n",
    "    print('fmri data for train and test:',fmri_data_train.shape,fmri_data_test.shape)\n",
    "    \n",
    "    label_data_train = np.array([label_data_matrix[i] for i in train_sid_tmp])\n",
    "    label_data_test = np.array([label_data_matrix[i] for i in test_sid])\n",
    "    print('label data for train and test',label_data_train.shape,label_data_test.shape)\n",
    "    \n",
    "    ###transform the data\n",
    "    \n",
    "    scaler = preprocessing.StandardScaler().fit(np.vstack(fmri_data_train))\n",
    "    ##fmri_data_train = scaler.transform(fmri_data_train)\n",
    "    X_test = scaler.transform(np.vstack(fmri_data_test))\n",
    "    nb_class = len(target_name)\n",
    "    Y_test = label_data_test.ravel()\n",
    "    ##print(X_test.shape,Y_test.shape)\n",
    "    \n",
    "    from sklearn.model_selection import ShuffleSplit\n",
    "    valsplit = ShuffleSplit(n_splits=n_folds, test_size=valsize, random_state=rs)\n",
    "    X_train_scaled = []\n",
    "    X_val_scaled = []\n",
    "    Y_train_scaled = []\n",
    "    Y_val_scaled = []\n",
    "    for train_sid, val_sid in valsplit.split(train_sid_tmp):\n",
    "        ##preprocess features and labels\n",
    "        X = np.array(np.vstack([fmri_data_train[i] for i in train_sid]))\n",
    "        Y = np.array([label_data_train[i] for i in train_sid]).ravel()\n",
    "        #print('fmri and label data for training:',X.shape, Y.shape)\n",
    "        X_train_scaled.append(scaler.transform(X))\n",
    "        Y_train_scaled.append(Y)\n",
    "    \n",
    "        X = np.array(np.vstack([fmri_data_train[i] for i in val_sid]))\n",
    "        Y = np.array([label_data_train[i] for i in val_sid]).ravel()\n",
    "        #print('fmri and label data for validation:',X.shape, Y.shape)\n",
    "        X_val_scaled.append(scaler.transform(X))\n",
    "        Y_val_scaled.append(Y)\n",
    "    \n",
    "    print('Samples of Subjects for training: %d and testing %d and validating %d with %d classes' % (len(train_sid), len(test_sid), len(val_sid), nb_class))\n",
    "    return X_train_scaled, Y_train_scaled, X_val_scaled, Y_val_scaled, X_test, Y_test\n",
    "\n",
    "    \n",
    "##########################################\n",
    "Subject_Num, Trial_Num, Region_Num = np.array(subjects_tc_matrix_new).shape\n",
    "if Trial_Num != np.array(subjects_trial_label_matrix_new).shape[1]:\n",
    "    print('Miss-matching trial infos for event and fmri data')\n",
    "if Subject_Num != np.array(subjects_trial_label_matrix_new).shape[0]:\n",
    "    print('Adjust subject numbers for event data')\n",
    "    subjects_trial_label_matrix = np.array(subjects_trial_label_matrix_new[:Subject_Num])\n",
    "else:\n",
    "    subjects_trial_label_matrix = np.array(subjects_trial_label_matrix_new)\n",
    "\n",
    "    \n",
    "block_dura = 39\n",
    "Trial_dura = 39\n",
    "##split data into train, val and test in subject-level\n",
    "X_train, Y_train, X_val, Y_val, X_test, Y_test = \\\n",
    "subject_cross_validation_split_trials_new(subjects_tc_matrix_new, subjects_trial_label_matrix,target_name,sub_num=100,block_dura=block_dura)\n",
    "\n",
    "from sklearn import preprocessing\n",
    "X_train_all = np.array(np.vstack((X_train[0], X_val[0])))\n",
    "Y_train_all = np.array(np.concatenate((Y_train[0], Y_val[0]), axis=0))\n",
    "print('sample size for training and testing: ', X_train_all.shape, Y_train_all.shape)\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(np.unique(Y_train_all))\n",
    "Y_train_int = le.transform(Y_train_all)\n",
    "Y_test_int = le.transform(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "each trial contains 39 volumes/TRs for task WM\nfirst cut: (8, 39, 360) (8, 39)\nsecond cut: (104, 3, 360) (104,)\nfinalize: reshape data into size: (104, 3, 360) (104,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2148, 104, 3, 360) (2148, 104)\nfmri data for train and test: (80, 104, 1080) (20, 104, 1080)\nlabel data for train and test (80, 104) (20, 104)\n(2080, 1080) (2080,)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-2b9a2bd63ea5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;31m#print(list(X_test.shape[:-1])+list(fmri_data_block.shape[1:]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfmri_data_block\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m \u001b[0mX_train_scaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_scaled\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_scaled\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfmri_data_block\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0mX_val_scaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val_scaled\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val_scaled\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfmri_data_block\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_scaled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val_scaled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "tc_matrix = subjects_tc_matrix_new\n",
    "label_matrix = subjects_trial_label_matrix\n",
    "sub_num = 100\n",
    "block_dura = 3\n",
    "randomseed=1234;testsize = 0.2;n_folds=10;valsize=0.1\n",
    "\n",
    "Subject_Num, Trial_Num, Region_Num = np.array(tc_matrix).shape\n",
    "rs = np.random.RandomState(randomseed)\n",
    "if not sub_num or sub_num>Subject_Num:\n",
    "    sub_num = Subject_Num\n",
    "if not block_dura:\n",
    "    block_dura = 18 ###12s block for MOTOR task\n",
    "print('each trial contains %d volumes/TRs for task %s' % (Trial_dura,modality))\n",
    "\n",
    "fmri_data_matrix = []\n",
    "label_data_matrix = []\n",
    "for subi in range(Subject_Num):\n",
    "    label_trial_data = np.array(label_matrix[subi])\n",
    "    condition_mask = pd.Series(label_trial_data).isin(target_name)\n",
    "    ##condition_mask = pd.Series(label_trial_data).str.split('_', expand=True)[0].isin(target_name)\n",
    "    \n",
    "    tc_matrix_select = np.array(tc_matrix[subi][condition_mask, :])\n",
    "    label_data_select = np.array(label_trial_data[condition_mask])\n",
    "    ##print(tc_matrix_select.shape,label_data_select.shape)\n",
    "    \n",
    "    \n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(target_name)\n",
    "    label_data_int = le.transform(label_data_select)\n",
    "    \n",
    "    ##cut the trials\n",
    "    chunks = int(np.floor(len(label_data_select)/Trial_dura))\n",
    "    label_data_trial_block = np.array(np.split(label_data_select, np.where(np.diff(label_data_int))[0]+1))\n",
    "    if label_data_trial_block.shape[0] != chunks:\n",
    "        print(\"Wrong cutting of event data...\")\n",
    "        print(\"Should have %d block-trials but only found %d cuts\" % (chunks,label_data_trial_block.shape[0]))   \n",
    "    label_data_trial_block = np.array([label_data_trial_block[i][:Trial_dura] for i in range(chunks)]) \n",
    "\n",
    "    fmri_data_block = np.array_split(tc_matrix_select,np.where(np.diff(label_data_int))[0]+1,axis=0)\n",
    "    fmri_data_block = np.array([fmri_data_block[i][:Trial_dura,:] for i in range(chunks)])\n",
    "    if subi==1: print('first cut:',fmri_data_block.shape,label_data_trial_block.shape)\n",
    "    \n",
    "    ##cut each trial to blocks\n",
    "    chunks = int(np.ceil(Trial_dura / block_dura))\n",
    "    if Trial_dura % block_dura:\n",
    "        fmri_data_block = np.array(np.vstack(np.array_split(fmri_data_block, chunks, axis=1)[:-1])).astype('float32',casting='same_kind')\n",
    "        label_data_trial_block = np.array(np.vstack(np.array_split(label_data_trial_block, chunks, axis=1)[:-1]))[:,0]\n",
    "    else:\n",
    "        fmri_data_block = np.array(np.vstack(np.array_split(fmri_data_block, chunks, axis=1))).astype('float32',casting='same_kind')\n",
    "        label_data_trial_block = np.array(np.vstack(np.array_split(label_data_trial_block, chunks, axis=1)))[:,0]\n",
    "    if subi==1: print('second cut:',fmri_data_block.shape,label_data_trial_block.shape)    \n",
    "    ##label_data_test = le.transform(label_data_trial_block[:,0]).flatten()\n",
    "    if subi==1: print('finalize: reshape data into size:',fmri_data_block.shape,label_data_trial_block.shape)\n",
    "   \n",
    "    fmri_data_matrix.append(fmri_data_block)\n",
    "    label_data_matrix.append(label_data_trial_block)\n",
    "fmri_data_matrix = np.array(fmri_data_matrix).astype('float32', casting='same_kind')\n",
    "label_data_matrix = np.array(label_data_matrix)\n",
    "print(fmri_data_matrix.shape,label_data_matrix.shape)\n",
    "\n",
    "\n",
    "########spliting into train,val and testing\n",
    "fmri_data_matrix = fmri_data_matrix.reshape((Subject_Num,fmri_data_block.shape[0],np.prod(fmri_data_block.shape[1:])))\n",
    "train_sid_tmp, test_sid = train_test_split(range(sub_num), test_size=testsize, random_state=rs, shuffle=True)\n",
    "fmri_data_train = np.array([fmri_data_matrix[i] for i in train_sid_tmp]).astype('float32', casting='same_kind')\n",
    "fmri_data_test = np.array([fmri_data_matrix[i] for i in test_sid]).astype('float32', casting='same_kind')\n",
    "print('fmri data for train and test:',fmri_data_train.shape,fmri_data_test.shape)\n",
    "\n",
    "label_data_train = np.array([label_data_matrix[i] for i in train_sid_tmp])\n",
    "label_data_test = np.array([label_data_matrix[i] for i in test_sid])\n",
    "print('label data for train and test',label_data_train.shape,label_data_test.shape)\n",
    "\n",
    "###transform the data\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(np.vstack(fmri_data_train))\n",
    "##fmri_data_train = scaler.transform(fmri_data_train)\n",
    "X_test = scaler.transform(np.vstack(fmri_data_test))\n",
    "nb_class = len(target_name)\n",
    "Y_test = label_data_test.ravel()\n",
    "print(X_test.shape,Y_test.shape)\n",
    "\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "valsplit = ShuffleSplit(n_splits=n_folds, test_size=valsize, random_state=rs)\n",
    "X_train_scaled = []\n",
    "X_val_scaled = []\n",
    "Y_train_scaled = []\n",
    "Y_val_scaled = []\n",
    "for train_sid, val_sid in valsplit.split(train_sid_tmp):\n",
    "    ##preprocess features and labels\n",
    "    X = np.array(np.vstack([fmri_data_train[i] for i in train_sid]))\n",
    "    Y = np.array([label_data_train[i] for i in train_sid]).ravel()\n",
    "    #print('fmri and label data for training:',X.shape, Y.shape)\n",
    "    X_train_scaled.append(scaler.transform(X))\n",
    "    Y_train_scaled.append(Y)\n",
    "\n",
    "    X = np.array(np.vstack([fmri_data_train[i] for i in val_sid]))\n",
    "    Y = np.array([label_data_train[i] for i in val_sid]).ravel()\n",
    "    #print('fmri and label data for validation:',X.shape, Y.shape)\n",
    "    X_val_scaled.append(scaler.transform(X))\n",
    "    Y_val_scaled.append(Y)\n",
    "\n",
    "#print(list(X_test.shape[:-1])+list(fmri_data_block.shape[1:]))\n",
    "X_test = X_test.reshape(list(X_test.shape[:-1])+list(fmri_data_block.shape[1:]))\n",
    "X_train_scaled = np.reshape(X_train_scaled,list(X_train_scaled.shape[:-1])+list(fmri_data_block.shape[1:]))\n",
    "X_val_scaled = np.reshape(X_val_scaled,list(X_val_scaled.shape[:-1])+list(fmri_data_block.shape[1:]))\n",
    "print(X_test.shape,np.array(X_train_scaled).shape,np.array(X_val_scaled).shape)\n",
    "print('Samples of Subjects for training: %d and testing %d and validating %d with %d classes' % (len(train_sid), len(test_sid), len(val_sid), nb_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###build the graph\n",
    "###using rsfc\n",
    "adj_mat_file = pathdata + 'temp_res/REST_MMP_rsfc_matrix_1200R_ALL.h5'\n",
    "print(adj_mat_file)\n",
    "adj_mat = nib.load(adj_mat_file).get_data()\n",
    "print(adj_mat.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import tensorflow as tf\n",
    "flags = tf.app.flags\n",
    "FLAGS = flags.FLAGS\n",
    "\n",
    "# Graphs.\n",
    "flags.DEFINE_integer('number_edges', 8, 'Graph: minimum number of edges per vertex.')\n",
    "flags.DEFINE_string('metric', 'euclidean', 'Graph: similarity measure (between features).')\n",
    "# TODO: change cgcnn for combinatorial Laplacians.\n",
    "flags.DEFINE_bool('normalized_laplacian', True, 'Graph Laplacian: normalized.')\n",
    "flags.DEFINE_integer('coarsening_levels', 6, 'Number of coarsened graphs.')\n",
    "\n",
    "# Directories.\n",
    "flags.DEFINE_string('dir_data', os.path.join(pathout, 'data', modality), 'Directory to store data.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pixdim[1,2,3] should be non-zero; setting 0 dims to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(360, 360)\nLayer 0: M_0 = |V| = 640 nodes (280 added),|E| = 1053 edges\nLayer 1: M_1 = |V| = 320 nodes (124 added),|E| = 565 edges\nLayer 2: M_2 = |V| = 160 nodes (55 added),|E| = 295 edges\nLayer 3: M_3 = |V| = 80 nodes (22 added),|E| = 157 edges\nLayer 4: M_4 = |V| = 40 nodes (7 added),|E| = 86 edges\nLayer 5: M_5 = |V| = 20 nodes (2 added),|E| = 42 edges\nLayer 6: M_6 = |V| = 10 nodes (0 added),|E| = 18 edges\nLayer 0: M_0 = |V| = 512 nodes (152 added),|E| = 1053 edges\nLayer 1: M_1 = |V| = 256 nodes (61 added),|E| = 561 edges\nLayer 2: M_2 = |V| = 128 nodes (24 added),|E| = 291 edges\nLayer 3: M_3 = |V| = 64 nodes (8 added),|E| = 150 edges\nLayer 4: M_4 = |V| = 32 nodes (1 added),|E| = 79 edges\nLayer 5: M_5 = |V| = 16 nodes (0 added),|E| = 36 edges\nLayer 6: M_6 = |V| = 8 nodes (0 added),|E| = 14 edges\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb5d45d1358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb5d46f0fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb5d450fd30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb5c6860e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb5c69089b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb5d485cac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb5d44a5550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy import sparse\n",
    "noise_level = 0.001\n",
    "coarsening_levels = 6\n",
    "adjacent_mat_type = 'surface'\n",
    "adjacent_mat_file = pathout + 'MMP_adjacency_mat_white.pconn.nii'\n",
    "\n",
    "###loading adjcent matrix\n",
    "adj_mat = nib.load(adjacent_mat_file).get_data()\n",
    "adj_mat = sparse.csr_matrix(adj_mat)\n",
    "print(adj_mat.shape)\n",
    "A = graph.replace_random_edges(adj_mat, noise_level)\n",
    "###build multi-level graph using coarsen (div by 2 at each level)\n",
    "graphs, perm = coarsening.coarsen(A, levels=coarsening_levels, self_connections=False)\n",
    "L = [graph.laplacian(A, normalized=True) for A in graphs]\n",
    "# graph.plot_spectrum(L)\n",
    "\n",
    "###build multi-level graph using coarsen (div by 2 at each level)\n",
    "coarsening_levels = 6\n",
    "graphs, perm = coarsening.coarsen(A, levels=coarsening_levels, self_connections=False)\n",
    "L = [graph.laplacian(A, normalized=True) for A in graphs]\n",
    "graph.plot_spectrum(L)\n",
    "\n",
    "for li in range(coarsening_levels):\n",
    "    plt.figure()\n",
    "    plt.spy(graphs[li], markersize=2, color='black');\n",
    "    plt.title('level %d with %d nodes' % (li,graphs[li].shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import tensorflow as tf\n",
    "\n",
    "common = {}\n",
    "common['dir_name']       = modality\n",
    "common['num_epochs']     = 50 ###20\n",
    "common['batch_size']     = 128\n",
    "common['decay_steps']    = X_train[0].shape[0] / common['batch_size']\n",
    "common['eval_frequency'] = 30 * common['num_epochs']\n",
    "common['brelu']          = 'b1relu'\n",
    "common['pool']           = 'mpool1'\n",
    "C = len(np.unique(Y_test)) + 1  # number of classes\n",
    "\n",
    "\n",
    "model_perf = utils.model_perf()\n",
    "dir(model_perf)\n",
    "\n",
    "#print(model_perf.test_accuracy,model_perf.test_f1,model_perf.test_loss)\n",
    "#print(model_perf.train_accuracy,model_perf.train_f1,model_perf.train_loss)\n",
    "\n",
    "def show_gcn_results(s, fontsize=None):\n",
    "    if fontsize:\n",
    "        plt.rc('pdf', fonttype=42)\n",
    "        plt.rc('ps', fonttype=42)\n",
    "        plt.rc('font', size=fontsize)         # controls default text sizes\n",
    "        plt.rc('axes', titlesize=fontsize)    # fontsize of the axes title\n",
    "        plt.rc('axes', labelsize=fontsize)    # fontsize of the x any y labels\n",
    "        plt.rc('xtick', labelsize=fontsize)   # fontsize of the tick labels\n",
    "        plt.rc('ytick', labelsize=fontsize)   # fontsize of the tick labels\n",
    "        plt.rc('legend', fontsize=fontsize)   # legend fontsize\n",
    "        plt.rc('figure', titlesize=fontsize)  # size of the figure title\n",
    "    print('  accuracy        F1             loss        time [ms]  name')\n",
    "    print('test  train   test  train   test     train')\n",
    "    for name in sorted(s.names):\n",
    "        print('{:5.2f} {:5.2f}   {:5.2f} {:5.2f}   {:.2e} {:.2e}   {:3.0f}   {}'.format(\n",
    "                s.test_accuracy[name], s.train_accuracy[name],\n",
    "                s.test_f1[name], s.train_f1[name],\n",
    "                s.test_loss[name], s.train_loss[name], s.fit_time[name]*1000, name))\n",
    "    '''\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    for name in sorted(s.names):\n",
    "        steps = np.arange(len(s.fit_accuracies[name])) + 1\n",
    "        steps *= s.params[name]['eval_frequency']\n",
    "        ax[0].plot(steps, s.fit_accuracies[name], '.-', label=name)\n",
    "        ax[1].plot(steps, s.fit_losses[name], '.-', label=name)\n",
    "    ax[0].set_xlim(min(steps), max(steps))\n",
    "    ax[1].set_xlim(min(steps), max(steps))\n",
    "    ax[0].set_xlabel('step')\n",
    "    ax[1].set_xlabel('step')\n",
    "    ax[0].set_ylabel('validation accuracy')\n",
    "    ax[1].set_ylabel('training loss')\n",
    "    ax[0].legend(loc='lower right')\n",
    "    ax[1].legend(loc='upper right')\n",
    "    #fig.savefig('training.pdf')\n",
    "    '''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN architecture\n  input: M_0 = 512\n  layer 1: logits (softmax)\n    representation: M_1 = 9\n    weights: M_0 * M_1 = 512 * 9 = 4608\n    biases: M_1 = 9\n<cnn_graph.lib.models.cgcnn object at 0x7fb5c669d6a0>\n['body0b_wm' 'body2b_wm' 'face0b_wm' 'face2b_wm' 'place0b_wm' 'place2b_wm'\n 'tool0b_wm' 'tool2b_wm']\n(576, 360) (64, 360)\n(576, 512) (576, 360) (576, 360)\n\nFold #1: training on 576 samples with 512 features, validating on 64 samples and testing on 160 samples\nNN architecture\n  input: M_0 = 512\n  layer 1: logits (softmax)\n    representation: M_1 = 9\n    weights: M_0 * M_1 = 512 * 9 = 4608\n    biases: M_1 = 9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 225 / 225 (epoch 50.00 / 50):\n  learning_rate = 1.62e-03, loss_average = 1.05e-01\n  validation accuracy: 89.06 (57 / 64), f1 (weighted): 89.04, loss: 2.90e+00\n  time: 0s (wall 0s)\nvalidation accuracy: peak = 89.06, mean = 89.06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 225 / 225 (epoch 50.00 / 50):\n  learning_rate = 1.62e-03, loss_average = 1.05e-01\n  validation accuracy: 89.06 (57 / 64), f1 (weighted): 89.00, loss: 2.96e+00\n  time: 0s (wall 0s)\nvalidation accuracy: peak = 89.06, mean = 89.06\nINFO:tensorflow:Restoring parameters from /home/yu/PycharmProjects/HCP_fmripredict/cnn_graph/lib/../checkpoints/WMsoftmax/model-225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 99.48 (573 / 576), f1 (weighted): 99.48, loss: 3.80e-01\ntime: 0s (wall 0s)\nINFO:tensorflow:Restoring parameters from /home/yu/PycharmProjects/HCP_fmripredict/cnn_graph/lib/../checkpoints/WMsoftmax/model-225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test  accuracy: 82.50 (132 / 160), f1 (weighted): 82.14, loss: 2.13e+00\ntime: 0s (wall 0s)\n\n\n(576, 360) (64, 360)\n(576, 512) (576, 360) (576, 360)\n\nFold #2: training on 576 samples with 512 features, validating on 64 samples and testing on 160 samples\nNN architecture\n  input: M_0 = 512\n  layer 1: logits (softmax)\n    representation: M_1 = 9\n    weights: M_0 * M_1 = 512 * 9 = 4608\n    biases: M_1 = 9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 225 / 225 (epoch 50.00 / 50):\n  learning_rate = 1.62e-03, loss_average = 1.09e-01\n  validation accuracy: 84.38 (54 / 64), f1 (weighted): 84.15, loss: 2.91e+00\n  time: 0s (wall 0s)\nvalidation accuracy: peak = 84.38, mean = 84.38\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 225 / 225 (epoch 50.00 / 50):\n  learning_rate = 1.62e-03, loss_average = 1.06e-01\n  validation accuracy: 84.38 (54 / 64), f1 (weighted): 83.42, loss: 2.88e+00\n  time: 0s (wall 0s)\nvalidation accuracy: peak = 84.38, mean = 84.38\nINFO:tensorflow:Restoring parameters from /home/yu/PycharmProjects/HCP_fmripredict/cnn_graph/lib/../checkpoints/WMsoftmax/model-225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 99.65 (574 / 576), f1 (weighted): 99.65, loss: 3.81e-01\ntime: 0s (wall 0s)\nINFO:tensorflow:Restoring parameters from /home/yu/PycharmProjects/HCP_fmripredict/cnn_graph/lib/../checkpoints/WMsoftmax/model-225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test  accuracy: 81.88 (131 / 160), f1 (weighted): 81.57, loss: 2.09e+00\ntime: 0s (wall 0s)\n\n\nAccuracy of training:99.56597222222223,testing:82.1875\nAccuracy of validation: [89.0625 84.375 ]\n mean=86.718750\n  accuracy        F1             loss        time [ms]  name\ntest  train   test  train   test     train\n81.88 99.65   81.57 99.65   2.09e+00 3.81e-01     1   softmax\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n###training figures\\nprint(accuracy, loss,t_step )\\nfig, ax1 = plt.subplots(figsize=(10, 5))\\nax1.plot(np.mean(accuracy,axis=0), 'b.-')\\nax1.set_ylabel('validation accuracy', color='b')\\nax2 = ax1.twinx()\\nax2.plot(np.mean(loss,axis=0), 'g.-')\\nax2.set_ylabel('training loss', color='g')\\nplt.show()\\n\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###test different param settins\n",
    "##model1: no convolution\n",
    "name = 'softmax'\n",
    "params = common.copy()\n",
    "params['dir_name'] += name\n",
    "params['regularization'] = 5e-4\n",
    "params['dropout']        = 1\n",
    "params['learning_rate']  = 0.02\n",
    "params['decay_rate']     = 0.95\n",
    "params['momentum']       = 0.9\n",
    "params['F']              = []\n",
    "params['K']              = []\n",
    "params['p']              = []\n",
    "params['M']              = [C]\n",
    "model = models.cgcnn(L, **params)\n",
    "print(model)\n",
    "\n",
    "d = {k: v+1 for v, k in enumerate(sorted(set(Y_test)))}\n",
    "test_labels = np.array([d[x] for x in Y_test])\n",
    "print(np.unique(Y_test))\n",
    "\n",
    "train_acc = []; train_loss = [];\n",
    "test_acc = []; test_loss = [];\n",
    "val_acc = []; val_loss = [];\n",
    "accuracy = []; loss = []; t_step = [];\n",
    "for x_train, y_train, x_val, y_val,tcount in zip(X_train, Y_train, X_val, Y_val,range(2)):\n",
    "    x_train = x_train.repeat()\n",
    "    train_data = coarsening.perm_data(x_train.reshape(-1,Region_Num), perm)\n",
    "    print(train_data.shape, x_train.shape, x_train.reshape(-1,Region_Num).shape)\n",
    "    train_labels = np.array([d[x] for x in y_train])\n",
    "    val_data = coarsening.perm_data(x_val.reshape(-1,Region_Num), perm)\n",
    "    val_labels = np.array([d[x] for x in y_val])\n",
    "    test_data = coarsening.perm_data(X_test.reshape(-1,Region_Num), perm)\n",
    "    print('\\nFold #%d: training on %d samples with %d features, validating on %d samples and testing on %d samples' % \n",
    "          (tcount+1,train_data.shape[0],train_data.shape[1],val_data.shape[0],test_data.shape[0]))  \n",
    "    \n",
    "    ###training\n",
    "    model = models.cgcnn(L, **params)\n",
    "    acc, los, tstep = model.fit(train_data, train_labels, val_data, val_labels)\n",
    "    accuracy.append(acc)\n",
    "    loss.append(los)\n",
    "    t_step.append(tstep)\n",
    "\n",
    "    ##evaluation\n",
    "    model_perf.test(model, name, params,\n",
    "                    train_data, train_labels, val_data, val_labels, test_data, test_labels)\n",
    "    train_acc.append(model_perf.train_accuracy[name])\n",
    "    train_loss.append(model_perf.train_loss[name])\n",
    "    test_acc.append(model_perf.test_accuracy[name])\n",
    "    test_loss.append(model_perf.test_loss[name])\n",
    "    val_acc.append(model_perf.fit_accuracies[name])\n",
    "    val_loss.append(model_perf.fit_losses[name])\n",
    "    print('\\n')\n",
    "       \n",
    "print('Accuracy of training:{},testing:{}'.format(np.mean(train_acc),np.mean(test_acc)))\n",
    "print('Accuracy of validation:',np.max(val_acc,axis=1))\n",
    "print(' mean=%2f' % np.mean(np.max(val_acc,axis=1)))\n",
    "\n",
    "show_gcn_results(model_perf,fontsize=50)\n",
    "'''\n",
    "###training figures\n",
    "print(accuracy, loss,t_step )\n",
    "fig, ax1 = plt.subplots(figsize=(10, 5))\n",
    "ax1.plot(np.mean(accuracy,axis=0), 'b.-')\n",
    "ax1.set_ylabel('validation accuracy', color='b')\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(np.mean(loss,axis=0), 'g.-')\n",
    "ax2.set_ylabel('training loss', color='g')\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[512 128  32]\n[(512, 512), (256, 256), (128, 128), (64, 64), (32, 32), (16, 16), (8, 8)]\nNN architecture\n  input: M_0 = 512\n  layer 1: cgconv1\n    representation: M_0 * F_1 / p_1 = 512 * 32 / 4 = 4096\n    weights: F_0 * F_1 * K_1 = 1 * 32 * 512 = 16384\n    biases: F_1 = 32\n  layer 2: cgconv2\n    representation: M_1 * F_2 / p_2 = 128 * 64 / 4 = 2048\n    weights: F_1 * F_2 * K_2 = 32 * 64 * 128 = 262144\n    biases: F_2 = 64\n  layer 3: cgconv3\n    representation: M_2 * F_3 / p_3 = 32 * 128 / 4 = 1024\n    weights: F_2 * F_3 * K_3 = 64 * 128 * 32 = 262144\n    biases: F_3 = 128\n  layer 4: fc1\n    representation: M_4 = 256\n    weights: M_3 * M_4 = 1024 * 256 = 262144\n    biases: M_4 = 256\n  layer 5: logits (softmax)\n    representation: M_5 = 9\n    weights: M_4 * M_5 = 256 * 9 = 2304\n    biases: M_5 = 9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['body0b_wm' 'body2b_wm' 'face0b_wm' 'face2b_wm' 'place0b_wm' 'place2b_wm'\n 'tool0b_wm' 'tool2b_wm']\n\nFold #1: training on 576 samples with 512 features, validating on 64 samples and testing on 160 samples\nNN architecture\n  input: M_0 = 512\n  layer 1: cgconv1\n    representation: M_0 * F_1 / p_1 = 512 * 32 / 4 = 4096\n    weights: F_0 * F_1 * K_1 = 1 * 32 * 512 = 16384\n    biases: F_1 = 32\n  layer 2: cgconv2\n    representation: M_1 * F_2 / p_2 = 128 * 64 / 4 = 2048\n    weights: F_1 * F_2 * K_2 = 32 * 64 * 128 = 262144\n    biases: F_2 = 64\n  layer 3: cgconv3\n    representation: M_2 * F_3 / p_3 = 32 * 128 / 4 = 1024\n    weights: F_2 * F_3 * K_3 = 64 * 128 * 32 = 262144\n    biases: F_3 = 128\n  layer 4: fc1\n    representation: M_4 = 256\n    weights: M_3 * M_4 = 1024 * 256 = 262144\n    biases: M_4 = 256\n  layer 5: logits (softmax)\n    representation: M_5 = 9\n    weights: M_4 * M_5 = 256 * 9 = 2304\n    biases: M_5 = 9\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "cudnn PoolForward launch failed\n\t [[node conv1/pooling/MaxPool (defined at /home/yu/PycharmProjects/HCP_fmripredict/cnn_graph/lib/models.py:937)  = MaxPool[T=DT_FLOAT, data_format=\"NCHW\", ksize=[1, 1, 4, 1], padding=\"SAME\", strides=[1, 1, 4, 1], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](training/gradients/conv1/pooling/MaxPool_grad/MaxPoolGrad-0-TransposeNHWCToNCHW-LayoutOptimizer)]]\n\t [[{{node training/control/_23}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_479_training/control\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'conv1/pooling/MaxPool', defined at:\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/yu/tensorflow-py3.6/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/yu/tensorflow-py3.6/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/yu/tensorflow-py3.6/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/home/yu/tensorflow-py3.6/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/yu/tensorflow-py3.6/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/yu/tensorflow-py3.6/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/home/yu/tensorflow-py3.6/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/yu/tensorflow-py3.6/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/yu/tensorflow-py3.6/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/yu/tensorflow-py3.6/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/yu/tensorflow-py3.6/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/yu/tensorflow-py3.6/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/yu/tensorflow-py3.6/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/yu/tensorflow-py3.6/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/yu/tensorflow-py3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/yu/tensorflow-py3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/yu/tensorflow-py3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-10-a6ac1547b405>\", line 47, in <module>\n    model = models.cgcnn(L, **params)\n  File \"/home/yu/PycharmProjects/HCP_fmripredict/cnn_graph/lib/models.py\", line 812, in __init__\n    self.build_graph(M_0)\n  File \"/home/yu/PycharmProjects/HCP_fmripredict/cnn_graph/lib/models.py\", line 165, in build_graph\n    op_logits = self.inference(self.ph_data, self.ph_dropout)\n  File \"/home/yu/PycharmProjects/HCP_fmripredict/cnn_graph/lib/models.py\", line 194, in inference\n    logits = self._inference(data, dropout)\n  File \"/home/yu/PycharmProjects/HCP_fmripredict/cnn_graph/lib/models.py\", line 970, in _inference\n    x = self.pool(x, self.p[i])\n  File \"/home/yu/PycharmProjects/HCP_fmripredict/cnn_graph/lib/models.py\", line 937, in mpool1\n    x = tf.nn.max_pool(x, ksize=[1,p,1,1], strides=[1,p,1,1], padding='SAME')\n  File \"/home/yu/tensorflow-py3.6/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\", line 2140, in max_pool\n    name=name)\n  File \"/home/yu/tensorflow-py3.6/lib/python3.6/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 4641, in max_pool\n    data_format=data_format, name=name)\n  File \"/home/yu/tensorflow-py3.6/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/yu/tensorflow-py3.6/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"/home/yu/tensorflow-py3.6/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3274, in create_op\n    op_def=op_def)\n  File \"/home/yu/tensorflow-py3.6/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInternalError (see above for traceback): cudnn PoolForward launch failed\n\t [[node conv1/pooling/MaxPool (defined at /home/yu/PycharmProjects/HCP_fmripredict/cnn_graph/lib/models.py:937)  = MaxPool[T=DT_FLOAT, data_format=\"NCHW\", ksize=[1, 1, 4, 1], padding=\"SAME\", strides=[1, 1, 4, 1], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](training/gradients/conv1/pooling/MaxPool_grad/MaxPoolGrad-0-TransposeNHWCToNCHW-LayoutOptimizer)]]\n\t [[{{node training/control/_23}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_479_training/control\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m~/tensorflow-py3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow-py3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow-py3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: cudnn PoolForward launch failed\n\t [[{{node conv1/pooling/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NCHW\", ksize=[1, 1, 4, 1], padding=\"SAME\", strides=[1, 1, 4, 1], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](training/gradients/conv1/pooling/MaxPool_grad/MaxPoolGrad-0-TransposeNHWCToNCHW-LayoutOptimizer)]]\n\t [[{{node training/control/_23}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_479_training/control\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-a6ac1547b405>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;31m###training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcgcnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m     \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m     \u001b[0maccuracy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/HCP_fmripredict/cnn_graph/lib/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, train_data, train_labels, val_data, val_labels)\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0mbatch_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# convert sparse matrices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mph_data\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mph_labels\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mph_dropout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_average\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop_loss_average\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0;31m# Periodical evaluation of the model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow-py3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow-py3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow-py3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow-py3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1346\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: cudnn PoolForward launch failed\n\t [[node conv1/pooling/MaxPool (defined at /home/yu/PycharmProjects/HCP_fmripredict/cnn_graph/lib/models.py:937)  = MaxPool[T=DT_FLOAT, data_format=\"NCHW\", ksize=[1, 1, 4, 1], padding=\"SAME\", strides=[1, 1, 4, 1], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](training/gradients/conv1/pooling/MaxPool_grad/MaxPoolGrad-0-TransposeNHWCToNCHW-LayoutOptimizer)]]\n\t [[{{node training/control/_23}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_479_training/control\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'conv1/pooling/MaxPool', defined at:\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/yu/tensorflow-py3.6/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/yu/tensorflow-py3.6/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/yu/tensorflow-py3.6/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/home/yu/tensorflow-py3.6/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/yu/tensorflow-py3.6/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/yu/tensorflow-py3.6/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/home/yu/tensorflow-py3.6/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/yu/tensorflow-py3.6/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/yu/tensorflow-py3.6/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/yu/tensorflow-py3.6/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/yu/tensorflow-py3.6/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/yu/tensorflow-py3.6/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/yu/tensorflow-py3.6/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/yu/tensorflow-py3.6/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/yu/tensorflow-py3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/yu/tensorflow-py3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/yu/tensorflow-py3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-10-a6ac1547b405>\", line 47, in <module>\n    model = models.cgcnn(L, **params)\n  File \"/home/yu/PycharmProjects/HCP_fmripredict/cnn_graph/lib/models.py\", line 812, in __init__\n    self.build_graph(M_0)\n  File \"/home/yu/PycharmProjects/HCP_fmripredict/cnn_graph/lib/models.py\", line 165, in build_graph\n    op_logits = self.inference(self.ph_data, self.ph_dropout)\n  File \"/home/yu/PycharmProjects/HCP_fmripredict/cnn_graph/lib/models.py\", line 194, in inference\n    logits = self._inference(data, dropout)\n  File \"/home/yu/PycharmProjects/HCP_fmripredict/cnn_graph/lib/models.py\", line 970, in _inference\n    x = self.pool(x, self.p[i])\n  File \"/home/yu/PycharmProjects/HCP_fmripredict/cnn_graph/lib/models.py\", line 937, in mpool1\n    x = tf.nn.max_pool(x, ksize=[1,p,1,1], strides=[1,p,1,1], padding='SAME')\n  File \"/home/yu/tensorflow-py3.6/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\", line 2140, in max_pool\n    name=name)\n  File \"/home/yu/tensorflow-py3.6/lib/python3.6/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 4641, in max_pool\n    data_format=data_format, name=name)\n  File \"/home/yu/tensorflow-py3.6/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/yu/tensorflow-py3.6/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"/home/yu/tensorflow-py3.6/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3274, in create_op\n    op_def=op_def)\n  File \"/home/yu/tensorflow-py3.6/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInternalError (see above for traceback): cudnn PoolForward launch failed\n\t [[node conv1/pooling/MaxPool (defined at /home/yu/PycharmProjects/HCP_fmripredict/cnn_graph/lib/models.py:937)  = MaxPool[T=DT_FLOAT, data_format=\"NCHW\", ksize=[1, 1, 4, 1], padding=\"SAME\", strides=[1, 1, 4, 1], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](training/gradients/conv1/pooling/MaxPool_grad/MaxPoolGrad-0-TransposeNHWCToNCHW-LayoutOptimizer)]]\n\t [[{{node training/control/_23}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_479_training/control\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "# Common hyper-parameters for LeNet5-like networks (two convolutional layers).\n",
    "common['regularization'] = 5e-4\n",
    "common['dropout']        = 0.5\n",
    "common['learning_rate']  = 0.02  # 0.03 in the paper but sgconv_sgconv_fc_softmax has difficulty to converge\n",
    "common['decay_rate']     = 0.95\n",
    "common['momentum']       = 0.9\n",
    "common['F']              = [32, 64, 128]  # Number of graph convolutional filters.\n",
    "common['K']              = [25, 25, 25]  # Polynomial orders.\n",
    "common['p']              = [4, 4, 4]    # Pooling sizes.\n",
    "common['M']              = [256, C]  # Output dimensionality of fully connected layers.\n",
    "\n",
    "##model#1: two convolutional layers with fourier transform as filters\n",
    "name = 'fgconv_fgconv_fc_softmax' #  'Non-Param'\n",
    "params = common.copy()\n",
    "params['dir_name'] += name\n",
    "params['filter'] = 'fourier'\n",
    "params['K'] = np.zeros(len(common['p']), dtype=int)\n",
    "for pi,li in zip(common['p'],range(len(common['p']))):\n",
    "    if pi == 2: \n",
    "        params['K'][li] = L[li].shape[0]\n",
    "    if pi == 4:\n",
    "        params['K'][li] = L[li*2].shape[0]\n",
    "print(params['K'])    \n",
    "#params['K'] = [L[0].shape[0], L[2].shape[0]]\n",
    "print([L[li].shape for li in range(len(L))])\n",
    "model = models.cgcnn(L, **params)\n",
    "    \n",
    "d = {k: v+1 for v, k in enumerate(sorted(set(Y_test)))}\n",
    "test_labels = np.array([d[x] for x in Y_test])\n",
    "print(np.unique(Y_test))\n",
    "\n",
    "train_acc = []; train_loss = [];\n",
    "test_acc = []; test_loss = [];\n",
    "val_acc = []; val_loss = [];\n",
    "accuracy = []; loss = []; t_step = [];\n",
    "for x_train, y_train, x_val, y_val,tcount in zip(X_train, Y_train, X_val, Y_val,range(2)):\n",
    "    \n",
    "    train_data = coarsening.perm_data(x_train.reshape(-1,Region_Num), perm)\n",
    "    train_labels = np.array([d[x] for x in y_train])\n",
    "    val_data = coarsening.perm_data(x_val.reshape(-1,Region_Num), perm)\n",
    "    val_labels = np.array([d[x] for x in y_val])\n",
    "    test_data = coarsening.perm_data(X_test.reshape(-1,Region_Num), perm)\n",
    "    print('\\nFold #%d: training on %d samples with %d features, validating on %d samples and testing on %d samples' % \n",
    "          (tcount+1,train_data.shape[0],train_data.shape[1],val_data.shape[0],test_data.shape[0]))  \n",
    "    \n",
    "    ###training\n",
    "    model = models.cgcnn(L, **params)\n",
    "    acc, los, tstep = model.fit(train_data, train_labels, val_data, val_labels)\n",
    "    accuracy.append(acc)\n",
    "    loss.append(los)\n",
    "    t_step.append(tstep)\n",
    "\n",
    "    ##evaluation\n",
    "    model_perf.test(model, name, params,\n",
    "                    train_data, train_labels, val_data, val_labels, test_data, test_labels)\n",
    "    train_acc.append(model_perf.train_accuracy[name])\n",
    "    train_loss.append(model_perf.train_loss[name])\n",
    "    test_acc.append(model_perf.test_accuracy[name])\n",
    "    test_loss.append(model_perf.test_loss[name])\n",
    "    val_acc.append(model_perf.fit_accuracies[name])\n",
    "    val_loss.append(model_perf.fit_losses[name])\n",
    "    print('\\n')\n",
    "       \n",
    "print('Accuracy of training:{},testing:{}'.format(np.mean(train_acc),np.mean(test_acc)))\n",
    "print('Accuracy of validation:',np.max(val_acc,axis=1))\n",
    "print(' mean=%2f' % np.mean(np.max(val_acc,axis=1)))\n",
    "\n",
    "###training figures\n",
    "print(accuracy, loss,t_step )\n",
    "fig, ax1 = plt.subplots(figsize=(10, 5))\n",
    "ax1.plot(np.mean(accuracy,axis=0), 'b.-')\n",
    "ax1.set_ylabel('validation accuracy', color='b')\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(np.mean(loss,axis=0), 'g.-')\n",
    "ax2.set_ylabel('training loss', color='g')\n",
    "plt.show()\n",
    "\n",
    "###summarize the results\n",
    "#model_perf.show()\n",
    "show_gcn_results(model_perf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dir_name': 'WMsgconv_sgconv_fc_softmax', 'num_epochs': 50, 'batch_size': 128, 'decay_steps': 3768.375, 'eval_frequency': 1500, 'brelu': 'b1relu', 'pool': 'mpool1', 'regularization': 0.0005, 'dropout': 0.5, 'learning_rate': 0.02, 'decay_rate': 0.95, 'momentum': 0.9, 'F': [32, 64, 128], 'K': [25, 25, 25], 'p': [4, 4, 4], 'M': [256, 9], 'filter': 'spline'}\n",
      "[(576, 576), (288, 288), (144, 144), (72, 72), (36, 36), (18, 18), (9, 9)]\n",
      "NN architecture\n",
      "  input: M_0 = 576\n",
      "  layer 1: cgconv1\n",
      "    representation: M_0 * F_1 / p_1 = 576 * 32 / 4 = 4608\n",
      "    weights: F_0 * F_1 * K_1 = 1 * 32 * 25 = 800\n",
      "    biases: F_1 = 32\n",
      "  layer 2: cgconv2\n",
      "    representation: M_1 * F_2 / p_2 = 144 * 64 / 4 = 2304\n",
      "    weights: F_1 * F_2 * K_2 = 32 * 64 * 25 = 51200\n",
      "    biases: F_2 = 64\n",
      "  layer 3: cgconv3\n",
      "    representation: M_2 * F_3 / p_3 = 36 * 128 / 4 = 1152\n",
      "    weights: F_2 * F_3 * K_3 = 64 * 128 * 25 = 204800\n",
      "    biases: F_3 = 128\n",
      "  layer 4: fc1\n",
      "    representation: M_4 = 256\n",
      "    weights: M_3 * M_4 = 1152 * 256 = 294912\n",
      "    biases: M_4 = 256\n",
      "  layer 5: logits (softmax)\n",
      "    representation: M_5 = 9\n",
      "    weights: M_4 * M_5 = 256 * 9 = 2304\n",
      "    biases: M_5 = 9\n",
      "576 32 1\n",
      "144 64 32\n",
      "36 128 64\n",
      "['body0b_wm' 'body2b_wm' 'face0b_wm' 'face2b_wm' 'place0b_wm' 'place2b_wm'\n",
      " 'tool0b_wm' 'tool2b_wm']\n",
      "\n",
      "Fold #1: training on 482352 samples with 576 features, validating on 53664 samples and testing on 134160 samples\n",
      "NN architecture\n",
      "  input: M_0 = 576\n",
      "  layer 1: cgconv1\n",
      "    representation: M_0 * F_1 / p_1 = 576 * 32 / 4 = 4608\n",
      "    weights: F_0 * F_1 * K_1 = 1 * 32 * 25 = 800\n",
      "    biases: F_1 = 32\n",
      "  layer 2: cgconv2\n",
      "    representation: M_1 * F_2 / p_2 = 144 * 64 / 4 = 2304\n",
      "    weights: F_1 * F_2 * K_2 = 32 * 64 * 25 = 51200\n",
      "    biases: F_2 = 64\n",
      "  layer 3: cgconv3\n",
      "    representation: M_2 * F_3 / p_3 = 36 * 128 / 4 = 1152\n",
      "    weights: F_2 * F_3 * K_3 = 64 * 128 * 25 = 204800\n",
      "    biases: F_3 = 128\n",
      "  layer 4: fc1\n",
      "    representation: M_4 = 256\n",
      "    weights: M_3 * M_4 = 1152 * 256 = 294912\n",
      "    biases: M_4 = 256\n",
      "  layer 5: logits (softmax)\n",
      "    representation: M_5 = 9\n",
      "    weights: M_4 * M_5 = 256 * 9 = 2304\n",
      "    biases: M_5 = 9\n",
      "576 32 1\n",
      "144 64 32\n",
      "36 128 64\n",
      "step 1500 / 188418 (epoch 0.40 / 50):\n",
      "  learning_rate = 2.00e-02, loss_average = 2.40e+00\n",
      "  validation accuracy: 27.81 (14922 / 53664), f1 (weighted): 24.50, loss: 2.37e+00\n",
      "  time: 11s (wall 12s)\n",
      "step 3000 / 188418 (epoch 0.80 / 50):\n",
      "  learning_rate = 2.00e-02, loss_average = 1.95e+00\n",
      "  validation accuracy: 44.66 (23967 / 53664), f1 (weighted): 44.32, loss: 1.88e+00\n",
      "  time: 19s (wall 22s)\n",
      "step 4500 / 188418 (epoch 1.19 / 50):\n",
      "  learning_rate = 1.90e-02, loss_average = 1.76e+00\n",
      "  validation accuracy: 49.10 (26347 / 53664), f1 (weighted): 49.12, loss: 1.68e+00\n",
      "  time: 28s (wall 31s)\n",
      "step 6000 / 188418 (epoch 1.59 / 50):\n",
      "  learning_rate = 1.90e-02, loss_average = 1.57e+00\n",
      "  validation accuracy: 51.61 (27696 / 53664), f1 (weighted): 51.66, loss: 1.56e+00\n",
      "  time: 36s (wall 41s)\n",
      "step 7500 / 188418 (epoch 1.99 / 50):\n",
      "  learning_rate = 1.90e-02, loss_average = 1.49e+00\n",
      "  validation accuracy: 54.30 (29140 / 53664), f1 (weighted): 54.15, loss: 1.45e+00\n",
      "  time: 44s (wall 50s)\n",
      "step 9000 / 188418 (epoch 2.39 / 50):\n",
      "  learning_rate = 1.80e-02, loss_average = 1.35e+00\n",
      "  validation accuracy: 56.06 (30085 / 53664), f1 (weighted): 56.09, loss: 1.38e+00\n",
      "  time: 53s (wall 60s)\n",
      "step 10500 / 188418 (epoch 2.79 / 50):\n",
      "  learning_rate = 1.80e-02, loss_average = 1.34e+00\n",
      "  validation accuracy: 56.31 (30217 / 53664), f1 (weighted): 56.30, loss: 1.34e+00\n",
      "  time: 61s (wall 69s)\n",
      "step 12000 / 188418 (epoch 3.18 / 50):\n",
      "  learning_rate = 1.71e-02, loss_average = 1.26e+00\n",
      "  validation accuracy: 56.41 (30274 / 53664), f1 (weighted): 56.51, loss: 1.31e+00\n",
      "  time: 70s (wall 78s)\n",
      "step 13500 / 188418 (epoch 3.58 / 50):\n",
      "  learning_rate = 1.71e-02, loss_average = 1.25e+00\n",
      "  validation accuracy: 57.65 (30936 / 53664), f1 (weighted): 57.66, loss: 1.28e+00\n",
      "  time: 78s (wall 88s)\n",
      "step 15000 / 188418 (epoch 3.98 / 50):\n",
      "  learning_rate = 1.71e-02, loss_average = 1.24e+00\n",
      "  validation accuracy: 58.13 (31197 / 53664), f1 (weighted): 58.21, loss: 1.25e+00\n",
      "  time: 86s (wall 97s)\n",
      "step 16500 / 188418 (epoch 4.38 / 50):\n",
      "  learning_rate = 1.63e-02, loss_average = 1.21e+00\n",
      "  validation accuracy: 58.77 (31540 / 53664), f1 (weighted): 58.79, loss: 1.23e+00\n",
      "  time: 95s (wall 106s)\n",
      "step 18000 / 188418 (epoch 4.78 / 50):\n",
      "  learning_rate = 1.63e-02, loss_average = 1.21e+00\n",
      "  validation accuracy: 58.39 (31334 / 53664), f1 (weighted): 58.43, loss: 1.24e+00\n",
      "  time: 103s (wall 116s)\n",
      "step 19500 / 188418 (epoch 5.17 / 50):\n",
      "  learning_rate = 1.55e-02, loss_average = 1.14e+00\n",
      "  validation accuracy: 58.69 (31497 / 53664), f1 (weighted): 58.77, loss: 1.22e+00\n",
      "  time: 111s (wall 125s)\n",
      "step 21000 / 188418 (epoch 5.57 / 50):\n",
      "  learning_rate = 1.55e-02, loss_average = 1.12e+00\n",
      "  validation accuracy: 59.46 (31906 / 53664), f1 (weighted): 59.50, loss: 1.20e+00\n",
      "  time: 120s (wall 135s)\n",
      "step 22500 / 188418 (epoch 5.97 / 50):\n",
      "  learning_rate = 1.55e-02, loss_average = 1.14e+00\n",
      "  validation accuracy: 59.69 (32033 / 53664), f1 (weighted): 59.68, loss: 1.20e+00\n",
      "  time: 128s (wall 144s)\n",
      "step 24000 / 188418 (epoch 6.37 / 50):\n",
      "  learning_rate = 1.47e-02, loss_average = 1.10e+00\n",
      "  validation accuracy: 60.10 (32254 / 53664), f1 (weighted): 60.09, loss: 1.19e+00\n",
      "  time: 136s (wall 153s)\n",
      "step 25500 / 188418 (epoch 6.77 / 50):\n",
      "  learning_rate = 1.47e-02, loss_average = 1.15e+00\n",
      "  validation accuracy: 60.04 (32222 / 53664), f1 (weighted): 60.04, loss: 1.18e+00\n",
      "  time: 144s (wall 162s)\n",
      "step 27000 / 188418 (epoch 7.16 / 50):\n",
      "  learning_rate = 1.40e-02, loss_average = 1.09e+00\n",
      "  validation accuracy: 60.20 (32304 / 53664), f1 (weighted): 60.11, loss: 1.18e+00\n",
      "  time: 152s (wall 172s)\n",
      "step 28500 / 188418 (epoch 7.56 / 50):\n",
      "  learning_rate = 1.40e-02, loss_average = 1.06e+00\n",
      "  validation accuracy: 60.19 (32302 / 53664), f1 (weighted): 60.14, loss: 1.18e+00\n",
      "  time: 161s (wall 181s)\n",
      "step 30000 / 188418 (epoch 7.96 / 50):\n",
      "  learning_rate = 1.40e-02, loss_average = 1.10e+00\n",
      "  validation accuracy: 60.34 (32383 / 53664), f1 (weighted): 60.36, loss: 1.18e+00\n",
      "  time: 169s (wall 190s)\n",
      "step 31500 / 188418 (epoch 8.36 / 50):\n",
      "  learning_rate = 1.33e-02, loss_average = 1.10e+00\n",
      "  validation accuracy: 60.62 (32532 / 53664), f1 (weighted): 60.68, loss: 1.16e+00\n",
      "  time: 177s (wall 199s)\n",
      "step 33000 / 188418 (epoch 8.76 / 50):\n",
      "  learning_rate = 1.33e-02, loss_average = 1.09e+00\n",
      "  validation accuracy: 60.82 (32640 / 53664), f1 (weighted): 60.84, loss: 1.16e+00\n",
      "  time: 185s (wall 209s)\n",
      "step 34500 / 188418 (epoch 9.16 / 50):\n",
      "  learning_rate = 1.26e-02, loss_average = 1.05e+00\n",
      "  validation accuracy: 60.93 (32697 / 53664), f1 (weighted): 60.96, loss: 1.15e+00\n",
      "  time: 193s (wall 218s)\n",
      "step 36000 / 188418 (epoch 9.55 / 50):\n",
      "  learning_rate = 1.26e-02, loss_average = 1.09e+00\n",
      "  validation accuracy: 60.93 (32696 / 53664), f1 (weighted): 60.99, loss: 1.16e+00\n",
      "  time: 202s (wall 227s)\n",
      "step 37500 / 188418 (epoch 9.95 / 50):\n",
      "  learning_rate = 1.26e-02, loss_average = 1.04e+00\n",
      "  validation accuracy: 60.90 (32679 / 53664), f1 (weighted): 60.95, loss: 1.16e+00\n",
      "  time: 210s (wall 237s)\n",
      "step 39000 / 188418 (epoch 10.35 / 50):\n",
      "  learning_rate = 1.20e-02, loss_average = 1.01e+00\n",
      "  validation accuracy: 61.05 (32761 / 53664), f1 (weighted): 61.04, loss: 1.16e+00\n",
      "  time: 218s (wall 246s)\n",
      "step 40500 / 188418 (epoch 10.75 / 50):\n",
      "  learning_rate = 1.20e-02, loss_average = 1.04e+00\n",
      "  validation accuracy: 61.17 (32827 / 53664), f1 (weighted): 61.18, loss: 1.16e+00\n",
      "  time: 226s (wall 255s)\n",
      "step 42000 / 188418 (epoch 11.15 / 50):\n",
      "  learning_rate = 1.14e-02, loss_average = 1.02e+00\n",
      "  validation accuracy: 60.89 (32678 / 53664), f1 (weighted): 60.87, loss: 1.17e+00\n",
      "  time: 234s (wall 264s)\n",
      "step 43500 / 188418 (epoch 11.54 / 50):\n",
      "  learning_rate = 1.14e-02, loss_average = 1.06e+00\n",
      "  validation accuracy: 61.53 (33022 / 53664), f1 (weighted): 61.55, loss: 1.15e+00\n",
      "  time: 242s (wall 273s)\n",
      "step 45000 / 188418 (epoch 11.94 / 50):\n",
      "  learning_rate = 1.14e-02, loss_average = 1.05e+00\n",
      "  validation accuracy: 61.19 (32835 / 53664), f1 (weighted): 61.21, loss: 1.15e+00\n",
      "  time: 250s (wall 283s)\n",
      "step 46500 / 188418 (epoch 12.34 / 50):\n",
      "  learning_rate = 1.08e-02, loss_average = 9.90e-01\n",
      "  validation accuracy: 61.31 (32901 / 53664), f1 (weighted): 61.35, loss: 1.15e+00\n",
      "  time: 258s (wall 292s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 48000 / 188418 (epoch 12.74 / 50):\n",
      "  learning_rate = 1.08e-02, loss_average = 9.74e-01\n",
      "  validation accuracy: 61.38 (32937 / 53664), f1 (weighted): 61.32, loss: 1.15e+00\n",
      "  time: 267s (wall 301s)\n",
      "step 49500 / 188418 (epoch 13.14 / 50):\n",
      "  learning_rate = 1.03e-02, loss_average = 9.93e-01\n",
      "  validation accuracy: 61.26 (32873 / 53664), f1 (weighted): 61.27, loss: 1.15e+00\n",
      "  time: 275s (wall 310s)\n",
      "step 51000 / 188418 (epoch 13.53 / 50):\n",
      "  learning_rate = 1.03e-02, loss_average = 9.93e-01\n",
      "  validation accuracy: 61.42 (32961 / 53664), f1 (weighted): 61.46, loss: 1.15e+00\n",
      "  time: 283s (wall 320s)\n",
      "step 52500 / 188418 (epoch 13.93 / 50):\n",
      "  learning_rate = 1.03e-02, loss_average = 1.02e+00\n",
      "  validation accuracy: 61.47 (32989 / 53664), f1 (weighted): 61.39, loss: 1.15e+00\n",
      "  time: 291s (wall 329s)\n",
      "step 54000 / 188418 (epoch 14.33 / 50):\n",
      "  learning_rate = 9.75e-03, loss_average = 1.00e+00\n",
      "  validation accuracy: 61.57 (33043 / 53664), f1 (weighted): 61.56, loss: 1.15e+00\n",
      "  time: 299s (wall 338s)\n",
      "step 55500 / 188418 (epoch 14.73 / 50):\n",
      "  learning_rate = 9.75e-03, loss_average = 9.89e-01\n",
      "  validation accuracy: 61.68 (33098 / 53664), f1 (weighted): 61.75, loss: 1.15e+00\n",
      "  time: 307s (wall 348s)\n",
      "step 57000 / 188418 (epoch 15.13 / 50):\n",
      "  learning_rate = 9.27e-03, loss_average = 1.02e+00\n",
      "  validation accuracy: 61.64 (33077 / 53664), f1 (weighted): 61.58, loss: 1.14e+00\n",
      "  time: 316s (wall 357s)\n",
      "step 58500 / 188418 (epoch 15.52 / 50):\n",
      "  learning_rate = 9.27e-03, loss_average = 1.02e+00\n",
      "  validation accuracy: 61.75 (33135 / 53664), f1 (weighted): 61.77, loss: 1.14e+00\n",
      "  time: 324s (wall 366s)\n",
      "step 60000 / 188418 (epoch 15.92 / 50):\n",
      "  learning_rate = 9.27e-03, loss_average = 1.00e+00\n",
      "  validation accuracy: 61.68 (33101 / 53664), f1 (weighted): 61.68, loss: 1.15e+00\n",
      "  time: 332s (wall 375s)\n",
      "step 61500 / 188418 (epoch 16.32 / 50):\n",
      "  learning_rate = 8.80e-03, loss_average = 9.70e-01\n",
      "  validation accuracy: 61.72 (33124 / 53664), f1 (weighted): 61.72, loss: 1.15e+00\n",
      "  time: 340s (wall 385s)\n",
      "step 63000 / 188418 (epoch 16.72 / 50):\n",
      "  learning_rate = 8.80e-03, loss_average = 9.54e-01\n",
      "  validation accuracy: 61.54 (33027 / 53664), f1 (weighted): 61.56, loss: 1.15e+00\n",
      "  time: 348s (wall 394s)\n",
      "step 64500 / 188418 (epoch 17.12 / 50):\n",
      "  learning_rate = 8.36e-03, loss_average = 9.61e-01\n",
      "  validation accuracy: 61.91 (33221 / 53664), f1 (weighted): 61.92, loss: 1.15e+00\n",
      "  time: 357s (wall 403s)\n",
      "step 66000 / 188418 (epoch 17.51 / 50):\n",
      "  learning_rate = 8.36e-03, loss_average = 9.77e-01\n",
      "  validation accuracy: 62.04 (33294 / 53664), f1 (weighted): 62.01, loss: 1.14e+00\n",
      "  time: 365s (wall 412s)\n",
      "step 67500 / 188418 (epoch 17.91 / 50):\n",
      "  learning_rate = 8.36e-03, loss_average = 1.00e+00\n",
      "  validation accuracy: 61.82 (33176 / 53664), f1 (weighted): 61.83, loss: 1.14e+00\n",
      "  time: 373s (wall 422s)\n",
      "step 69000 / 188418 (epoch 18.31 / 50):\n",
      "  learning_rate = 7.94e-03, loss_average = 9.76e-01\n",
      "  validation accuracy: 61.81 (33171 / 53664), f1 (weighted): 61.80, loss: 1.14e+00\n",
      "  time: 381s (wall 431s)\n",
      "step 70500 / 188418 (epoch 18.71 / 50):\n",
      "  learning_rate = 7.94e-03, loss_average = 9.60e-01\n",
      "  validation accuracy: 61.88 (33207 / 53664), f1 (weighted): 61.89, loss: 1.14e+00\n",
      "  time: 389s (wall 440s)\n",
      "step 72000 / 188418 (epoch 19.11 / 50):\n",
      "  learning_rate = 7.55e-03, loss_average = 9.32e-01\n",
      "  validation accuracy: 61.94 (33237 / 53664), f1 (weighted): 61.97, loss: 1.15e+00\n",
      "  time: 397s (wall 449s)\n",
      "step 73500 / 188418 (epoch 19.50 / 50):\n",
      "  learning_rate = 7.55e-03, loss_average = 9.47e-01\n",
      "  validation accuracy: 61.72 (33124 / 53664), f1 (weighted): 61.64, loss: 1.15e+00\n",
      "  time: 406s (wall 459s)\n",
      "step 75000 / 188418 (epoch 19.90 / 50):\n",
      "  learning_rate = 7.55e-03, loss_average = 9.39e-01\n",
      "  validation accuracy: 62.02 (33281 / 53664), f1 (weighted): 62.04, loss: 1.15e+00\n",
      "  time: 414s (wall 468s)\n",
      "step 76500 / 188418 (epoch 20.30 / 50):\n",
      "  learning_rate = 7.17e-03, loss_average = 9.27e-01\n",
      "  validation accuracy: 62.20 (33381 / 53664), f1 (weighted): 62.18, loss: 1.15e+00\n",
      "  time: 422s (wall 477s)\n",
      "step 78000 / 188418 (epoch 20.70 / 50):\n",
      "  learning_rate = 7.17e-03, loss_average = 9.28e-01\n",
      "  validation accuracy: 61.95 (33244 / 53664), f1 (weighted): 61.95, loss: 1.14e+00\n",
      "  time: 430s (wall 487s)\n",
      "step 79500 / 188418 (epoch 21.10 / 50):\n",
      "  learning_rate = 6.81e-03, loss_average = 9.37e-01\n",
      "  validation accuracy: 62.01 (33279 / 53664), f1 (weighted): 62.01, loss: 1.15e+00\n",
      "  time: 438s (wall 496s)\n",
      "step 81000 / 188418 (epoch 21.49 / 50):\n",
      "  learning_rate = 6.81e-03, loss_average = 9.45e-01\n",
      "  validation accuracy: 62.00 (33273 / 53664), f1 (weighted): 62.00, loss: 1.15e+00\n",
      "  time: 446s (wall 505s)\n",
      "step 82500 / 188418 (epoch 21.89 / 50):\n",
      "  learning_rate = 6.81e-03, loss_average = 9.49e-01\n",
      "  validation accuracy: 61.80 (33164 / 53664), f1 (weighted): 61.86, loss: 1.15e+00\n",
      "  time: 455s (wall 514s)\n",
      "step 84000 / 188418 (epoch 22.29 / 50):\n",
      "  learning_rate = 6.47e-03, loss_average = 9.34e-01\n",
      "  validation accuracy: 61.86 (33199 / 53664), f1 (weighted): 61.88, loss: 1.15e+00\n",
      "  time: 463s (wall 524s)\n",
      "step 85500 / 188418 (epoch 22.69 / 50):\n",
      "  learning_rate = 6.47e-03, loss_average = 9.33e-01\n",
      "  validation accuracy: 62.11 (33332 / 53664), f1 (weighted): 62.09, loss: 1.15e+00\n",
      "  time: 471s (wall 533s)\n",
      "step 87000 / 188418 (epoch 23.09 / 50):\n",
      "  learning_rate = 6.15e-03, loss_average = 9.03e-01\n",
      "  validation accuracy: 62.10 (33324 / 53664), f1 (weighted): 62.12, loss: 1.15e+00\n",
      "  time: 479s (wall 542s)\n",
      "step 88500 / 188418 (epoch 23.48 / 50):\n",
      "  learning_rate = 6.15e-03, loss_average = 9.12e-01\n",
      "  validation accuracy: 62.21 (33383 / 53664), f1 (weighted): 62.22, loss: 1.14e+00\n",
      "  time: 487s (wall 551s)\n",
      "step 90000 / 188418 (epoch 23.88 / 50):\n",
      "  learning_rate = 6.15e-03, loss_average = 9.12e-01\n",
      "  validation accuracy: 62.08 (33312 / 53664), f1 (weighted): 62.04, loss: 1.15e+00\n",
      "  time: 495s (wall 561s)\n",
      "step 91500 / 188418 (epoch 24.28 / 50):\n",
      "  learning_rate = 5.84e-03, loss_average = 9.39e-01\n",
      "  validation accuracy: 62.00 (33274 / 53664), f1 (weighted): 62.02, loss: 1.15e+00\n",
      "  time: 504s (wall 570s)\n",
      "step 93000 / 188418 (epoch 24.68 / 50):\n",
      "  learning_rate = 5.84e-03, loss_average = 9.68e-01\n",
      "  validation accuracy: 62.04 (33292 / 53664), f1 (weighted): 62.05, loss: 1.15e+00\n",
      "  time: 512s (wall 579s)\n",
      "step 94500 / 188418 (epoch 25.08 / 50):\n",
      "  learning_rate = 5.55e-03, loss_average = 9.14e-01\n",
      "  validation accuracy: 62.14 (33349 / 53664), f1 (weighted): 62.14, loss: 1.14e+00\n",
      "  time: 520s (wall 588s)\n",
      "step 96000 / 188418 (epoch 25.48 / 50):\n",
      "  learning_rate = 5.55e-03, loss_average = 8.98e-01\n",
      "  validation accuracy: 62.04 (33291 / 53664), f1 (weighted): 62.03, loss: 1.15e+00\n",
      "  time: 528s (wall 598s)\n",
      "step 97500 / 188418 (epoch 25.87 / 50):\n",
      "  learning_rate = 5.55e-03, loss_average = 9.33e-01\n",
      "  validation accuracy: 62.16 (33356 / 53664), f1 (weighted): 62.19, loss: 1.15e+00\n",
      "  time: 536s (wall 607s)\n",
      "step 99000 / 188418 (epoch 26.27 / 50):\n",
      "  learning_rate = 5.27e-03, loss_average = 9.05e-01\n",
      "  validation accuracy: 62.08 (33313 / 53664), f1 (weighted): 62.09, loss: 1.16e+00\n",
      "  time: 545s (wall 616s)\n",
      "step 100500 / 188418 (epoch 26.67 / 50):\n",
      "  learning_rate = 5.27e-03, loss_average = 8.89e-01\n",
      "  validation accuracy: 62.24 (33400 / 53664), f1 (weighted): 62.24, loss: 1.15e+00\n",
      "  time: 553s (wall 626s)\n",
      "step 102000 / 188418 (epoch 27.07 / 50):\n",
      "  learning_rate = 5.01e-03, loss_average = 8.70e-01\n",
      "  validation accuracy: 62.23 (33393 / 53664), f1 (weighted): 62.26, loss: 1.16e+00\n",
      "  time: 561s (wall 635s)\n",
      "step 103500 / 188418 (epoch 27.47 / 50):\n",
      "  learning_rate = 5.01e-03, loss_average = 8.57e-01\n",
      "  validation accuracy: 61.88 (33206 / 53664), f1 (weighted): 61.93, loss: 1.16e+00\n",
      "  time: 569s (wall 644s)\n",
      "step 105000 / 188418 (epoch 27.86 / 50):\n",
      "  learning_rate = 5.01e-03, loss_average = 8.68e-01\n",
      "  validation accuracy: 61.85 (33190 / 53664), f1 (weighted): 61.89, loss: 1.16e+00\n",
      "  time: 577s (wall 653s)\n",
      "step 106500 / 188418 (epoch 28.26 / 50):\n",
      "  learning_rate = 4.76e-03, loss_average = 9.03e-01\n",
      "  validation accuracy: 61.87 (33202 / 53664), f1 (weighted): 61.89, loss: 1.16e+00\n",
      "  time: 586s (wall 663s)\n",
      "step 108000 / 188418 (epoch 28.66 / 50):\n",
      "  learning_rate = 4.76e-03, loss_average = 8.70e-01\n",
      "  validation accuracy: 62.11 (33332 / 53664), f1 (weighted): 62.11, loss: 1.16e+00\n",
      "  time: 594s (wall 672s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 109500 / 188418 (epoch 29.06 / 50):\n",
      "  learning_rate = 4.52e-03, loss_average = 8.39e-01\n",
      "  validation accuracy: 61.79 (33158 / 53664), f1 (weighted): 61.82, loss: 1.17e+00\n",
      "  time: 602s (wall 681s)\n",
      "step 111000 / 188418 (epoch 29.46 / 50):\n",
      "  learning_rate = 4.52e-03, loss_average = 8.94e-01\n",
      "  validation accuracy: 61.96 (33250 / 53664), f1 (weighted): 62.00, loss: 1.16e+00\n",
      "  time: 610s (wall 691s)\n",
      "step 112500 / 188418 (epoch 29.85 / 50):\n",
      "  learning_rate = 4.52e-03, loss_average = 8.48e-01\n",
      "  validation accuracy: 62.05 (33297 / 53664), f1 (weighted): 62.07, loss: 1.17e+00\n",
      "  time: 618s (wall 700s)\n",
      "step 114000 / 188418 (epoch 30.25 / 50):\n",
      "  learning_rate = 4.29e-03, loss_average = 9.05e-01\n",
      "  validation accuracy: 61.91 (33222 / 53664), f1 (weighted): 61.94, loss: 1.16e+00\n",
      "  time: 627s (wall 709s)\n",
      "step 115500 / 188418 (epoch 30.65 / 50):\n",
      "  learning_rate = 4.29e-03, loss_average = 8.81e-01\n",
      "  validation accuracy: 62.31 (33436 / 53664), f1 (weighted): 62.33, loss: 1.15e+00\n",
      "  time: 635s (wall 719s)\n",
      "step 117000 / 188418 (epoch 31.05 / 50):\n",
      "  learning_rate = 4.08e-03, loss_average = 8.33e-01\n",
      "  validation accuracy: 61.88 (33207 / 53664), f1 (weighted): 61.88, loss: 1.17e+00\n",
      "  time: 643s (wall 728s)\n",
      "step 118500 / 188418 (epoch 31.45 / 50):\n",
      "  learning_rate = 4.08e-03, loss_average = 8.63e-01\n",
      "  validation accuracy: 61.82 (33174 / 53664), f1 (weighted): 61.82, loss: 1.17e+00\n",
      "  time: 651s (wall 737s)\n",
      "step 120000 / 188418 (epoch 31.84 / 50):\n",
      "  learning_rate = 4.08e-03, loss_average = 8.59e-01\n",
      "  validation accuracy: 62.14 (33348 / 53664), f1 (weighted): 62.16, loss: 1.16e+00\n",
      "  time: 659s (wall 746s)\n",
      "step 121500 / 188418 (epoch 32.24 / 50):\n",
      "  learning_rate = 3.87e-03, loss_average = 9.02e-01\n",
      "  validation accuracy: 61.76 (33144 / 53664), f1 (weighted): 61.78, loss: 1.17e+00\n",
      "  time: 667s (wall 755s)\n",
      "step 123000 / 188418 (epoch 32.64 / 50):\n",
      "  learning_rate = 3.87e-03, loss_average = 8.94e-01\n",
      "  validation accuracy: 61.99 (33265 / 53664), f1 (weighted): 62.02, loss: 1.17e+00\n",
      "  time: 676s (wall 765s)\n",
      "step 124500 / 188418 (epoch 33.04 / 50):\n",
      "  learning_rate = 3.68e-03, loss_average = 8.39e-01\n",
      "  validation accuracy: 62.02 (33281 / 53664), f1 (weighted): 62.06, loss: 1.16e+00\n",
      "  time: 684s (wall 774s)\n",
      "step 126000 / 188418 (epoch 33.44 / 50):\n",
      "  learning_rate = 3.68e-03, loss_average = 8.62e-01\n",
      "  validation accuracy: 61.99 (33264 / 53664), f1 (weighted): 62.01, loss: 1.17e+00\n",
      "  time: 692s (wall 783s)\n",
      "step 127500 / 188418 (epoch 33.83 / 50):\n",
      "  learning_rate = 3.68e-03, loss_average = 8.63e-01\n",
      "  validation accuracy: 62.18 (33369 / 53664), f1 (weighted): 62.20, loss: 1.17e+00\n",
      "  time: 700s (wall 792s)\n",
      "step 129000 / 188418 (epoch 34.23 / 50):\n",
      "  learning_rate = 3.50e-03, loss_average = 8.41e-01\n",
      "  validation accuracy: 62.08 (33315 / 53664), f1 (weighted): 62.08, loss: 1.18e+00\n",
      "  time: 708s (wall 802s)\n",
      "step 130500 / 188418 (epoch 34.63 / 50):\n",
      "  learning_rate = 3.50e-03, loss_average = 8.83e-01\n",
      "  validation accuracy: 62.00 (33272 / 53664), f1 (weighted): 62.01, loss: 1.16e+00\n",
      "  time: 716s (wall 811s)\n",
      "step 132000 / 188418 (epoch 35.03 / 50):\n",
      "  learning_rate = 3.32e-03, loss_average = 8.07e-01\n",
      "  validation accuracy: 62.18 (33369 / 53664), f1 (weighted): 62.21, loss: 1.16e+00\n",
      "  time: 725s (wall 820s)\n",
      "step 133500 / 188418 (epoch 35.43 / 50):\n",
      "  learning_rate = 3.32e-03, loss_average = 8.05e-01\n",
      "  validation accuracy: 62.01 (33275 / 53664), f1 (weighted): 62.03, loss: 1.18e+00\n",
      "  time: 733s (wall 829s)\n",
      "step 135000 / 188418 (epoch 35.82 / 50):\n",
      "  learning_rate = 3.32e-03, loss_average = 8.32e-01\n",
      "  validation accuracy: 62.21 (33386 / 53664), f1 (weighted): 62.23, loss: 1.17e+00\n",
      "  time: 741s (wall 839s)\n",
      "step 136500 / 188418 (epoch 36.22 / 50):\n",
      "  learning_rate = 3.16e-03, loss_average = 8.78e-01\n",
      "  validation accuracy: 61.98 (33259 / 53664), f1 (weighted): 62.02, loss: 1.17e+00\n",
      "  time: 749s (wall 848s)\n",
      "step 138000 / 188418 (epoch 36.62 / 50):\n",
      "  learning_rate = 3.16e-03, loss_average = 8.42e-01\n",
      "  validation accuracy: 62.07 (33310 / 53664), f1 (weighted): 62.11, loss: 1.18e+00\n",
      "  time: 757s (wall 857s)\n",
      "step 139500 / 188418 (epoch 37.02 / 50):\n",
      "  learning_rate = 3.00e-03, loss_average = 8.10e-01\n",
      "  validation accuracy: 62.04 (33293 / 53664), f1 (weighted): 62.06, loss: 1.18e+00\n",
      "  time: 765s (wall 866s)\n",
      "step 141000 / 188418 (epoch 37.42 / 50):\n",
      "  learning_rate = 3.00e-03, loss_average = 8.59e-01\n",
      "  validation accuracy: 62.10 (33325 / 53664), f1 (weighted): 62.12, loss: 1.17e+00\n",
      "  time: 773s (wall 876s)\n",
      "step 142500 / 188418 (epoch 37.81 / 50):\n",
      "  learning_rate = 3.00e-03, loss_average = 7.98e-01\n",
      "  validation accuracy: 61.83 (33180 / 53664), f1 (weighted): 61.84, loss: 1.18e+00\n",
      "  time: 782s (wall 885s)\n",
      "step 144000 / 188418 (epoch 38.21 / 50):\n",
      "  learning_rate = 2.85e-03, loss_average = 8.34e-01\n",
      "  validation accuracy: 61.96 (33250 / 53664), f1 (weighted): 62.00, loss: 1.18e+00\n",
      "  time: 790s (wall 894s)\n",
      "step 145500 / 188418 (epoch 38.61 / 50):\n",
      "  learning_rate = 2.85e-03, loss_average = 8.75e-01\n",
      "  validation accuracy: 61.92 (33227 / 53664), f1 (weighted): 61.92, loss: 1.18e+00\n",
      "  time: 798s (wall 903s)\n",
      "step 147000 / 188418 (epoch 39.01 / 50):\n",
      "  learning_rate = 2.71e-03, loss_average = 8.17e-01\n",
      "  validation accuracy: 62.07 (33308 / 53664), f1 (weighted): 62.09, loss: 1.18e+00\n",
      "  time: 806s (wall 912s)\n",
      "step 148500 / 188418 (epoch 39.41 / 50):\n",
      "  learning_rate = 2.71e-03, loss_average = 8.11e-01\n",
      "  validation accuracy: 61.75 (33136 / 53664), f1 (weighted): 61.76, loss: 1.19e+00\n",
      "  time: 814s (wall 922s)\n",
      "step 150000 / 188418 (epoch 39.80 / 50):\n",
      "  learning_rate = 2.71e-03, loss_average = 8.66e-01\n",
      "  validation accuracy: 62.00 (33272 / 53664), f1 (weighted): 62.00, loss: 1.18e+00\n",
      "  time: 822s (wall 931s)\n",
      "step 151500 / 188418 (epoch 40.20 / 50):\n",
      "  learning_rate = 2.57e-03, loss_average = 8.23e-01\n",
      "  validation accuracy: 61.94 (33238 / 53664), f1 (weighted): 61.96, loss: 1.18e+00\n",
      "  time: 830s (wall 940s)\n",
      "step 153000 / 188418 (epoch 40.60 / 50):\n",
      "  learning_rate = 2.57e-03, loss_average = 8.13e-01\n",
      "  validation accuracy: 62.05 (33300 / 53664), f1 (weighted): 62.07, loss: 1.18e+00\n",
      "  time: 838s (wall 949s)\n",
      "step 154500 / 188418 (epoch 41.00 / 50):\n",
      "  learning_rate = 2.57e-03, loss_average = 8.41e-01\n",
      "  validation accuracy: 61.94 (33241 / 53664), f1 (weighted): 61.96, loss: 1.18e+00\n",
      "  time: 846s (wall 959s)\n",
      "step 156000 / 188418 (epoch 41.40 / 50):\n",
      "  learning_rate = 2.44e-03, loss_average = 8.08e-01\n",
      "  validation accuracy: 61.68 (33100 / 53664), f1 (weighted): 61.71, loss: 1.19e+00\n",
      "  time: 855s (wall 968s)\n",
      "step 157500 / 188418 (epoch 41.80 / 50):\n",
      "  learning_rate = 2.44e-03, loss_average = 8.03e-01\n",
      "  validation accuracy: 61.86 (33196 / 53664), f1 (weighted): 61.87, loss: 1.18e+00\n",
      "  time: 863s (wall 977s)\n",
      "step 159000 / 188418 (epoch 42.19 / 50):\n",
      "  learning_rate = 2.32e-03, loss_average = 8.00e-01\n",
      "  validation accuracy: 61.93 (33236 / 53664), f1 (weighted): 61.93, loss: 1.19e+00\n",
      "  time: 871s (wall 987s)\n",
      "step 160500 / 188418 (epoch 42.59 / 50):\n",
      "  learning_rate = 2.32e-03, loss_average = 8.38e-01\n",
      "  validation accuracy: 61.99 (33267 / 53664), f1 (weighted): 62.01, loss: 1.19e+00\n",
      "  time: 879s (wall 996s)\n",
      "step 162000 / 188418 (epoch 42.99 / 50):\n",
      "  learning_rate = 2.32e-03, loss_average = 8.42e-01\n",
      "  validation accuracy: 61.72 (33122 / 53664), f1 (weighted): 61.77, loss: 1.18e+00\n",
      "  time: 888s (wall 1005s)\n",
      "step 163500 / 188418 (epoch 43.39 / 50):\n",
      "  learning_rate = 2.20e-03, loss_average = 7.89e-01\n",
      "  validation accuracy: 61.91 (33224 / 53664), f1 (weighted): 61.93, loss: 1.19e+00\n",
      "  time: 896s (wall 1014s)\n",
      "step 165000 / 188418 (epoch 43.79 / 50):\n",
      "  learning_rate = 2.20e-03, loss_average = 8.20e-01\n",
      "  validation accuracy: 62.08 (33315 / 53664), f1 (weighted): 62.10, loss: 1.19e+00\n",
      "  time: 904s (wall 1023s)\n",
      "step 166500 / 188418 (epoch 44.18 / 50):\n",
      "  learning_rate = 2.09e-03, loss_average = 8.18e-01\n",
      "  validation accuracy: 62.10 (33326 / 53664), f1 (weighted): 62.10, loss: 1.19e+00\n",
      "  time: 912s (wall 1033s)\n",
      "step 168000 / 188418 (epoch 44.58 / 50):\n",
      "  learning_rate = 2.09e-03, loss_average = 8.50e-01\n",
      "  validation accuracy: 61.82 (33175 / 53664), f1 (weighted): 61.83, loss: 1.19e+00\n",
      "  time: 920s (wall 1042s)\n",
      "step 169500 / 188418 (epoch 44.98 / 50):\n",
      "  learning_rate = 2.09e-03, loss_average = 7.96e-01\n",
      "  validation accuracy: 61.81 (33168 / 53664), f1 (weighted): 61.86, loss: 1.19e+00\n",
      "  time: 929s (wall 1052s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 171000 / 188418 (epoch 45.38 / 50):\n",
      "  learning_rate = 1.99e-03, loss_average = 7.94e-01\n",
      "  validation accuracy: 61.85 (33191 / 53664), f1 (weighted): 61.88, loss: 1.19e+00\n",
      "  time: 937s (wall 1061s)\n",
      "step 172500 / 188418 (epoch 45.78 / 50):\n",
      "  learning_rate = 1.99e-03, loss_average = 8.18e-01\n",
      "  validation accuracy: 61.88 (33206 / 53664), f1 (weighted): 61.91, loss: 1.19e+00\n",
      "  time: 945s (wall 1070s)\n",
      "step 174000 / 188418 (epoch 46.17 / 50):\n",
      "  learning_rate = 1.89e-03, loss_average = 7.68e-01\n",
      "  validation accuracy: 61.84 (33185 / 53664), f1 (weighted): 61.87, loss: 1.20e+00\n",
      "  time: 954s (wall 1080s)\n",
      "step 175500 / 188418 (epoch 46.57 / 50):\n",
      "  learning_rate = 1.89e-03, loss_average = 8.00e-01\n",
      "  validation accuracy: 61.80 (33162 / 53664), f1 (weighted): 61.86, loss: 1.20e+00\n",
      "  time: 962s (wall 1089s)\n",
      "step 177000 / 188418 (epoch 46.97 / 50):\n",
      "  learning_rate = 1.89e-03, loss_average = 8.44e-01\n",
      "  validation accuracy: 61.86 (33197 / 53664), f1 (weighted): 61.89, loss: 1.18e+00\n",
      "  time: 970s (wall 1098s)\n",
      "step 178500 / 188418 (epoch 47.37 / 50):\n",
      "  learning_rate = 1.79e-03, loss_average = 8.23e-01\n",
      "  validation accuracy: 61.98 (33260 / 53664), f1 (weighted): 62.00, loss: 1.19e+00\n",
      "  time: 978s (wall 1107s)\n",
      "step 180000 / 188418 (epoch 47.77 / 50):\n",
      "  learning_rate = 1.79e-03, loss_average = 8.10e-01\n",
      "  validation accuracy: 62.00 (33271 / 53664), f1 (weighted): 62.02, loss: 1.19e+00\n",
      "  time: 986s (wall 1116s)\n",
      "step 181500 / 188418 (epoch 48.16 / 50):\n",
      "  learning_rate = 1.71e-03, loss_average = 7.84e-01\n",
      "  validation accuracy: 61.99 (33267 / 53664), f1 (weighted): 62.01, loss: 1.19e+00\n",
      "  time: 994s (wall 1126s)\n",
      "step 183000 / 188418 (epoch 48.56 / 50):\n",
      "  learning_rate = 1.71e-03, loss_average = 8.19e-01\n",
      "  validation accuracy: 61.88 (33206 / 53664), f1 (weighted): 61.90, loss: 1.19e+00\n",
      "  time: 1003s (wall 1135s)\n",
      "step 184500 / 188418 (epoch 48.96 / 50):\n",
      "  learning_rate = 1.71e-03, loss_average = 7.59e-01\n",
      "  validation accuracy: 61.90 (33220 / 53664), f1 (weighted): 61.91, loss: 1.20e+00\n",
      "  time: 1011s (wall 1144s)\n",
      "step 186000 / 188418 (epoch 49.36 / 50):\n",
      "  learning_rate = 1.62e-03, loss_average = 7.90e-01\n",
      "  validation accuracy: 61.76 (33142 / 53664), f1 (weighted): 61.80, loss: 1.20e+00\n",
      "  time: 1019s (wall 1153s)\n",
      "step 187500 / 188418 (epoch 49.76 / 50):\n",
      "  learning_rate = 1.62e-03, loss_average = 8.08e-01\n",
      "  validation accuracy: 61.80 (33162 / 53664), f1 (weighted): 61.83, loss: 1.20e+00\n",
      "  time: 1027s (wall 1162s)\n",
      "step 188418 / 188418 (epoch 50.00 / 50):\n",
      "  learning_rate = 1.62e-03, loss_average = 8.09e-01\n",
      "  validation accuracy: 62.11 (33332 / 53664), f1 (weighted): 62.14, loss: 1.19e+00\n",
      "  time: 1033s (wall 1169s)\n",
      "validation accuracy: peak = 62.31, mean = 61.91\n",
      "step 1500 / 188418 (epoch 0.40 / 50):\n",
      "  learning_rate = 2.00e-02, loss_average = 2.46e+00\n",
      "  validation accuracy: 23.40 (12558 / 53664), f1 (weighted): 19.93, loss: 2.45e+00\n",
      "  time: 9s (wall 10s)\n",
      "step 3000 / 188418 (epoch 0.80 / 50):\n",
      "  learning_rate = 2.00e-02, loss_average = 1.92e+00\n",
      "  validation accuracy: 43.18 (23173 / 53664), f1 (weighted): 42.82, loss: 1.91e+00\n",
      "  time: 18s (wall 20s)\n",
      "step 4500 / 188418 (epoch 1.19 / 50):\n",
      "  learning_rate = 1.90e-02, loss_average = 1.71e+00\n",
      "  validation accuracy: 49.05 (26324 / 53664), f1 (weighted): 48.89, loss: 1.68e+00\n",
      "  time: 27s (wall 30s)\n",
      "step 6000 / 188418 (epoch 1.59 / 50):\n",
      "  learning_rate = 1.90e-02, loss_average = 1.52e+00\n",
      "  validation accuracy: 52.56 (28207 / 53664), f1 (weighted): 52.62, loss: 1.53e+00\n",
      "  time: 35s (wall 39s)\n",
      "step 7500 / 188418 (epoch 1.99 / 50):\n",
      "  learning_rate = 1.90e-02, loss_average = 1.45e+00\n",
      "  validation accuracy: 54.39 (29187 / 53664), f1 (weighted): 54.50, loss: 1.44e+00\n",
      "  time: 43s (wall 49s)\n",
      "step 9000 / 188418 (epoch 2.39 / 50):\n",
      "  learning_rate = 1.80e-02, loss_average = 1.38e+00\n",
      "  validation accuracy: 55.69 (29886 / 53664), f1 (weighted): 55.76, loss: 1.38e+00\n",
      "  time: 52s (wall 58s)\n",
      "step 10500 / 188418 (epoch 2.79 / 50):\n",
      "  learning_rate = 1.80e-02, loss_average = 1.34e+00\n",
      "  validation accuracy: 56.11 (30111 / 53664), f1 (weighted): 56.13, loss: 1.34e+00\n",
      "  time: 60s (wall 67s)\n",
      "step 12000 / 188418 (epoch 3.18 / 50):\n",
      "  learning_rate = 1.71e-02, loss_average = 1.27e+00\n",
      "  validation accuracy: 57.27 (30731 / 53664), f1 (weighted): 57.30, loss: 1.30e+00\n",
      "  time: 68s (wall 77s)\n",
      "step 13500 / 188418 (epoch 3.58 / 50):\n",
      "  learning_rate = 1.71e-02, loss_average = 1.25e+00\n",
      "  validation accuracy: 57.30 (30751 / 53664), f1 (weighted): 57.23, loss: 1.28e+00\n",
      "  time: 77s (wall 86s)\n",
      "step 15000 / 188418 (epoch 3.98 / 50):\n",
      "  learning_rate = 1.71e-02, loss_average = 1.25e+00\n",
      "  validation accuracy: 57.55 (30884 / 53664), f1 (weighted): 57.63, loss: 1.27e+00\n",
      "  time: 85s (wall 96s)\n",
      "step 16500 / 188418 (epoch 4.38 / 50):\n",
      "  learning_rate = 1.63e-02, loss_average = 1.22e+00\n",
      "  validation accuracy: 58.41 (31346 / 53664), f1 (weighted): 58.45, loss: 1.24e+00\n",
      "  time: 93s (wall 105s)\n",
      "step 18000 / 188418 (epoch 4.78 / 50):\n",
      "  learning_rate = 1.63e-02, loss_average = 1.18e+00\n",
      "  validation accuracy: 58.96 (31642 / 53664), f1 (weighted): 59.06, loss: 1.22e+00\n",
      "  time: 101s (wall 114s)\n",
      "step 19500 / 188418 (epoch 5.17 / 50):\n",
      "  learning_rate = 1.55e-02, loss_average = 1.15e+00\n",
      "  validation accuracy: 59.16 (31750 / 53664), f1 (weighted): 59.19, loss: 1.21e+00\n",
      "  time: 109s (wall 123s)\n",
      "step 21000 / 188418 (epoch 5.57 / 50):\n",
      "  learning_rate = 1.55e-02, loss_average = 1.16e+00\n",
      "  validation accuracy: 59.37 (31862 / 53664), f1 (weighted): 59.43, loss: 1.20e+00\n",
      "  time: 117s (wall 133s)\n",
      "step 22500 / 188418 (epoch 5.97 / 50):\n",
      "  learning_rate = 1.55e-02, loss_average = 1.16e+00\n",
      "  validation accuracy: 59.64 (32005 / 53664), f1 (weighted): 59.72, loss: 1.19e+00\n",
      "  time: 126s (wall 142s)\n",
      "step 24000 / 188418 (epoch 6.37 / 50):\n",
      "  learning_rate = 1.47e-02, loss_average = 1.09e+00\n",
      "  validation accuracy: 59.86 (32122 / 53664), f1 (weighted): 59.88, loss: 1.19e+00\n",
      "  time: 134s (wall 151s)\n",
      "step 25500 / 188418 (epoch 6.77 / 50):\n",
      "  learning_rate = 1.47e-02, loss_average = 1.09e+00\n",
      "  validation accuracy: 59.87 (32130 / 53664), f1 (weighted): 59.85, loss: 1.18e+00\n",
      "  time: 142s (wall 160s)\n",
      "step 27000 / 188418 (epoch 7.16 / 50):\n",
      "  learning_rate = 1.40e-02, loss_average = 1.09e+00\n",
      "  validation accuracy: 60.06 (32230 / 53664), f1 (weighted): 60.09, loss: 1.19e+00\n",
      "  time: 150s (wall 170s)\n",
      "step 28500 / 188418 (epoch 7.56 / 50):\n",
      "  learning_rate = 1.40e-02, loss_average = 1.10e+00\n",
      "  validation accuracy: 60.52 (32479 / 53664), f1 (weighted): 60.60, loss: 1.17e+00\n",
      "  time: 159s (wall 179s)\n",
      "step 30000 / 188418 (epoch 7.96 / 50):\n",
      "  learning_rate = 1.40e-02, loss_average = 1.07e+00\n",
      "  validation accuracy: 60.51 (32471 / 53664), f1 (weighted): 60.54, loss: 1.17e+00\n",
      "  time: 167s (wall 188s)\n",
      "step 31500 / 188418 (epoch 8.36 / 50):\n",
      "  learning_rate = 1.33e-02, loss_average = 1.08e+00\n",
      "  validation accuracy: 60.68 (32564 / 53664), f1 (weighted): 60.67, loss: 1.16e+00\n",
      "  time: 175s (wall 197s)\n",
      "step 33000 / 188418 (epoch 8.76 / 50):\n",
      "  learning_rate = 1.33e-02, loss_average = 1.05e+00\n",
      "  validation accuracy: 60.64 (32541 / 53664), f1 (weighted): 60.65, loss: 1.16e+00\n",
      "  time: 183s (wall 207s)\n",
      "step 34500 / 188418 (epoch 9.16 / 50):\n",
      "  learning_rate = 1.26e-02, loss_average = 1.08e+00\n",
      "  validation accuracy: 61.05 (32763 / 53664), f1 (weighted): 61.11, loss: 1.15e+00\n",
      "  time: 191s (wall 216s)\n",
      "step 36000 / 188418 (epoch 9.55 / 50):\n",
      "  learning_rate = 1.26e-02, loss_average = 1.02e+00\n",
      "  validation accuracy: 60.76 (32605 / 53664), f1 (weighted): 60.79, loss: 1.16e+00\n",
      "  time: 199s (wall 225s)\n",
      "step 37500 / 188418 (epoch 9.95 / 50):\n",
      "  learning_rate = 1.26e-02, loss_average = 1.08e+00\n",
      "  validation accuracy: 60.80 (32627 / 53664), f1 (weighted): 60.79, loss: 1.16e+00\n",
      "  time: 208s (wall 235s)\n",
      "step 39000 / 188418 (epoch 10.35 / 50):\n",
      "  learning_rate = 1.20e-02, loss_average = 1.03e+00\n",
      "  validation accuracy: 61.37 (32935 / 53664), f1 (weighted): 61.40, loss: 1.15e+00\n",
      "  time: 216s (wall 244s)\n",
      "step 40500 / 188418 (epoch 10.75 / 50):\n",
      "  learning_rate = 1.20e-02, loss_average = 1.03e+00\n",
      "  validation accuracy: 60.90 (32683 / 53664), f1 (weighted): 60.92, loss: 1.16e+00\n",
      "  time: 224s (wall 253s)\n",
      "step 42000 / 188418 (epoch 11.15 / 50):\n",
      "  learning_rate = 1.14e-02, loss_average = 1.03e+00\n",
      "  validation accuracy: 61.01 (32743 / 53664), f1 (weighted): 61.05, loss: 1.15e+00\n",
      "  time: 232s (wall 262s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 43500 / 188418 (epoch 11.54 / 50):\n",
      "  learning_rate = 1.14e-02, loss_average = 1.03e+00\n",
      "  validation accuracy: 61.16 (32820 / 53664), f1 (weighted): 61.17, loss: 1.15e+00\n",
      "  time: 240s (wall 272s)\n",
      "step 45000 / 188418 (epoch 11.94 / 50):\n",
      "  learning_rate = 1.14e-02, loss_average = 1.06e+00\n",
      "  validation accuracy: 61.49 (32996 / 53664), f1 (weighted): 61.48, loss: 1.15e+00\n",
      "  time: 249s (wall 281s)\n",
      "step 46500 / 188418 (epoch 12.34 / 50):\n",
      "  learning_rate = 1.08e-02, loss_average = 1.01e+00\n",
      "  validation accuracy: 61.18 (32833 / 53664), f1 (weighted): 61.13, loss: 1.15e+00\n",
      "  time: 257s (wall 290s)\n",
      "step 48000 / 188418 (epoch 12.74 / 50):\n",
      "  learning_rate = 1.08e-02, loss_average = 9.95e-01\n",
      "  validation accuracy: 61.36 (32929 / 53664), f1 (weighted): 61.37, loss: 1.14e+00\n",
      "  time: 265s (wall 300s)\n",
      "step 49500 / 188418 (epoch 13.14 / 50):\n",
      "  learning_rate = 1.03e-02, loss_average = 1.00e+00\n",
      "  validation accuracy: 61.47 (32987 / 53664), f1 (weighted): 61.46, loss: 1.15e+00\n",
      "  time: 273s (wall 309s)\n",
      "step 51000 / 188418 (epoch 13.53 / 50):\n",
      "  learning_rate = 1.03e-02, loss_average = 1.01e+00\n",
      "  validation accuracy: 61.32 (32909 / 53664), f1 (weighted): 61.36, loss: 1.15e+00\n",
      "  time: 281s (wall 318s)\n",
      "step 52500 / 188418 (epoch 13.93 / 50):\n",
      "  learning_rate = 1.03e-02, loss_average = 1.01e+00\n",
      "  validation accuracy: 61.59 (33050 / 53664), f1 (weighted): 61.63, loss: 1.14e+00\n",
      "  time: 290s (wall 327s)\n",
      "step 54000 / 188418 (epoch 14.33 / 50):\n",
      "  learning_rate = 9.75e-03, loss_average = 1.01e+00\n",
      "  validation accuracy: 61.43 (32965 / 53664), f1 (weighted): 61.45, loss: 1.14e+00\n",
      "  time: 298s (wall 337s)\n",
      "step 55500 / 188418 (epoch 14.73 / 50):\n",
      "  learning_rate = 9.75e-03, loss_average = 9.86e-01\n",
      "  validation accuracy: 61.63 (33072 / 53664), f1 (weighted): 61.60, loss: 1.15e+00\n",
      "  time: 306s (wall 346s)\n",
      "step 57000 / 188418 (epoch 15.13 / 50):\n",
      "  learning_rate = 9.27e-03, loss_average = 9.47e-01\n",
      "  validation accuracy: 61.92 (33229 / 53664), f1 (weighted): 61.94, loss: 1.14e+00\n",
      "  time: 314s (wall 355s)\n",
      "step 58500 / 188418 (epoch 15.52 / 50):\n",
      "  learning_rate = 9.27e-03, loss_average = 1.02e+00\n",
      "  validation accuracy: 61.61 (33062 / 53664), f1 (weighted): 61.67, loss: 1.14e+00\n",
      "  time: 322s (wall 364s)\n",
      "step 60000 / 188418 (epoch 15.92 / 50):\n",
      "  learning_rate = 9.27e-03, loss_average = 9.88e-01\n",
      "  validation accuracy: 61.75 (33139 / 53664), f1 (weighted): 61.78, loss: 1.14e+00\n",
      "  time: 330s (wall 374s)\n",
      "step 61500 / 188418 (epoch 16.32 / 50):\n",
      "  learning_rate = 8.80e-03, loss_average = 9.71e-01\n",
      "  validation accuracy: 61.96 (33248 / 53664), f1 (weighted): 61.94, loss: 1.14e+00\n",
      "  time: 339s (wall 383s)\n",
      "step 63000 / 188418 (epoch 16.72 / 50):\n",
      "  learning_rate = 8.80e-03, loss_average = 9.92e-01\n",
      "  validation accuracy: 61.68 (33101 / 53664), f1 (weighted): 61.72, loss: 1.15e+00\n",
      "  time: 347s (wall 392s)\n",
      "step 64500 / 188418 (epoch 17.12 / 50):\n",
      "  learning_rate = 8.36e-03, loss_average = 9.37e-01\n",
      "  validation accuracy: 61.75 (33135 / 53664), f1 (weighted): 61.79, loss: 1.14e+00\n",
      "  time: 355s (wall 401s)\n",
      "step 66000 / 188418 (epoch 17.51 / 50):\n",
      "  learning_rate = 8.36e-03, loss_average = 9.47e-01\n",
      "  validation accuracy: 61.75 (33140 / 53664), f1 (weighted): 61.75, loss: 1.14e+00\n",
      "  time: 363s (wall 411s)\n",
      "step 67500 / 188418 (epoch 17.91 / 50):\n",
      "  learning_rate = 8.36e-03, loss_average = 9.73e-01\n",
      "  validation accuracy: 61.65 (33086 / 53664), f1 (weighted): 61.67, loss: 1.15e+00\n",
      "  time: 371s (wall 420s)\n",
      "step 69000 / 188418 (epoch 18.31 / 50):\n",
      "  learning_rate = 7.94e-03, loss_average = 9.60e-01\n",
      "  validation accuracy: 61.83 (33180 / 53664), f1 (weighted): 61.81, loss: 1.14e+00\n",
      "  time: 380s (wall 429s)\n",
      "step 70500 / 188418 (epoch 18.71 / 50):\n",
      "  learning_rate = 7.94e-03, loss_average = 9.80e-01\n",
      "  validation accuracy: 61.87 (33204 / 53664), f1 (weighted): 61.91, loss: 1.14e+00\n",
      "  time: 388s (wall 439s)\n",
      "step 72000 / 188418 (epoch 19.11 / 50):\n",
      "  learning_rate = 7.55e-03, loss_average = 9.33e-01\n",
      "  validation accuracy: 62.29 (33428 / 53664), f1 (weighted): 62.27, loss: 1.14e+00\n",
      "  time: 396s (wall 448s)\n",
      "step 73500 / 188418 (epoch 19.50 / 50):\n",
      "  learning_rate = 7.55e-03, loss_average = 9.21e-01\n",
      "  validation accuracy: 61.90 (33217 / 53664), f1 (weighted): 61.89, loss: 1.15e+00\n",
      "  time: 404s (wall 457s)\n",
      "step 75000 / 188418 (epoch 19.90 / 50):\n",
      "  learning_rate = 7.55e-03, loss_average = 9.05e-01\n",
      "  validation accuracy: 61.73 (33127 / 53664), f1 (weighted): 61.72, loss: 1.16e+00\n",
      "  time: 412s (wall 466s)\n",
      "step 76500 / 188418 (epoch 20.30 / 50):\n",
      "  learning_rate = 7.17e-03, loss_average = 9.21e-01\n",
      "  validation accuracy: 62.02 (33282 / 53664), f1 (weighted): 62.06, loss: 1.15e+00\n",
      "  time: 420s (wall 476s)\n",
      "step 78000 / 188418 (epoch 20.70 / 50):\n",
      "  learning_rate = 7.17e-03, loss_average = 9.37e-01\n",
      "  validation accuracy: 61.92 (33228 / 53664), f1 (weighted): 61.95, loss: 1.15e+00\n",
      "  time: 429s (wall 485s)\n",
      "step 79500 / 188418 (epoch 21.10 / 50):\n",
      "  learning_rate = 6.81e-03, loss_average = 9.05e-01\n",
      "  validation accuracy: 62.15 (33354 / 53664), f1 (weighted): 62.20, loss: 1.15e+00\n",
      "  time: 437s (wall 494s)\n",
      "step 81000 / 188418 (epoch 21.49 / 50):\n",
      "  learning_rate = 6.81e-03, loss_average = 9.31e-01\n",
      "  validation accuracy: 62.07 (33308 / 53664), f1 (weighted): 62.07, loss: 1.14e+00\n",
      "  time: 445s (wall 503s)\n",
      "step 82500 / 188418 (epoch 21.89 / 50):\n",
      "  learning_rate = 6.81e-03, loss_average = 9.50e-01\n",
      "  validation accuracy: 62.06 (33303 / 53664), f1 (weighted): 62.07, loss: 1.14e+00\n",
      "  time: 453s (wall 513s)\n",
      "step 84000 / 188418 (epoch 22.29 / 50):\n",
      "  learning_rate = 6.47e-03, loss_average = 9.15e-01\n",
      "  validation accuracy: 61.96 (33248 / 53664), f1 (weighted): 61.98, loss: 1.15e+00\n",
      "  time: 461s (wall 522s)\n",
      "step 85500 / 188418 (epoch 22.69 / 50):\n",
      "  learning_rate = 6.47e-03, loss_average = 9.24e-01\n",
      "  validation accuracy: 61.92 (33228 / 53664), f1 (weighted): 61.92, loss: 1.15e+00\n",
      "  time: 469s (wall 531s)\n",
      "step 87000 / 188418 (epoch 23.09 / 50):\n",
      "  learning_rate = 6.15e-03, loss_average = 8.84e-01\n",
      "  validation accuracy: 61.90 (33217 / 53664), f1 (weighted): 61.88, loss: 1.16e+00\n",
      "  time: 478s (wall 541s)\n",
      "step 88500 / 188418 (epoch 23.48 / 50):\n",
      "  learning_rate = 6.15e-03, loss_average = 9.67e-01\n",
      "  validation accuracy: 61.94 (33241 / 53664), f1 (weighted): 61.96, loss: 1.15e+00\n",
      "  time: 486s (wall 550s)\n",
      "step 90000 / 188418 (epoch 23.88 / 50):\n",
      "  learning_rate = 6.15e-03, loss_average = 9.08e-01\n",
      "  validation accuracy: 62.18 (33368 / 53664), f1 (weighted): 62.22, loss: 1.14e+00\n",
      "  time: 494s (wall 559s)\n",
      "step 91500 / 188418 (epoch 24.28 / 50):\n",
      "  learning_rate = 5.84e-03, loss_average = 8.77e-01\n",
      "  validation accuracy: 61.91 (33223 / 53664), f1 (weighted): 61.94, loss: 1.16e+00\n",
      "  time: 502s (wall 568s)\n",
      "step 93000 / 188418 (epoch 24.68 / 50):\n",
      "  learning_rate = 5.84e-03, loss_average = 9.13e-01\n",
      "  validation accuracy: 61.85 (33193 / 53664), f1 (weighted): 61.89, loss: 1.15e+00\n",
      "  time: 511s (wall 578s)\n",
      "step 94500 / 188418 (epoch 25.08 / 50):\n",
      "  learning_rate = 5.55e-03, loss_average = 9.00e-01\n",
      "  validation accuracy: 62.02 (33281 / 53664), f1 (weighted): 62.01, loss: 1.15e+00\n",
      "  time: 519s (wall 587s)\n",
      "step 96000 / 188418 (epoch 25.48 / 50):\n",
      "  learning_rate = 5.55e-03, loss_average = 9.04e-01\n",
      "  validation accuracy: 62.11 (33332 / 53664), f1 (weighted): 62.13, loss: 1.15e+00\n",
      "  time: 527s (wall 596s)\n",
      "step 97500 / 188418 (epoch 25.87 / 50):\n",
      "  learning_rate = 5.55e-03, loss_average = 9.24e-01\n",
      "  validation accuracy: 62.20 (33379 / 53664), f1 (weighted): 62.21, loss: 1.14e+00\n",
      "  time: 535s (wall 606s)\n",
      "step 99000 / 188418 (epoch 26.27 / 50):\n",
      "  learning_rate = 5.27e-03, loss_average = 8.61e-01\n",
      "  validation accuracy: 61.82 (33175 / 53664), f1 (weighted): 61.86, loss: 1.16e+00\n",
      "  time: 543s (wall 615s)\n",
      "step 100500 / 188418 (epoch 26.67 / 50):\n",
      "  learning_rate = 5.27e-03, loss_average = 9.10e-01\n",
      "  validation accuracy: 62.06 (33304 / 53664), f1 (weighted): 62.07, loss: 1.15e+00\n",
      "  time: 552s (wall 624s)\n",
      "step 102000 / 188418 (epoch 27.07 / 50):\n",
      "  learning_rate = 5.01e-03, loss_average = 8.67e-01\n",
      "  validation accuracy: 61.84 (33187 / 53664), f1 (weighted): 61.89, loss: 1.16e+00\n",
      "  time: 560s (wall 634s)\n",
      "step 103500 / 188418 (epoch 27.47 / 50):\n",
      "  learning_rate = 5.01e-03, loss_average = 8.74e-01\n",
      "  validation accuracy: 62.18 (33367 / 53664), f1 (weighted): 62.20, loss: 1.15e+00\n",
      "  time: 568s (wall 643s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 105000 / 188418 (epoch 27.86 / 50):\n",
      "  learning_rate = 5.01e-03, loss_average = 8.71e-01\n",
      "  validation accuracy: 61.90 (33220 / 53664), f1 (weighted): 61.91, loss: 1.15e+00\n",
      "  time: 576s (wall 652s)\n",
      "step 106500 / 188418 (epoch 28.26 / 50):\n",
      "  learning_rate = 4.76e-03, loss_average = 8.46e-01\n",
      "  validation accuracy: 61.91 (33226 / 53664), f1 (weighted): 61.92, loss: 1.15e+00\n",
      "  time: 584s (wall 661s)\n",
      "step 108000 / 188418 (epoch 28.66 / 50):\n",
      "  learning_rate = 4.76e-03, loss_average = 8.80e-01\n",
      "  validation accuracy: 62.10 (33325 / 53664), f1 (weighted): 62.12, loss: 1.15e+00\n",
      "  time: 592s (wall 670s)\n",
      "step 109500 / 188418 (epoch 29.06 / 50):\n",
      "  learning_rate = 4.52e-03, loss_average = 8.49e-01\n",
      "  validation accuracy: 62.05 (33297 / 53664), f1 (weighted): 62.03, loss: 1.16e+00\n",
      "  time: 601s (wall 680s)\n",
      "step 111000 / 188418 (epoch 29.46 / 50):\n",
      "  learning_rate = 4.52e-03, loss_average = 8.91e-01\n",
      "  validation accuracy: 62.00 (33274 / 53664), f1 (weighted): 62.00, loss: 1.16e+00\n",
      "  time: 609s (wall 689s)\n",
      "step 112500 / 188418 (epoch 29.85 / 50):\n",
      "  learning_rate = 4.52e-03, loss_average = 8.66e-01\n",
      "  validation accuracy: 62.23 (33397 / 53664), f1 (weighted): 62.25, loss: 1.15e+00\n",
      "  time: 617s (wall 698s)\n",
      "step 114000 / 188418 (epoch 30.25 / 50):\n",
      "  learning_rate = 4.29e-03, loss_average = 8.70e-01\n",
      "  validation accuracy: 62.02 (33283 / 53664), f1 (weighted): 62.04, loss: 1.17e+00\n",
      "  time: 625s (wall 708s)\n",
      "step 115500 / 188418 (epoch 30.65 / 50):\n",
      "  learning_rate = 4.29e-03, loss_average = 8.85e-01\n",
      "  validation accuracy: 62.17 (33363 / 53664), f1 (weighted): 62.14, loss: 1.16e+00\n",
      "  time: 633s (wall 717s)\n",
      "step 117000 / 188418 (epoch 31.05 / 50):\n",
      "  learning_rate = 4.08e-03, loss_average = 8.38e-01\n",
      "  validation accuracy: 62.33 (33450 / 53664), f1 (weighted): 62.35, loss: 1.16e+00\n",
      "  time: 642s (wall 726s)\n",
      "step 118500 / 188418 (epoch 31.45 / 50):\n",
      "  learning_rate = 4.08e-03, loss_average = 8.40e-01\n",
      "  validation accuracy: 62.10 (33325 / 53664), f1 (weighted): 62.11, loss: 1.16e+00\n",
      "  time: 650s (wall 735s)\n",
      "step 120000 / 188418 (epoch 31.84 / 50):\n",
      "  learning_rate = 4.08e-03, loss_average = 8.98e-01\n",
      "  validation accuracy: 61.85 (33189 / 53664), f1 (weighted): 61.85, loss: 1.17e+00\n",
      "  time: 658s (wall 745s)\n",
      "step 121500 / 188418 (epoch 32.24 / 50):\n",
      "  learning_rate = 3.87e-03, loss_average = 8.57e-01\n",
      "  validation accuracy: 62.00 (33270 / 53664), f1 (weighted): 62.05, loss: 1.16e+00\n",
      "  time: 666s (wall 754s)\n",
      "step 123000 / 188418 (epoch 32.64 / 50):\n",
      "  learning_rate = 3.87e-03, loss_average = 8.68e-01\n",
      "  validation accuracy: 62.11 (33330 / 53664), f1 (weighted): 62.13, loss: 1.16e+00\n",
      "  time: 674s (wall 763s)\n",
      "step 124500 / 188418 (epoch 33.04 / 50):\n",
      "  learning_rate = 3.68e-03, loss_average = 8.48e-01\n",
      "  validation accuracy: 61.95 (33245 / 53664), f1 (weighted): 62.00, loss: 1.16e+00\n",
      "  time: 682s (wall 772s)\n",
      "step 126000 / 188418 (epoch 33.44 / 50):\n",
      "  learning_rate = 3.68e-03, loss_average = 8.69e-01\n",
      "  validation accuracy: 62.35 (33458 / 53664), f1 (weighted): 62.38, loss: 1.16e+00\n",
      "  time: 690s (wall 782s)\n",
      "step 127500 / 188418 (epoch 33.83 / 50):\n",
      "  learning_rate = 3.68e-03, loss_average = 8.71e-01\n",
      "  validation accuracy: 62.09 (33319 / 53664), f1 (weighted): 62.12, loss: 1.16e+00\n",
      "  time: 699s (wall 791s)\n",
      "step 129000 / 188418 (epoch 34.23 / 50):\n",
      "  learning_rate = 3.50e-03, loss_average = 8.40e-01\n",
      "  validation accuracy: 62.22 (33389 / 53664), f1 (weighted): 62.22, loss: 1.16e+00\n",
      "  time: 707s (wall 800s)\n",
      "step 130500 / 188418 (epoch 34.63 / 50):\n",
      "  learning_rate = 3.50e-03, loss_average = 8.32e-01\n",
      "  validation accuracy: 62.15 (33352 / 53664), f1 (weighted): 62.14, loss: 1.16e+00\n",
      "  time: 715s (wall 809s)\n",
      "step 132000 / 188418 (epoch 35.03 / 50):\n",
      "  learning_rate = 3.32e-03, loss_average = 8.41e-01\n",
      "  validation accuracy: 62.26 (33412 / 53664), f1 (weighted): 62.24, loss: 1.17e+00\n",
      "  time: 723s (wall 819s)\n",
      "step 133500 / 188418 (epoch 35.43 / 50):\n",
      "  learning_rate = 3.32e-03, loss_average = 8.55e-01\n",
      "  validation accuracy: 62.08 (33313 / 53664), f1 (weighted): 62.10, loss: 1.17e+00\n",
      "  time: 731s (wall 828s)\n",
      "step 135000 / 188418 (epoch 35.82 / 50):\n",
      "  learning_rate = 3.32e-03, loss_average = 8.37e-01\n",
      "  validation accuracy: 62.07 (33309 / 53664), f1 (weighted): 62.09, loss: 1.17e+00\n",
      "  time: 739s (wall 837s)\n",
      "step 136500 / 188418 (epoch 36.22 / 50):\n",
      "  learning_rate = 3.16e-03, loss_average = 8.29e-01\n",
      "  validation accuracy: 61.92 (33228 / 53664), f1 (weighted): 61.97, loss: 1.17e+00\n",
      "  time: 747s (wall 846s)\n",
      "step 138000 / 188418 (epoch 36.62 / 50):\n",
      "  learning_rate = 3.16e-03, loss_average = 8.64e-01\n",
      "  validation accuracy: 62.00 (33274 / 53664), f1 (weighted): 62.06, loss: 1.16e+00\n",
      "  time: 756s (wall 856s)\n",
      "step 139500 / 188418 (epoch 37.02 / 50):\n",
      "  learning_rate = 3.00e-03, loss_average = 8.20e-01\n",
      "  validation accuracy: 62.03 (33290 / 53664), f1 (weighted): 62.04, loss: 1.17e+00\n",
      "  time: 764s (wall 865s)\n",
      "step 141000 / 188418 (epoch 37.42 / 50):\n",
      "  learning_rate = 3.00e-03, loss_average = 8.13e-01\n",
      "  validation accuracy: 61.92 (33228 / 53664), f1 (weighted): 61.95, loss: 1.18e+00\n",
      "  time: 772s (wall 874s)\n",
      "step 142500 / 188418 (epoch 37.81 / 50):\n",
      "  learning_rate = 3.00e-03, loss_average = 8.55e-01\n",
      "  validation accuracy: 61.99 (33267 / 53664), f1 (weighted): 62.03, loss: 1.17e+00\n",
      "  time: 780s (wall 884s)\n",
      "step 144000 / 188418 (epoch 38.21 / 50):\n",
      "  learning_rate = 2.85e-03, loss_average = 8.34e-01\n",
      "  validation accuracy: 62.16 (33359 / 53664), f1 (weighted): 62.18, loss: 1.18e+00\n",
      "  time: 788s (wall 893s)\n",
      "step 145500 / 188418 (epoch 38.61 / 50):\n",
      "  learning_rate = 2.85e-03, loss_average = 8.34e-01\n",
      "  validation accuracy: 62.04 (33291 / 53664), f1 (weighted): 62.07, loss: 1.17e+00\n",
      "  time: 796s (wall 902s)\n",
      "step 147000 / 188418 (epoch 39.01 / 50):\n",
      "  learning_rate = 2.71e-03, loss_average = 8.33e-01\n",
      "  validation accuracy: 62.13 (33340 / 53664), f1 (weighted): 62.15, loss: 1.17e+00\n",
      "  time: 804s (wall 911s)\n",
      "step 148500 / 188418 (epoch 39.41 / 50):\n",
      "  learning_rate = 2.71e-03, loss_average = 8.25e-01\n",
      "  validation accuracy: 62.13 (33341 / 53664), f1 (weighted): 62.13, loss: 1.17e+00\n",
      "  time: 813s (wall 921s)\n",
      "step 150000 / 188418 (epoch 39.80 / 50):\n",
      "  learning_rate = 2.71e-03, loss_average = 8.09e-01\n",
      "  validation accuracy: 62.20 (33381 / 53664), f1 (weighted): 62.22, loss: 1.17e+00\n",
      "  time: 821s (wall 930s)\n",
      "step 151500 / 188418 (epoch 40.20 / 50):\n",
      "  learning_rate = 2.57e-03, loss_average = 8.38e-01\n",
      "  validation accuracy: 61.97 (33255 / 53664), f1 (weighted): 61.99, loss: 1.17e+00\n",
      "  time: 829s (wall 939s)\n",
      "step 153000 / 188418 (epoch 40.60 / 50):\n",
      "  learning_rate = 2.57e-03, loss_average = 7.91e-01\n",
      "  validation accuracy: 62.04 (33291 / 53664), f1 (weighted): 62.06, loss: 1.18e+00\n",
      "  time: 837s (wall 948s)\n",
      "step 154500 / 188418 (epoch 41.00 / 50):\n",
      "  learning_rate = 2.57e-03, loss_average = 8.04e-01\n",
      "  validation accuracy: 62.10 (33328 / 53664), f1 (weighted): 62.12, loss: 1.18e+00\n",
      "  time: 845s (wall 957s)\n",
      "step 156000 / 188418 (epoch 41.40 / 50):\n",
      "  learning_rate = 2.44e-03, loss_average = 8.18e-01\n",
      "  validation accuracy: 62.08 (33317 / 53664), f1 (weighted): 62.12, loss: 1.18e+00\n",
      "  time: 853s (wall 967s)\n",
      "step 157500 / 188418 (epoch 41.80 / 50):\n",
      "  learning_rate = 2.44e-03, loss_average = 8.14e-01\n",
      "  validation accuracy: 62.06 (33302 / 53664), f1 (weighted): 62.04, loss: 1.19e+00\n",
      "  time: 862s (wall 976s)\n",
      "step 159000 / 188418 (epoch 42.19 / 50):\n",
      "  learning_rate = 2.32e-03, loss_average = 8.16e-01\n",
      "  validation accuracy: 62.24 (33401 / 53664), f1 (weighted): 62.26, loss: 1.17e+00\n",
      "  time: 870s (wall 985s)\n",
      "step 160500 / 188418 (epoch 42.59 / 50):\n",
      "  learning_rate = 2.32e-03, loss_average = 8.58e-01\n",
      "  validation accuracy: 62.05 (33297 / 53664), f1 (weighted): 62.05, loss: 1.18e+00\n",
      "  time: 878s (wall 994s)\n",
      "step 162000 / 188418 (epoch 42.99 / 50):\n",
      "  learning_rate = 2.32e-03, loss_average = 8.06e-01\n",
      "  validation accuracy: 62.12 (33336 / 53664), f1 (weighted): 62.15, loss: 1.18e+00\n",
      "  time: 886s (wall 1004s)\n",
      "step 163500 / 188418 (epoch 43.39 / 50):\n",
      "  learning_rate = 2.20e-03, loss_average = 7.80e-01\n",
      "  validation accuracy: 62.10 (33326 / 53664), f1 (weighted): 62.15, loss: 1.18e+00\n",
      "  time: 894s (wall 1013s)\n",
      "step 165000 / 188418 (epoch 43.79 / 50):\n",
      "  learning_rate = 2.20e-03, loss_average = 8.03e-01\n",
      "  validation accuracy: 62.02 (33283 / 53664), f1 (weighted): 62.04, loss: 1.19e+00\n",
      "  time: 902s (wall 1022s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 166500 / 188418 (epoch 44.18 / 50):\n",
      "  learning_rate = 2.09e-03, loss_average = 8.01e-01\n",
      "  validation accuracy: 62.05 (33297 / 53664), f1 (weighted): 62.04, loss: 1.19e+00\n",
      "  time: 911s (wall 1031s)\n",
      "step 168000 / 188418 (epoch 44.58 / 50):\n",
      "  learning_rate = 2.09e-03, loss_average = 8.12e-01\n",
      "  validation accuracy: 62.22 (33389 / 53664), f1 (weighted): 62.22, loss: 1.18e+00\n",
      "  time: 919s (wall 1041s)\n",
      "step 169500 / 188418 (epoch 44.98 / 50):\n",
      "  learning_rate = 2.09e-03, loss_average = 7.61e-01\n",
      "  validation accuracy: 62.13 (33341 / 53664), f1 (weighted): 62.16, loss: 1.19e+00\n",
      "  time: 927s (wall 1050s)\n",
      "step 171000 / 188418 (epoch 45.38 / 50):\n",
      "  learning_rate = 1.99e-03, loss_average = 7.98e-01\n",
      "  validation accuracy: 61.95 (33243 / 53664), f1 (weighted): 61.94, loss: 1.19e+00\n",
      "  time: 935s (wall 1059s)\n",
      "step 172500 / 188418 (epoch 45.78 / 50):\n",
      "  learning_rate = 1.99e-03, loss_average = 8.31e-01\n",
      "  validation accuracy: 62.16 (33356 / 53664), f1 (weighted): 62.15, loss: 1.18e+00\n",
      "  time: 943s (wall 1068s)\n",
      "step 174000 / 188418 (epoch 46.17 / 50):\n",
      "  learning_rate = 1.89e-03, loss_average = 8.10e-01\n",
      "  validation accuracy: 62.12 (33337 / 53664), f1 (weighted): 62.12, loss: 1.18e+00\n",
      "  time: 951s (wall 1077s)\n",
      "step 175500 / 188418 (epoch 46.57 / 50):\n",
      "  learning_rate = 1.89e-03, loss_average = 7.95e-01\n",
      "  validation accuracy: 62.07 (33310 / 53664), f1 (weighted): 62.09, loss: 1.19e+00\n",
      "  time: 960s (wall 1087s)\n",
      "step 177000 / 188418 (epoch 46.97 / 50):\n",
      "  learning_rate = 1.89e-03, loss_average = 7.80e-01\n",
      "  validation accuracy: 62.19 (33375 / 53664), f1 (weighted): 62.19, loss: 1.19e+00\n",
      "  time: 968s (wall 1096s)\n",
      "step 178500 / 188418 (epoch 47.37 / 50):\n",
      "  learning_rate = 1.79e-03, loss_average = 8.39e-01\n",
      "  validation accuracy: 62.00 (33274 / 53664), f1 (weighted): 62.03, loss: 1.18e+00\n",
      "  time: 976s (wall 1105s)\n",
      "step 180000 / 188418 (epoch 47.77 / 50):\n",
      "  learning_rate = 1.79e-03, loss_average = 8.24e-01\n",
      "  validation accuracy: 62.20 (33381 / 53664), f1 (weighted): 62.22, loss: 1.19e+00\n",
      "  time: 984s (wall 1114s)\n",
      "step 181500 / 188418 (epoch 48.16 / 50):\n",
      "  learning_rate = 1.71e-03, loss_average = 7.73e-01\n",
      "  validation accuracy: 62.09 (33321 / 53664), f1 (weighted): 62.10, loss: 1.19e+00\n",
      "  time: 992s (wall 1124s)\n",
      "step 183000 / 188418 (epoch 48.56 / 50):\n",
      "  learning_rate = 1.71e-03, loss_average = 7.99e-01\n",
      "  validation accuracy: 62.12 (33335 / 53664), f1 (weighted): 62.10, loss: 1.18e+00\n",
      "  time: 1000s (wall 1133s)\n",
      "step 184500 / 188418 (epoch 48.96 / 50):\n",
      "  learning_rate = 1.71e-03, loss_average = 8.19e-01\n",
      "  validation accuracy: 62.01 (33277 / 53664), f1 (weighted): 62.01, loss: 1.19e+00\n",
      "  time: 1009s (wall 1142s)\n",
      "step 186000 / 188418 (epoch 49.36 / 50):\n",
      "  learning_rate = 1.62e-03, loss_average = 8.02e-01\n",
      "  validation accuracy: 62.04 (33295 / 53664), f1 (weighted): 62.05, loss: 1.20e+00\n",
      "  time: 1017s (wall 1152s)\n",
      "step 187500 / 188418 (epoch 49.76 / 50):\n",
      "  learning_rate = 1.62e-03, loss_average = 7.93e-01\n",
      "  validation accuracy: 62.19 (33371 / 53664), f1 (weighted): 62.22, loss: 1.19e+00\n",
      "  time: 1025s (wall 1161s)\n",
      "step 188418 / 188418 (epoch 50.00 / 50):\n",
      "  learning_rate = 1.62e-03, loss_average = 8.03e-01\n",
      "  validation accuracy: 62.08 (33312 / 53664), f1 (weighted): 62.10, loss: 1.19e+00\n",
      "  time: 1031s (wall 1167s)\n",
      "validation accuracy: peak = 62.35, mean = 62.10\n",
      "INFO:tensorflow:Restoring parameters from /scratch/yuzhang/HCP/codes/HCP_fmripredict/cnn_graph/lib/../checkpoints/WMsgconv_sgconv_fc_softmax/model-188418\n",
      "train accuracy: 76.75 (370205 / 482352), f1 (weighted): 76.75, loss: 7.26e-01\n",
      "time: 11s (wall 11s)\n",
      "INFO:tensorflow:Restoring parameters from /scratch/yuzhang/HCP/codes/HCP_fmripredict/cnn_graph/lib/../checkpoints/WMsgconv_sgconv_fc_softmax/model-188418\n",
      "test  accuracy: 62.30 (83580 / 134160), f1 (weighted): 62.31, loss: 1.19e+00\n",
      "time: 4s (wall 4s)\n",
      "\n",
      "\n",
      "\n",
      "Fold #2: training on 482352 samples with 576 features, validating on 53664 samples and testing on 134160 samples\n",
      "NN architecture\n",
      "  input: M_0 = 576\n",
      "  layer 1: cgconv1\n",
      "    representation: M_0 * F_1 / p_1 = 576 * 32 / 4 = 4608\n",
      "    weights: F_0 * F_1 * K_1 = 1 * 32 * 25 = 800\n",
      "    biases: F_1 = 32\n",
      "  layer 2: cgconv2\n",
      "    representation: M_1 * F_2 / p_2 = 144 * 64 / 4 = 2304\n",
      "    weights: F_1 * F_2 * K_2 = 32 * 64 * 25 = 51200\n",
      "    biases: F_2 = 64\n",
      "  layer 3: cgconv3\n",
      "    representation: M_2 * F_3 / p_3 = 36 * 128 / 4 = 1152\n",
      "    weights: F_2 * F_3 * K_3 = 64 * 128 * 25 = 204800\n",
      "    biases: F_3 = 128\n",
      "  layer 4: fc1\n",
      "    representation: M_4 = 256\n",
      "    weights: M_3 * M_4 = 1152 * 256 = 294912\n",
      "    biases: M_4 = 256\n",
      "  layer 5: logits (softmax)\n",
      "    representation: M_5 = 9\n",
      "    weights: M_4 * M_5 = 256 * 9 = 2304\n",
      "    biases: M_5 = 9\n",
      "576 32 1\n",
      "144 64 32\n",
      "36 128 64\n",
      "step 1500 / 188418 (epoch 0.40 / 50):\n",
      "  learning_rate = 2.00e-02, loss_average = 2.48e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yuzhang/tensorflow-py3.6/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  validation accuracy: 17.21 (9233 / 53664), f1 (weighted): 12.35, loss: 2.49e+00\n",
      "  time: 9s (wall 10s)\n",
      "step 3000 / 188418 (epoch 0.80 / 50):\n",
      "  learning_rate = 2.00e-02, loss_average = 1.97e+00\n",
      "  validation accuracy: 41.89 (22479 / 53664), f1 (weighted): 40.82, loss: 1.94e+00\n",
      "  time: 17s (wall 20s)\n",
      "step 4500 / 188418 (epoch 1.19 / 50):\n",
      "  learning_rate = 1.90e-02, loss_average = 1.72e+00\n",
      "  validation accuracy: 48.19 (25861 / 53664), f1 (weighted): 48.29, loss: 1.69e+00\n",
      "  time: 26s (wall 29s)\n",
      "step 6000 / 188418 (epoch 1.59 / 50):\n",
      "  learning_rate = 1.90e-02, loss_average = 1.60e+00\n",
      "  validation accuracy: 52.16 (27989 / 53664), f1 (weighted): 51.98, loss: 1.54e+00\n",
      "  time: 34s (wall 39s)\n",
      "step 7500 / 188418 (epoch 1.99 / 50):\n",
      "  learning_rate = 1.90e-02, loss_average = 1.49e+00\n",
      "  validation accuracy: 54.78 (29397 / 53664), f1 (weighted): 54.93, loss: 1.44e+00\n",
      "  time: 43s (wall 48s)\n",
      "step 9000 / 188418 (epoch 2.39 / 50):\n",
      "  learning_rate = 1.80e-02, loss_average = 1.39e+00\n",
      "  validation accuracy: 56.04 (30072 / 53664), f1 (weighted): 55.98, loss: 1.37e+00\n",
      "  time: 51s (wall 57s)\n",
      "step 10500 / 188418 (epoch 2.79 / 50):\n",
      "  learning_rate = 1.80e-02, loss_average = 1.32e+00\n",
      "  validation accuracy: 57.08 (30631 / 53664), f1 (weighted): 57.05, loss: 1.33e+00\n",
      "  time: 59s (wall 67s)\n",
      "step 12000 / 188418 (epoch 3.18 / 50):\n",
      "  learning_rate = 1.71e-02, loss_average = 1.29e+00\n",
      "  validation accuracy: 57.71 (30970 / 53664), f1 (weighted): 57.83, loss: 1.29e+00\n",
      "  time: 67s (wall 76s)\n",
      "step 13500 / 188418 (epoch 3.58 / 50):\n",
      "  learning_rate = 1.71e-02, loss_average = 1.28e+00\n",
      "  validation accuracy: 58.53 (31411 / 53664), f1 (weighted): 58.58, loss: 1.26e+00\n",
      "  time: 75s (wall 85s)\n",
      "step 15000 / 188418 (epoch 3.98 / 50):\n",
      "  learning_rate = 1.71e-02, loss_average = 1.22e+00\n",
      "  validation accuracy: 59.09 (31711 / 53664), f1 (weighted): 59.16, loss: 1.24e+00\n",
      "  time: 83s (wall 95s)\n",
      "step 16500 / 188418 (epoch 4.38 / 50):\n",
      "  learning_rate = 1.63e-02, loss_average = 1.19e+00\n",
      "  validation accuracy: 59.39 (31872 / 53664), f1 (weighted): 59.41, loss: 1.22e+00\n",
      "  time: 91s (wall 104s)\n",
      "step 18000 / 188418 (epoch 4.78 / 50):\n",
      "  learning_rate = 1.63e-02, loss_average = 1.18e+00\n",
      "  validation accuracy: 59.41 (31881 / 53664), f1 (weighted): 59.39, loss: 1.21e+00\n",
      "  time: 100s (wall 113s)\n",
      "step 19500 / 188418 (epoch 5.17 / 50):\n",
      "  learning_rate = 1.55e-02, loss_average = 1.18e+00\n",
      "  validation accuracy: 59.73 (32051 / 53664), f1 (weighted): 59.77, loss: 1.20e+00\n",
      "  time: 108s (wall 122s)\n",
      "step 21000 / 188418 (epoch 5.57 / 50):\n",
      "  learning_rate = 1.55e-02, loss_average = 1.13e+00\n",
      "  validation accuracy: 60.11 (32258 / 53664), f1 (weighted): 60.14, loss: 1.18e+00\n",
      "  time: 116s (wall 131s)\n",
      "step 22500 / 188418 (epoch 5.97 / 50):\n",
      "  learning_rate = 1.55e-02, loss_average = 1.17e+00\n",
      "  validation accuracy: 59.84 (32114 / 53664), f1 (weighted): 59.97, loss: 1.19e+00\n",
      "  time: 124s (wall 141s)\n",
      "step 24000 / 188418 (epoch 6.37 / 50):\n",
      "  learning_rate = 1.47e-02, loss_average = 1.12e+00\n",
      "  validation accuracy: 60.76 (32605 / 53664), f1 (weighted): 60.70, loss: 1.17e+00\n",
      "  time: 132s (wall 150s)\n",
      "step 25500 / 188418 (epoch 6.77 / 50):\n",
      "  learning_rate = 1.47e-02, loss_average = 1.12e+00\n",
      "  validation accuracy: 60.50 (32466 / 53664), f1 (weighted): 60.43, loss: 1.17e+00\n",
      "  time: 140s (wall 159s)\n",
      "step 27000 / 188418 (epoch 7.16 / 50):\n",
      "  learning_rate = 1.40e-02, loss_average = 1.11e+00\n",
      "  validation accuracy: 60.93 (32695 / 53664), f1 (weighted): 60.96, loss: 1.16e+00\n",
      "  time: 148s (wall 168s)\n",
      "step 28500 / 188418 (epoch 7.56 / 50):\n",
      "  learning_rate = 1.40e-02, loss_average = 1.12e+00\n",
      "  validation accuracy: 60.76 (32605 / 53664), f1 (weighted): 60.81, loss: 1.16e+00\n",
      "  time: 156s (wall 177s)\n",
      "step 30000 / 188418 (epoch 7.96 / 50):\n",
      "  learning_rate = 1.40e-02, loss_average = 1.11e+00\n",
      "  validation accuracy: 61.23 (32861 / 53664), f1 (weighted): 61.22, loss: 1.15e+00\n",
      "  time: 164s (wall 187s)\n",
      "step 31500 / 188418 (epoch 8.36 / 50):\n",
      "  learning_rate = 1.33e-02, loss_average = 1.10e+00\n",
      "  validation accuracy: 61.50 (33004 / 53664), f1 (weighted): 61.45, loss: 1.14e+00\n",
      "  time: 172s (wall 196s)\n",
      "step 33000 / 188418 (epoch 8.76 / 50):\n",
      "  learning_rate = 1.33e-02, loss_average = 1.09e+00\n",
      "  validation accuracy: 61.47 (32987 / 53664), f1 (weighted): 61.48, loss: 1.15e+00\n",
      "  time: 181s (wall 205s)\n",
      "step 34500 / 188418 (epoch 9.16 / 50):\n",
      "  learning_rate = 1.26e-02, loss_average = 1.06e+00\n",
      "  validation accuracy: 61.52 (33012 / 53664), f1 (weighted): 61.51, loss: 1.14e+00\n",
      "  time: 189s (wall 214s)\n",
      "step 36000 / 188418 (epoch 9.55 / 50):\n",
      "  learning_rate = 1.26e-02, loss_average = 1.09e+00\n",
      "  validation accuracy: 61.74 (33132 / 53664), f1 (weighted): 61.81, loss: 1.14e+00\n",
      "  time: 197s (wall 223s)\n",
      "step 37500 / 188418 (epoch 9.95 / 50):\n",
      "  learning_rate = 1.26e-02, loss_average = 1.06e+00\n",
      "  validation accuracy: 61.36 (32930 / 53664), f1 (weighted): 61.39, loss: 1.15e+00\n",
      "  time: 205s (wall 233s)\n",
      "step 39000 / 188418 (epoch 10.35 / 50):\n",
      "  learning_rate = 1.20e-02, loss_average = 1.01e+00\n",
      "  validation accuracy: 61.89 (33214 / 53664), f1 (weighted): 61.91, loss: 1.14e+00\n",
      "  time: 213s (wall 242s)\n",
      "step 40500 / 188418 (epoch 10.75 / 50):\n",
      "  learning_rate = 1.20e-02, loss_average = 1.05e+00\n",
      "  validation accuracy: 61.69 (33104 / 53664), f1 (weighted): 61.67, loss: 1.14e+00\n",
      "  time: 221s (wall 251s)\n",
      "step 42000 / 188418 (epoch 11.15 / 50):\n",
      "  learning_rate = 1.14e-02, loss_average = 1.01e+00\n",
      "  validation accuracy: 62.07 (33307 / 53664), f1 (weighted): 62.06, loss: 1.13e+00\n",
      "  time: 229s (wall 260s)\n",
      "step 43500 / 188418 (epoch 11.54 / 50):\n",
      "  learning_rate = 1.14e-02, loss_average = 1.01e+00\n",
      "  validation accuracy: 61.38 (32938 / 53664), f1 (weighted): 61.33, loss: 1.15e+00\n",
      "  time: 237s (wall 269s)\n",
      "step 45000 / 188418 (epoch 11.94 / 50):\n",
      "  learning_rate = 1.14e-02, loss_average = 1.01e+00\n",
      "  validation accuracy: 62.10 (33323 / 53664), f1 (weighted): 62.12, loss: 1.13e+00\n",
      "  time: 245s (wall 278s)\n",
      "step 46500 / 188418 (epoch 12.34 / 50):\n",
      "  learning_rate = 1.08e-02, loss_average = 1.03e+00\n",
      "  validation accuracy: 62.09 (33321 / 53664), f1 (weighted): 62.08, loss: 1.13e+00\n",
      "  time: 253s (wall 287s)\n",
      "step 48000 / 188418 (epoch 12.74 / 50):\n",
      "  learning_rate = 1.08e-02, loss_average = 1.02e+00\n",
      "  validation accuracy: 61.77 (33150 / 53664), f1 (weighted): 61.91, loss: 1.14e+00\n",
      "  time: 261s (wall 297s)\n",
      "step 49500 / 188418 (epoch 13.14 / 50):\n",
      "  learning_rate = 1.03e-02, loss_average = 1.01e+00\n",
      "  validation accuracy: 61.82 (33177 / 53664), f1 (weighted): 61.81, loss: 1.14e+00\n",
      "  time: 269s (wall 306s)\n",
      "step 51000 / 188418 (epoch 13.53 / 50):\n",
      "  learning_rate = 1.03e-02, loss_average = 1.02e+00\n",
      "  validation accuracy: 62.23 (33394 / 53664), f1 (weighted): 62.28, loss: 1.13e+00\n",
      "  time: 278s (wall 315s)\n",
      "step 52500 / 188418 (epoch 13.93 / 50):\n",
      "  learning_rate = 1.03e-02, loss_average = 1.03e+00\n",
      "  validation accuracy: 61.89 (33215 / 53664), f1 (weighted): 61.90, loss: 1.13e+00\n",
      "  time: 285s (wall 324s)\n",
      "step 54000 / 188418 (epoch 14.33 / 50):\n",
      "  learning_rate = 9.75e-03, loss_average = 9.80e-01\n",
      "  validation accuracy: 62.32 (33442 / 53664), f1 (weighted): 62.32, loss: 1.13e+00\n",
      "  time: 293s (wall 334s)\n",
      "step 55500 / 188418 (epoch 14.73 / 50):\n",
      "  learning_rate = 9.75e-03, loss_average = 1.01e+00\n",
      "  validation accuracy: 62.05 (33296 / 53664), f1 (weighted): 62.02, loss: 1.13e+00\n",
      "  time: 301s (wall 342s)\n",
      "step 57000 / 188418 (epoch 15.13 / 50):\n",
      "  learning_rate = 9.27e-03, loss_average = 9.68e-01\n",
      "  validation accuracy: 61.87 (33202 / 53664), f1 (weighted): 61.81, loss: 1.14e+00\n",
      "  time: 309s (wall 352s)\n",
      "step 58500 / 188418 (epoch 15.52 / 50):\n",
      "  learning_rate = 9.27e-03, loss_average = 9.87e-01\n",
      "  validation accuracy: 62.00 (33269 / 53664), f1 (weighted): 61.97, loss: 1.14e+00\n",
      "  time: 318s (wall 361s)\n",
      "step 60000 / 188418 (epoch 15.92 / 50):\n",
      "  learning_rate = 9.27e-03, loss_average = 1.00e+00\n",
      "  validation accuracy: 62.41 (33493 / 53664), f1 (weighted): 62.45, loss: 1.12e+00\n",
      "  time: 326s (wall 370s)\n",
      "step 61500 / 188418 (epoch 16.32 / 50):\n",
      "  learning_rate = 8.80e-03, loss_average = 9.99e-01\n",
      "  validation accuracy: 62.33 (33449 / 53664), f1 (weighted): 62.32, loss: 1.12e+00\n",
      "  time: 334s (wall 379s)\n",
      "step 63000 / 188418 (epoch 16.72 / 50):\n",
      "  learning_rate = 8.80e-03, loss_average = 9.85e-01\n",
      "  validation accuracy: 62.59 (33587 / 53664), f1 (weighted): 62.60, loss: 1.12e+00\n",
      "  time: 342s (wall 389s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 64500 / 188418 (epoch 17.12 / 50):\n",
      "  learning_rate = 8.36e-03, loss_average = 9.33e-01\n",
      "  validation accuracy: 62.08 (33315 / 53664), f1 (weighted): 62.08, loss: 1.13e+00\n",
      "  time: 350s (wall 398s)\n",
      "step 66000 / 188418 (epoch 17.51 / 50):\n",
      "  learning_rate = 8.36e-03, loss_average = 9.35e-01\n",
      "  validation accuracy: 62.34 (33455 / 53664), f1 (weighted): 62.37, loss: 1.13e+00\n",
      "  time: 358s (wall 407s)\n",
      "step 67500 / 188418 (epoch 17.91 / 50):\n",
      "  learning_rate = 8.36e-03, loss_average = 9.58e-01\n",
      "  validation accuracy: 62.17 (33363 / 53664), f1 (weighted): 62.24, loss: 1.13e+00\n",
      "  time: 366s (wall 416s)\n",
      "step 69000 / 188418 (epoch 18.31 / 50):\n",
      "  learning_rate = 7.94e-03, loss_average = 9.56e-01\n",
      "  validation accuracy: 62.32 (33445 / 53664), f1 (weighted): 62.34, loss: 1.13e+00\n",
      "  time: 375s (wall 426s)\n",
      "step 70500 / 188418 (epoch 18.71 / 50):\n",
      "  learning_rate = 7.94e-03, loss_average = 9.82e-01\n",
      "  validation accuracy: 62.15 (33351 / 53664), f1 (weighted): 62.17, loss: 1.13e+00\n",
      "  time: 382s (wall 435s)\n",
      "step 72000 / 188418 (epoch 19.11 / 50):\n",
      "  learning_rate = 7.55e-03, loss_average = 9.37e-01\n",
      "  validation accuracy: 62.42 (33495 / 53664), f1 (weighted): 62.45, loss: 1.13e+00\n",
      "  time: 390s (wall 444s)\n",
      "step 73500 / 188418 (epoch 19.50 / 50):\n",
      "  learning_rate = 7.55e-03, loss_average = 9.51e-01\n",
      "  validation accuracy: 62.44 (33508 / 53664), f1 (weighted): 62.40, loss: 1.13e+00\n",
      "  time: 398s (wall 453s)\n",
      "step 75000 / 188418 (epoch 19.90 / 50):\n",
      "  learning_rate = 7.55e-03, loss_average = 9.55e-01\n",
      "  validation accuracy: 62.59 (33590 / 53664), f1 (weighted): 62.65, loss: 1.13e+00\n",
      "  time: 406s (wall 462s)\n",
      "step 76500 / 188418 (epoch 20.30 / 50):\n",
      "  learning_rate = 7.17e-03, loss_average = 9.58e-01\n",
      "  validation accuracy: 62.48 (33528 / 53664), f1 (weighted): 62.52, loss: 1.13e+00\n",
      "  time: 415s (wall 471s)\n",
      "step 78000 / 188418 (epoch 20.70 / 50):\n",
      "  learning_rate = 7.17e-03, loss_average = 9.29e-01\n",
      "  validation accuracy: 62.66 (33625 / 53664), f1 (weighted): 62.65, loss: 1.13e+00\n",
      "  time: 423s (wall 481s)\n",
      "step 79500 / 188418 (epoch 21.10 / 50):\n",
      "  learning_rate = 6.81e-03, loss_average = 9.23e-01\n",
      "  validation accuracy: 62.59 (33590 / 53664), f1 (weighted): 62.60, loss: 1.13e+00\n",
      "  time: 431s (wall 490s)\n",
      "step 81000 / 188418 (epoch 21.49 / 50):\n",
      "  learning_rate = 6.81e-03, loss_average = 9.12e-01\n",
      "  validation accuracy: 62.69 (33644 / 53664), f1 (weighted): 62.70, loss: 1.13e+00\n",
      "  time: 439s (wall 499s)\n",
      "step 82500 / 188418 (epoch 21.89 / 50):\n",
      "  learning_rate = 6.81e-03, loss_average = 9.28e-01\n",
      "  validation accuracy: 62.76 (33678 / 53664), f1 (weighted): 62.78, loss: 1.12e+00\n",
      "  time: 447s (wall 508s)\n",
      "step 84000 / 188418 (epoch 22.29 / 50):\n",
      "  learning_rate = 6.47e-03, loss_average = 9.17e-01\n",
      "  validation accuracy: 62.56 (33574 / 53664), f1 (weighted): 62.53, loss: 1.13e+00\n",
      "  time: 455s (wall 517s)\n",
      "step 85500 / 188418 (epoch 22.69 / 50):\n",
      "  learning_rate = 6.47e-03, loss_average = 9.10e-01\n",
      "  validation accuracy: 62.42 (33495 / 53664), f1 (weighted): 62.42, loss: 1.14e+00\n",
      "  time: 463s (wall 527s)\n",
      "step 87000 / 188418 (epoch 23.09 / 50):\n",
      "  learning_rate = 6.15e-03, loss_average = 9.42e-01\n",
      "  validation accuracy: 62.54 (33564 / 53664), f1 (weighted): 62.53, loss: 1.13e+00\n",
      "  time: 472s (wall 536s)\n",
      "step 88500 / 188418 (epoch 23.48 / 50):\n",
      "  learning_rate = 6.15e-03, loss_average = 9.28e-01\n",
      "  validation accuracy: 62.38 (33475 / 53664), f1 (weighted): 62.42, loss: 1.13e+00\n",
      "  time: 479s (wall 545s)\n",
      "step 90000 / 188418 (epoch 23.88 / 50):\n",
      "  learning_rate = 6.15e-03, loss_average = 8.90e-01\n",
      "  validation accuracy: 62.30 (33431 / 53664), f1 (weighted): 62.34, loss: 1.14e+00\n",
      "  time: 487s (wall 554s)\n",
      "step 91500 / 188418 (epoch 24.28 / 50):\n",
      "  learning_rate = 5.84e-03, loss_average = 8.95e-01\n",
      "  validation accuracy: 62.67 (33631 / 53664), f1 (weighted): 62.71, loss: 1.13e+00\n",
      "  time: 495s (wall 563s)\n",
      "step 93000 / 188418 (epoch 24.68 / 50):\n",
      "  learning_rate = 5.84e-03, loss_average = 9.42e-01\n",
      "  validation accuracy: 62.44 (33507 / 53664), f1 (weighted): 62.43, loss: 1.14e+00\n",
      "  time: 503s (wall 572s)\n",
      "step 94500 / 188418 (epoch 25.08 / 50):\n",
      "  learning_rate = 5.55e-03, loss_average = 9.12e-01\n",
      "  validation accuracy: 62.60 (33594 / 53664), f1 (weighted): 62.66, loss: 1.14e+00\n",
      "  time: 512s (wall 582s)\n",
      "step 96000 / 188418 (epoch 25.48 / 50):\n",
      "  learning_rate = 5.55e-03, loss_average = 9.09e-01\n",
      "  validation accuracy: 62.83 (33717 / 53664), f1 (weighted): 62.83, loss: 1.13e+00\n",
      "  time: 520s (wall 591s)\n",
      "step 97500 / 188418 (epoch 25.87 / 50):\n",
      "  learning_rate = 5.55e-03, loss_average = 9.57e-01\n",
      "  validation accuracy: 62.55 (33567 / 53664), f1 (weighted): 62.57, loss: 1.14e+00\n",
      "  time: 528s (wall 600s)\n",
      "step 99000 / 188418 (epoch 26.27 / 50):\n",
      "  learning_rate = 5.27e-03, loss_average = 8.53e-01\n",
      "  validation accuracy: 62.59 (33589 / 53664), f1 (weighted): 62.58, loss: 1.15e+00\n",
      "  time: 536s (wall 609s)\n",
      "step 100500 / 188418 (epoch 26.67 / 50):\n",
      "  learning_rate = 5.27e-03, loss_average = 8.87e-01\n",
      "  validation accuracy: 62.59 (33586 / 53664), f1 (weighted): 62.59, loss: 1.14e+00\n",
      "  time: 544s (wall 618s)\n",
      "step 102000 / 188418 (epoch 27.07 / 50):\n",
      "  learning_rate = 5.01e-03, loss_average = 9.02e-01\n",
      "  validation accuracy: 62.70 (33649 / 53664), f1 (weighted): 62.75, loss: 1.13e+00\n",
      "  time: 552s (wall 627s)\n",
      "step 103500 / 188418 (epoch 27.47 / 50):\n",
      "  learning_rate = 5.01e-03, loss_average = 9.05e-01\n",
      "  validation accuracy: 62.57 (33576 / 53664), f1 (weighted): 62.57, loss: 1.14e+00\n",
      "  time: 560s (wall 637s)\n",
      "step 105000 / 188418 (epoch 27.86 / 50):\n",
      "  learning_rate = 5.01e-03, loss_average = 8.67e-01\n",
      "  validation accuracy: 62.59 (33586 / 53664), f1 (weighted): 62.60, loss: 1.15e+00\n",
      "  time: 568s (wall 646s)\n",
      "step 106500 / 188418 (epoch 28.26 / 50):\n",
      "  learning_rate = 4.76e-03, loss_average = 8.46e-01\n",
      "  validation accuracy: 62.72 (33657 / 53664), f1 (weighted): 62.72, loss: 1.14e+00\n",
      "  time: 576s (wall 655s)\n",
      "step 108000 / 188418 (epoch 28.66 / 50):\n",
      "  learning_rate = 4.76e-03, loss_average = 9.05e-01\n",
      "  validation accuracy: 62.69 (33644 / 53664), f1 (weighted): 62.69, loss: 1.14e+00\n",
      "  time: 584s (wall 664s)\n",
      "step 109500 / 188418 (epoch 29.06 / 50):\n",
      "  learning_rate = 4.52e-03, loss_average = 8.73e-01\n",
      "  validation accuracy: 62.57 (33580 / 53664), f1 (weighted): 62.59, loss: 1.14e+00\n",
      "  time: 592s (wall 674s)\n",
      "step 111000 / 188418 (epoch 29.46 / 50):\n",
      "  learning_rate = 4.52e-03, loss_average = 8.75e-01\n",
      "  validation accuracy: 62.74 (33671 / 53664), f1 (weighted): 62.69, loss: 1.14e+00\n",
      "  time: 601s (wall 683s)\n",
      "step 112500 / 188418 (epoch 29.85 / 50):\n",
      "  learning_rate = 4.52e-03, loss_average = 8.69e-01\n",
      "  validation accuracy: 62.73 (33665 / 53664), f1 (weighted): 62.77, loss: 1.14e+00\n",
      "  time: 609s (wall 692s)\n",
      "step 114000 / 188418 (epoch 30.25 / 50):\n",
      "  learning_rate = 4.29e-03, loss_average = 8.34e-01\n",
      "  validation accuracy: 62.35 (33461 / 53664), f1 (weighted): 62.36, loss: 1.15e+00\n",
      "  time: 617s (wall 701s)\n",
      "step 115500 / 188418 (epoch 30.65 / 50):\n",
      "  learning_rate = 4.29e-03, loss_average = 8.66e-01\n",
      "  validation accuracy: 62.57 (33577 / 53664), f1 (weighted): 62.66, loss: 1.16e+00\n",
      "  time: 625s (wall 710s)\n",
      "step 117000 / 188418 (epoch 31.05 / 50):\n",
      "  learning_rate = 4.08e-03, loss_average = 8.75e-01\n",
      "  validation accuracy: 62.93 (33773 / 53664), f1 (weighted): 62.91, loss: 1.14e+00\n",
      "  time: 633s (wall 720s)\n",
      "step 118500 / 188418 (epoch 31.45 / 50):\n",
      "  learning_rate = 4.08e-03, loss_average = 8.77e-01\n",
      "  validation accuracy: 62.76 (33681 / 53664), f1 (weighted): 62.75, loss: 1.15e+00\n",
      "  time: 641s (wall 729s)\n",
      "step 120000 / 188418 (epoch 31.84 / 50):\n",
      "  learning_rate = 4.08e-03, loss_average = 8.82e-01\n",
      "  validation accuracy: 62.77 (33684 / 53664), f1 (weighted): 62.78, loss: 1.14e+00\n",
      "  time: 649s (wall 738s)\n",
      "step 121500 / 188418 (epoch 32.24 / 50):\n",
      "  learning_rate = 3.87e-03, loss_average = 8.65e-01\n",
      "  validation accuracy: 62.77 (33686 / 53664), f1 (weighted): 62.79, loss: 1.14e+00\n",
      "  time: 657s (wall 747s)\n",
      "step 123000 / 188418 (epoch 32.64 / 50):\n",
      "  learning_rate = 3.87e-03, loss_average = 8.70e-01\n",
      "  validation accuracy: 62.57 (33575 / 53664), f1 (weighted): 62.55, loss: 1.15e+00\n",
      "  time: 665s (wall 756s)\n",
      "step 124500 / 188418 (epoch 33.04 / 50):\n",
      "  learning_rate = 3.68e-03, loss_average = 8.62e-01\n",
      "  validation accuracy: 62.83 (33716 / 53664), f1 (weighted): 62.83, loss: 1.15e+00\n",
      "  time: 673s (wall 766s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 126000 / 188418 (epoch 33.44 / 50):\n",
      "  learning_rate = 3.68e-03, loss_average = 8.33e-01\n",
      "  validation accuracy: 62.62 (33605 / 53664), f1 (weighted): 62.66, loss: 1.15e+00\n",
      "  time: 681s (wall 775s)\n",
      "step 127500 / 188418 (epoch 33.83 / 50):\n",
      "  learning_rate = 3.68e-03, loss_average = 8.74e-01\n",
      "  validation accuracy: 62.83 (33717 / 53664), f1 (weighted): 62.82, loss: 1.15e+00\n",
      "  time: 690s (wall 784s)\n",
      "step 129000 / 188418 (epoch 34.23 / 50):\n",
      "  learning_rate = 3.50e-03, loss_average = 8.63e-01\n",
      "  validation accuracy: 62.82 (33714 / 53664), f1 (weighted): 62.85, loss: 1.15e+00\n",
      "  time: 698s (wall 793s)\n",
      "step 130500 / 188418 (epoch 34.63 / 50):\n",
      "  learning_rate = 3.50e-03, loss_average = 8.43e-01\n",
      "  validation accuracy: 62.69 (33641 / 53664), f1 (weighted): 62.72, loss: 1.15e+00\n",
      "  time: 706s (wall 803s)\n",
      "step 132000 / 188418 (epoch 35.03 / 50):\n",
      "  learning_rate = 3.32e-03, loss_average = 8.58e-01\n",
      "  validation accuracy: 62.58 (33585 / 53664), f1 (weighted): 62.59, loss: 1.16e+00\n",
      "  time: 714s (wall 812s)\n",
      "step 133500 / 188418 (epoch 35.43 / 50):\n",
      "  learning_rate = 3.32e-03, loss_average = 8.98e-01\n",
      "  validation accuracy: 62.81 (33705 / 53664), f1 (weighted): 62.82, loss: 1.15e+00\n",
      "  time: 722s (wall 821s)\n",
      "step 135000 / 188418 (epoch 35.82 / 50):\n",
      "  learning_rate = 3.32e-03, loss_average = 8.47e-01\n",
      "  validation accuracy: 62.75 (33674 / 53664), f1 (weighted): 62.77, loss: 1.16e+00\n",
      "  time: 730s (wall 830s)\n",
      "step 136500 / 188418 (epoch 36.22 / 50):\n",
      "  learning_rate = 3.16e-03, loss_average = 8.51e-01\n",
      "  validation accuracy: 62.72 (33659 / 53664), f1 (weighted): 62.77, loss: 1.15e+00\n",
      "  time: 738s (wall 840s)\n",
      "step 138000 / 188418 (epoch 36.62 / 50):\n",
      "  learning_rate = 3.16e-03, loss_average = 8.43e-01\n",
      "  validation accuracy: 62.68 (33639 / 53664), f1 (weighted): 62.68, loss: 1.15e+00\n",
      "  time: 746s (wall 849s)\n",
      "step 139500 / 188418 (epoch 37.02 / 50):\n",
      "  learning_rate = 3.00e-03, loss_average = 8.10e-01\n",
      "  validation accuracy: 62.73 (33661 / 53664), f1 (weighted): 62.73, loss: 1.16e+00\n",
      "  time: 754s (wall 858s)\n",
      "step 141000 / 188418 (epoch 37.42 / 50):\n",
      "  learning_rate = 3.00e-03, loss_average = 8.50e-01\n",
      "  validation accuracy: 62.72 (33658 / 53664), f1 (weighted): 62.73, loss: 1.16e+00\n",
      "  time: 762s (wall 867s)\n",
      "step 142500 / 188418 (epoch 37.81 / 50):\n",
      "  learning_rate = 3.00e-03, loss_average = 8.14e-01\n",
      "  validation accuracy: 62.67 (33631 / 53664), f1 (weighted): 62.71, loss: 1.16e+00\n",
      "  time: 770s (wall 876s)\n",
      "step 144000 / 188418 (epoch 38.21 / 50):\n",
      "  learning_rate = 2.85e-03, loss_average = 8.06e-01\n",
      "  validation accuracy: 62.70 (33649 / 53664), f1 (weighted): 62.72, loss: 1.16e+00\n",
      "  time: 779s (wall 885s)\n",
      "step 145500 / 188418 (epoch 38.61 / 50):\n",
      "  learning_rate = 2.85e-03, loss_average = 8.27e-01\n",
      "  validation accuracy: 62.63 (33612 / 53664), f1 (weighted): 62.61, loss: 1.16e+00\n",
      "  time: 787s (wall 895s)\n",
      "step 147000 / 188418 (epoch 39.01 / 50):\n",
      "  learning_rate = 2.71e-03, loss_average = 8.52e-01\n",
      "  validation accuracy: 62.59 (33587 / 53664), f1 (weighted): 62.60, loss: 1.16e+00\n",
      "  time: 795s (wall 904s)\n",
      "step 148500 / 188418 (epoch 39.41 / 50):\n",
      "  learning_rate = 2.71e-03, loss_average = 8.52e-01\n",
      "  validation accuracy: 62.80 (33703 / 53664), f1 (weighted): 62.81, loss: 1.15e+00\n",
      "  time: 803s (wall 913s)\n",
      "step 150000 / 188418 (epoch 39.80 / 50):\n",
      "  learning_rate = 2.71e-03, loss_average = 8.44e-01\n",
      "  validation accuracy: 62.76 (33677 / 53664), f1 (weighted): 62.76, loss: 1.15e+00\n",
      "  time: 811s (wall 922s)\n",
      "step 151500 / 188418 (epoch 40.20 / 50):\n",
      "  learning_rate = 2.57e-03, loss_average = 8.04e-01\n",
      "  validation accuracy: 62.67 (33632 / 53664), f1 (weighted): 62.66, loss: 1.16e+00\n",
      "  time: 819s (wall 931s)\n",
      "step 153000 / 188418 (epoch 40.60 / 50):\n",
      "  learning_rate = 2.57e-03, loss_average = 8.28e-01\n",
      "  validation accuracy: 62.77 (33684 / 53664), f1 (weighted): 62.77, loss: 1.17e+00\n",
      "  time: 827s (wall 941s)\n",
      "step 154500 / 188418 (epoch 41.00 / 50):\n",
      "  learning_rate = 2.57e-03, loss_average = 8.34e-01\n",
      "  validation accuracy: 62.66 (33625 / 53664), f1 (weighted): 62.70, loss: 1.16e+00\n",
      "  time: 835s (wall 950s)\n",
      "step 156000 / 188418 (epoch 41.40 / 50):\n",
      "  learning_rate = 2.44e-03, loss_average = 8.24e-01\n",
      "  validation accuracy: 62.79 (33698 / 53664), f1 (weighted): 62.81, loss: 1.17e+00\n",
      "  time: 843s (wall 959s)\n",
      "step 157500 / 188418 (epoch 41.80 / 50):\n",
      "  learning_rate = 2.44e-03, loss_average = 8.06e-01\n",
      "  validation accuracy: 62.82 (33712 / 53664), f1 (weighted): 62.83, loss: 1.17e+00\n",
      "  time: 851s (wall 968s)\n",
      "step 159000 / 188418 (epoch 42.19 / 50):\n",
      "  learning_rate = 2.32e-03, loss_average = 7.92e-01\n",
      "  validation accuracy: 62.66 (33624 / 53664), f1 (weighted): 62.69, loss: 1.15e+00\n",
      "  time: 859s (wall 977s)\n",
      "step 160500 / 188418 (epoch 42.59 / 50):\n",
      "  learning_rate = 2.32e-03, loss_average = 8.64e-01\n",
      "  validation accuracy: 62.55 (33567 / 53664), f1 (weighted): 62.54, loss: 1.16e+00\n",
      "  time: 868s (wall 987s)\n",
      "step 162000 / 188418 (epoch 42.99 / 50):\n",
      "  learning_rate = 2.32e-03, loss_average = 7.73e-01\n",
      "  validation accuracy: 62.56 (33571 / 53664), f1 (weighted): 62.59, loss: 1.17e+00\n",
      "  time: 876s (wall 996s)\n",
      "step 163500 / 188418 (epoch 43.39 / 50):\n",
      "  learning_rate = 2.20e-03, loss_average = 8.09e-01\n",
      "  validation accuracy: 62.92 (33768 / 53664), f1 (weighted): 62.95, loss: 1.16e+00\n",
      "  time: 884s (wall 1005s)\n",
      "step 165000 / 188418 (epoch 43.79 / 50):\n",
      "  learning_rate = 2.20e-03, loss_average = 7.86e-01\n",
      "  validation accuracy: 62.66 (33624 / 53664), f1 (weighted): 62.68, loss: 1.17e+00\n",
      "  time: 892s (wall 1014s)\n",
      "step 166500 / 188418 (epoch 44.18 / 50):\n",
      "  learning_rate = 2.09e-03, loss_average = 8.32e-01\n",
      "  validation accuracy: 62.62 (33605 / 53664), f1 (weighted): 62.63, loss: 1.16e+00\n",
      "  time: 900s (wall 1023s)\n",
      "step 168000 / 188418 (epoch 44.58 / 50):\n",
      "  learning_rate = 2.09e-03, loss_average = 8.02e-01\n",
      "  validation accuracy: 62.67 (33631 / 53664), f1 (weighted): 62.70, loss: 1.17e+00\n",
      "  time: 908s (wall 1032s)\n",
      "step 169500 / 188418 (epoch 44.98 / 50):\n",
      "  learning_rate = 2.09e-03, loss_average = 8.12e-01\n",
      "  validation accuracy: 62.53 (33557 / 53664), f1 (weighted): 62.54, loss: 1.17e+00\n",
      "  time: 916s (wall 1042s)\n",
      "step 171000 / 188418 (epoch 45.38 / 50):\n",
      "  learning_rate = 1.99e-03, loss_average = 8.06e-01\n",
      "  validation accuracy: 62.45 (33512 / 53664), f1 (weighted): 62.46, loss: 1.17e+00\n",
      "  time: 924s (wall 1051s)\n",
      "step 172500 / 188418 (epoch 45.78 / 50):\n",
      "  learning_rate = 1.99e-03, loss_average = 8.17e-01\n",
      "  validation accuracy: 62.52 (33549 / 53664), f1 (weighted): 62.52, loss: 1.18e+00\n",
      "  time: 932s (wall 1060s)\n",
      "step 174000 / 188418 (epoch 46.17 / 50):\n",
      "  learning_rate = 1.89e-03, loss_average = 8.12e-01\n",
      "  validation accuracy: 62.54 (33563 / 53664), f1 (weighted): 62.53, loss: 1.17e+00\n",
      "  time: 940s (wall 1069s)\n",
      "step 175500 / 188418 (epoch 46.57 / 50):\n",
      "  learning_rate = 1.89e-03, loss_average = 8.35e-01\n",
      "  validation accuracy: 62.48 (33530 / 53664), f1 (weighted): 62.51, loss: 1.17e+00\n",
      "  time: 948s (wall 1078s)\n",
      "step 177000 / 188418 (epoch 46.97 / 50):\n",
      "  learning_rate = 1.89e-03, loss_average = 7.95e-01\n",
      "  validation accuracy: 62.63 (33610 / 53664), f1 (weighted): 62.65, loss: 1.17e+00\n",
      "  time: 956s (wall 1087s)\n",
      "step 178500 / 188418 (epoch 47.37 / 50):\n",
      "  learning_rate = 1.79e-03, loss_average = 7.86e-01\n",
      "  validation accuracy: 62.46 (33520 / 53664), f1 (weighted): 62.47, loss: 1.17e+00\n",
      "  time: 964s (wall 1097s)\n",
      "step 180000 / 188418 (epoch 47.77 / 50):\n",
      "  learning_rate = 1.79e-03, loss_average = 7.96e-01\n",
      "  validation accuracy: 62.57 (33580 / 53664), f1 (weighted): 62.59, loss: 1.17e+00\n",
      "  time: 973s (wall 1106s)\n",
      "step 181500 / 188418 (epoch 48.16 / 50):\n",
      "  learning_rate = 1.71e-03, loss_average = 8.02e-01\n",
      "  validation accuracy: 62.57 (33575 / 53664), f1 (weighted): 62.58, loss: 1.18e+00\n",
      "  time: 981s (wall 1115s)\n",
      "step 183000 / 188418 (epoch 48.56 / 50):\n",
      "  learning_rate = 1.71e-03, loss_average = 8.11e-01\n",
      "  validation accuracy: 62.56 (33570 / 53664), f1 (weighted): 62.57, loss: 1.18e+00\n",
      "  time: 989s (wall 1124s)\n",
      "step 184500 / 188418 (epoch 48.96 / 50):\n",
      "  learning_rate = 1.71e-03, loss_average = 7.94e-01\n",
      "  validation accuracy: 62.63 (33611 / 53664), f1 (weighted): 62.61, loss: 1.17e+00\n",
      "  time: 997s (wall 1133s)\n",
      "step 186000 / 188418 (epoch 49.36 / 50):\n",
      "  learning_rate = 1.62e-03, loss_average = 7.95e-01\n",
      "  validation accuracy: 62.35 (33457 / 53664), f1 (weighted): 62.36, loss: 1.18e+00\n",
      "  time: 1005s (wall 1142s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 187500 / 188418 (epoch 49.76 / 50):\n",
      "  learning_rate = 1.62e-03, loss_average = 7.86e-01\n",
      "  validation accuracy: 62.67 (33632 / 53664), f1 (weighted): 62.67, loss: 1.18e+00\n",
      "  time: 1013s (wall 1152s)\n",
      "step 188418 / 188418 (epoch 50.00 / 50):\n",
      "  learning_rate = 1.62e-03, loss_average = 7.75e-01\n",
      "  validation accuracy: 62.55 (33566 / 53664), f1 (weighted): 62.57, loss: 1.18e+00\n",
      "  time: 1019s (wall 1158s)\n",
      "validation accuracy: peak = 62.93, mean = 62.55\n",
      "step 1500 / 188418 (epoch 0.40 / 50):\n",
      "  learning_rate = 2.00e-02, loss_average = 2.43e+00\n",
      "  validation accuracy: 22.75 (12209 / 53664), f1 (weighted): 17.33, loss: 2.43e+00\n",
      "  time: 9s (wall 10s)\n",
      "step 3000 / 188418 (epoch 0.80 / 50):\n",
      "  learning_rate = 2.00e-02, loss_average = 1.94e+00\n",
      "  validation accuracy: 44.78 (24030 / 53664), f1 (weighted): 44.39, loss: 1.87e+00\n",
      "  time: 18s (wall 20s)\n",
      "step 4500 / 188418 (epoch 1.19 / 50):\n",
      "  learning_rate = 1.90e-02, loss_average = 1.70e+00\n",
      "  validation accuracy: 49.98 (26823 / 53664), f1 (weighted): 50.11, loss: 1.66e+00\n",
      "  time: 26s (wall 30s)\n",
      "step 6000 / 188418 (epoch 1.59 / 50):\n",
      "  learning_rate = 1.90e-02, loss_average = 1.57e+00\n",
      "  validation accuracy: 52.82 (28344 / 53664), f1 (weighted): 52.74, loss: 1.53e+00\n",
      "  time: 35s (wall 39s)\n",
      "step 7500 / 188418 (epoch 1.99 / 50):\n",
      "  learning_rate = 1.90e-02, loss_average = 1.42e+00\n",
      "  validation accuracy: 55.08 (29560 / 53664), f1 (weighted): 54.97, loss: 1.43e+00\n",
      "  time: 43s (wall 48s)\n",
      "step 9000 / 188418 (epoch 2.39 / 50):\n",
      "  learning_rate = 1.80e-02, loss_average = 1.41e+00\n",
      "  validation accuracy: 56.17 (30141 / 53664), f1 (weighted): 56.25, loss: 1.37e+00\n",
      "  time: 51s (wall 58s)\n",
      "step 10500 / 188418 (epoch 2.79 / 50):\n",
      "  learning_rate = 1.80e-02, loss_average = 1.30e+00\n",
      "  validation accuracy: 57.50 (30857 / 53664), f1 (weighted): 57.50, loss: 1.31e+00\n",
      "  time: 60s (wall 67s)\n",
      "step 12000 / 188418 (epoch 3.18 / 50):\n",
      "  learning_rate = 1.71e-02, loss_average = 1.30e+00\n",
      "  validation accuracy: 58.14 (31202 / 53664), f1 (weighted): 58.28, loss: 1.28e+00\n",
      "  time: 68s (wall 76s)\n",
      "step 13500 / 188418 (epoch 3.58 / 50):\n",
      "  learning_rate = 1.71e-02, loss_average = 1.27e+00\n",
      "  validation accuracy: 58.42 (31353 / 53664), f1 (weighted): 58.41, loss: 1.26e+00\n",
      "  time: 76s (wall 86s)\n",
      "step 15000 / 188418 (epoch 3.98 / 50):\n",
      "  learning_rate = 1.71e-02, loss_average = 1.21e+00\n",
      "  validation accuracy: 59.19 (31764 / 53664), f1 (weighted): 59.13, loss: 1.23e+00\n",
      "  time: 84s (wall 95s)\n",
      "step 16500 / 188418 (epoch 4.38 / 50):\n",
      "  learning_rate = 1.63e-02, loss_average = 1.20e+00\n",
      "  validation accuracy: 59.37 (31861 / 53664), f1 (weighted): 59.36, loss: 1.22e+00\n",
      "  time: 92s (wall 104s)\n",
      "step 18000 / 188418 (epoch 4.78 / 50):\n",
      "  learning_rate = 1.63e-02, loss_average = 1.18e+00\n",
      "  validation accuracy: 59.90 (32145 / 53664), f1 (weighted): 59.89, loss: 1.20e+00\n",
      "  time: 101s (wall 113s)\n",
      "step 19500 / 188418 (epoch 5.17 / 50):\n",
      "  learning_rate = 1.55e-02, loss_average = 1.17e+00\n",
      "  validation accuracy: 59.99 (32194 / 53664), f1 (weighted): 59.97, loss: 1.19e+00\n",
      "  time: 109s (wall 123s)\n",
      "step 21000 / 188418 (epoch 5.57 / 50):\n",
      "  learning_rate = 1.55e-02, loss_average = 1.17e+00\n",
      "  validation accuracy: 60.27 (32341 / 53664), f1 (weighted): 60.30, loss: 1.18e+00\n",
      "  time: 117s (wall 132s)\n",
      "step 22500 / 188418 (epoch 5.97 / 50):\n",
      "  learning_rate = 1.55e-02, loss_average = 1.17e+00\n",
      "  validation accuracy: 60.04 (32221 / 53664), f1 (weighted): 60.11, loss: 1.18e+00\n",
      "  time: 125s (wall 141s)\n",
      "step 24000 / 188418 (epoch 6.37 / 50):\n",
      "  learning_rate = 1.47e-02, loss_average = 1.13e+00\n",
      "  validation accuracy: 60.72 (32583 / 53664), f1 (weighted): 60.79, loss: 1.17e+00\n",
      "  time: 133s (wall 150s)\n",
      "step 25500 / 188418 (epoch 6.77 / 50):\n",
      "  learning_rate = 1.47e-02, loss_average = 1.12e+00\n",
      "  validation accuracy: 60.52 (32476 / 53664), f1 (weighted): 60.48, loss: 1.17e+00\n",
      "  time: 141s (wall 159s)\n",
      "step 27000 / 188418 (epoch 7.16 / 50):\n",
      "  learning_rate = 1.40e-02, loss_average = 1.08e+00\n",
      "  validation accuracy: 60.78 (32616 / 53664), f1 (weighted): 60.76, loss: 1.16e+00\n",
      "  time: 149s (wall 169s)\n",
      "step 28500 / 188418 (epoch 7.56 / 50):\n",
      "  learning_rate = 1.40e-02, loss_average = 1.08e+00\n",
      "  validation accuracy: 61.21 (32849 / 53664), f1 (weighted): 61.22, loss: 1.15e+00\n",
      "  time: 157s (wall 178s)\n",
      "step 30000 / 188418 (epoch 7.96 / 50):\n",
      "  learning_rate = 1.40e-02, loss_average = 1.06e+00\n",
      "  validation accuracy: 61.17 (32827 / 53664), f1 (weighted): 61.15, loss: 1.15e+00\n",
      "  time: 165s (wall 187s)\n",
      "step 31500 / 188418 (epoch 8.36 / 50):\n",
      "  learning_rate = 1.33e-02, loss_average = 1.11e+00\n",
      "  validation accuracy: 61.12 (32801 / 53664), f1 (weighted): 61.07, loss: 1.15e+00\n",
      "  time: 174s (wall 196s)\n",
      "step 33000 / 188418 (epoch 8.76 / 50):\n",
      "  learning_rate = 1.33e-02, loss_average = 1.09e+00\n",
      "  validation accuracy: 61.65 (33084 / 53664), f1 (weighted): 61.67, loss: 1.14e+00\n",
      "  time: 182s (wall 206s)\n",
      "step 34500 / 188418 (epoch 9.16 / 50):\n",
      "  learning_rate = 1.26e-02, loss_average = 1.09e+00\n",
      "  validation accuracy: 61.72 (33123 / 53664), f1 (weighted): 61.66, loss: 1.14e+00\n",
      "  time: 190s (wall 215s)\n",
      "step 36000 / 188418 (epoch 9.55 / 50):\n",
      "  learning_rate = 1.26e-02, loss_average = 1.08e+00\n",
      "  validation accuracy: 61.62 (33067 / 53664), f1 (weighted): 61.60, loss: 1.14e+00\n",
      "  time: 198s (wall 224s)\n",
      "step 37500 / 188418 (epoch 9.95 / 50):\n",
      "  learning_rate = 1.26e-02, loss_average = 1.06e+00\n",
      "  validation accuracy: 61.89 (33215 / 53664), f1 (weighted): 61.91, loss: 1.13e+00\n",
      "  time: 206s (wall 233s)\n",
      "step 39000 / 188418 (epoch 10.35 / 50):\n",
      "  learning_rate = 1.20e-02, loss_average = 1.05e+00\n",
      "  validation accuracy: 61.86 (33199 / 53664), f1 (weighted): 61.84, loss: 1.14e+00\n",
      "  time: 214s (wall 242s)\n",
      "step 40500 / 188418 (epoch 10.75 / 50):\n",
      "  learning_rate = 1.20e-02, loss_average = 1.06e+00\n",
      "  validation accuracy: 61.56 (33036 / 53664), f1 (weighted): 61.48, loss: 1.14e+00\n",
      "  time: 223s (wall 252s)\n",
      "step 42000 / 188418 (epoch 11.15 / 50):\n",
      "  learning_rate = 1.14e-02, loss_average = 1.02e+00\n",
      "  validation accuracy: 61.66 (33090 / 53664), f1 (weighted): 61.66, loss: 1.14e+00\n",
      "  time: 231s (wall 261s)\n",
      "step 43500 / 188418 (epoch 11.54 / 50):\n",
      "  learning_rate = 1.14e-02, loss_average = 1.03e+00\n",
      "  validation accuracy: 62.03 (33289 / 53664), f1 (weighted): 62.06, loss: 1.14e+00\n",
      "  time: 239s (wall 270s)\n",
      "step 45000 / 188418 (epoch 11.94 / 50):\n",
      "  learning_rate = 1.14e-02, loss_average = 1.05e+00\n",
      "  validation accuracy: 61.84 (33184 / 53664), f1 (weighted): 61.98, loss: 1.14e+00\n",
      "  time: 247s (wall 279s)\n",
      "step 46500 / 188418 (epoch 12.34 / 50):\n",
      "  learning_rate = 1.08e-02, loss_average = 1.01e+00\n",
      "  validation accuracy: 62.20 (33377 / 53664), f1 (weighted): 62.20, loss: 1.13e+00\n",
      "  time: 255s (wall 289s)\n",
      "step 48000 / 188418 (epoch 12.74 / 50):\n",
      "  learning_rate = 1.08e-02, loss_average = 1.06e+00\n",
      "  validation accuracy: 62.14 (33349 / 53664), f1 (weighted): 62.12, loss: 1.13e+00\n",
      "  time: 263s (wall 298s)\n",
      "step 49500 / 188418 (epoch 13.14 / 50):\n",
      "  learning_rate = 1.03e-02, loss_average = 9.91e-01\n",
      "  validation accuracy: 61.86 (33194 / 53664), f1 (weighted): 61.80, loss: 1.14e+00\n",
      "  time: 271s (wall 307s)\n",
      "step 51000 / 188418 (epoch 13.53 / 50):\n",
      "  learning_rate = 1.03e-02, loss_average = 9.84e-01\n",
      "  validation accuracy: 62.31 (33437 / 53664), f1 (weighted): 62.29, loss: 1.13e+00\n",
      "  time: 279s (wall 316s)\n",
      "step 52500 / 188418 (epoch 13.93 / 50):\n",
      "  learning_rate = 1.03e-02, loss_average = 1.05e+00\n",
      "  validation accuracy: 62.16 (33359 / 53664), f1 (weighted): 62.10, loss: 1.14e+00\n",
      "  time: 287s (wall 325s)\n",
      "step 54000 / 188418 (epoch 14.33 / 50):\n",
      "  learning_rate = 9.75e-03, loss_average = 1.02e+00\n",
      "  validation accuracy: 62.42 (33497 / 53664), f1 (weighted): 62.40, loss: 1.13e+00\n",
      "  time: 295s (wall 334s)\n",
      "step 55500 / 188418 (epoch 14.73 / 50):\n",
      "  learning_rate = 9.75e-03, loss_average = 1.01e+00\n",
      "  validation accuracy: 62.41 (33492 / 53664), f1 (weighted): 62.36, loss: 1.12e+00\n",
      "  time: 303s (wall 343s)\n",
      "step 57000 / 188418 (epoch 15.13 / 50):\n",
      "  learning_rate = 9.27e-03, loss_average = 9.50e-01\n",
      "  validation accuracy: 62.54 (33559 / 53664), f1 (weighted): 62.50, loss: 1.13e+00\n",
      "  time: 311s (wall 353s)\n",
      "step 58500 / 188418 (epoch 15.52 / 50):\n",
      "  learning_rate = 9.27e-03, loss_average = 9.94e-01\n",
      "  validation accuracy: 61.91 (33221 / 53664), f1 (weighted): 61.93, loss: 1.14e+00\n",
      "  time: 320s (wall 362s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 60000 / 188418 (epoch 15.92 / 50):\n",
      "  learning_rate = 9.27e-03, loss_average = 9.87e-01\n",
      "  validation accuracy: 62.39 (33483 / 53664), f1 (weighted): 62.39, loss: 1.13e+00\n",
      "  time: 328s (wall 371s)\n",
      "step 61500 / 188418 (epoch 16.32 / 50):\n",
      "  learning_rate = 8.80e-03, loss_average = 9.66e-01\n",
      "  validation accuracy: 62.32 (33441 / 53664), f1 (weighted): 62.32, loss: 1.13e+00\n",
      "  time: 336s (wall 380s)\n",
      "step 63000 / 188418 (epoch 16.72 / 50):\n",
      "  learning_rate = 8.80e-03, loss_average = 9.51e-01\n",
      "  validation accuracy: 62.44 (33509 / 53664), f1 (weighted): 62.45, loss: 1.13e+00\n",
      "  time: 344s (wall 389s)\n",
      "step 64500 / 188418 (epoch 17.12 / 50):\n",
      "  learning_rate = 8.36e-03, loss_average = 9.62e-01\n",
      "  validation accuracy: 62.36 (33467 / 53664), f1 (weighted): 62.35, loss: 1.14e+00\n",
      "  time: 352s (wall 399s)\n",
      "step 66000 / 188418 (epoch 17.51 / 50):\n",
      "  learning_rate = 8.36e-03, loss_average = 9.69e-01\n",
      "  validation accuracy: 62.65 (33618 / 53664), f1 (weighted): 62.66, loss: 1.13e+00\n",
      "  time: 360s (wall 408s)\n",
      "step 67500 / 188418 (epoch 17.91 / 50):\n",
      "  learning_rate = 8.36e-03, loss_average = 9.60e-01\n",
      "  validation accuracy: 62.55 (33567 / 53664), f1 (weighted): 62.52, loss: 1.14e+00\n",
      "  time: 368s (wall 417s)\n",
      "step 69000 / 188418 (epoch 18.31 / 50):\n",
      "  learning_rate = 7.94e-03, loss_average = 9.44e-01\n",
      "  validation accuracy: 62.58 (33585 / 53664), f1 (weighted): 62.60, loss: 1.13e+00\n",
      "  time: 376s (wall 426s)\n",
      "step 70500 / 188418 (epoch 18.71 / 50):\n",
      "  learning_rate = 7.94e-03, loss_average = 9.37e-01\n",
      "  validation accuracy: 62.57 (33577 / 53664), f1 (weighted): 62.53, loss: 1.13e+00\n",
      "  time: 384s (wall 435s)\n",
      "step 72000 / 188418 (epoch 19.11 / 50):\n",
      "  learning_rate = 7.55e-03, loss_average = 9.52e-01\n",
      "  validation accuracy: 62.70 (33649 / 53664), f1 (weighted): 62.69, loss: 1.13e+00\n",
      "  time: 392s (wall 444s)\n",
      "step 73500 / 188418 (epoch 19.50 / 50):\n",
      "  learning_rate = 7.55e-03, loss_average = 9.44e-01\n",
      "  validation accuracy: 62.68 (33636 / 53664), f1 (weighted): 62.66, loss: 1.13e+00\n",
      "  time: 400s (wall 454s)\n",
      "step 75000 / 188418 (epoch 19.90 / 50):\n",
      "  learning_rate = 7.55e-03, loss_average = 9.73e-01\n",
      "  validation accuracy: 62.26 (33409 / 53664), f1 (weighted): 62.22, loss: 1.13e+00\n",
      "  time: 408s (wall 463s)\n",
      "step 76500 / 188418 (epoch 20.30 / 50):\n",
      "  learning_rate = 7.17e-03, loss_average = 9.51e-01\n",
      "  validation accuracy: 62.66 (33624 / 53664), f1 (weighted): 62.67, loss: 1.13e+00\n",
      "  time: 417s (wall 472s)\n",
      "step 78000 / 188418 (epoch 20.70 / 50):\n",
      "  learning_rate = 7.17e-03, loss_average = 9.28e-01\n",
      "  validation accuracy: 62.60 (33591 / 53664), f1 (weighted): 62.57, loss: 1.14e+00\n",
      "  time: 425s (wall 481s)\n",
      "step 79500 / 188418 (epoch 21.10 / 50):\n",
      "  learning_rate = 6.81e-03, loss_average = 9.28e-01\n",
      "  validation accuracy: 62.62 (33606 / 53664), f1 (weighted): 62.63, loss: 1.13e+00\n",
      "  time: 433s (wall 490s)\n",
      "step 81000 / 188418 (epoch 21.49 / 50):\n",
      "  learning_rate = 6.81e-03, loss_average = 9.46e-01\n",
      "  validation accuracy: 62.77 (33684 / 53664), f1 (weighted): 62.78, loss: 1.13e+00\n",
      "  time: 441s (wall 500s)\n",
      "step 82500 / 188418 (epoch 21.89 / 50):\n",
      "  learning_rate = 6.81e-03, loss_average = 9.33e-01\n",
      "  validation accuracy: 62.35 (33459 / 53664), f1 (weighted): 62.36, loss: 1.14e+00\n",
      "  time: 449s (wall 509s)\n",
      "step 84000 / 188418 (epoch 22.29 / 50):\n",
      "  learning_rate = 6.47e-03, loss_average = 9.05e-01\n",
      "  validation accuracy: 62.56 (33570 / 53664), f1 (weighted): 62.52, loss: 1.15e+00\n",
      "  time: 457s (wall 518s)\n",
      "step 85500 / 188418 (epoch 22.69 / 50):\n",
      "  learning_rate = 6.47e-03, loss_average = 9.11e-01\n",
      "  validation accuracy: 62.46 (33518 / 53664), f1 (weighted): 62.38, loss: 1.14e+00\n",
      "  time: 465s (wall 527s)\n",
      "step 87000 / 188418 (epoch 23.09 / 50):\n",
      "  learning_rate = 6.15e-03, loss_average = 8.96e-01\n",
      "  validation accuracy: 62.27 (33416 / 53664), f1 (weighted): 62.32, loss: 1.15e+00\n",
      "  time: 473s (wall 536s)\n",
      "step 88500 / 188418 (epoch 23.48 / 50):\n",
      "  learning_rate = 6.15e-03, loss_average = 9.17e-01\n",
      "  validation accuracy: 62.33 (33448 / 53664), f1 (weighted): 62.27, loss: 1.15e+00\n",
      "  time: 481s (wall 545s)\n",
      "step 90000 / 188418 (epoch 23.88 / 50):\n",
      "  learning_rate = 6.15e-03, loss_average = 8.97e-01\n",
      "  validation accuracy: 62.73 (33664 / 53664), f1 (weighted): 62.71, loss: 1.13e+00\n",
      "  time: 489s (wall 554s)\n",
      "step 91500 / 188418 (epoch 24.28 / 50):\n",
      "  learning_rate = 5.84e-03, loss_average = 9.39e-01\n",
      "  validation accuracy: 62.70 (33646 / 53664), f1 (weighted): 62.67, loss: 1.14e+00\n",
      "  time: 497s (wall 564s)\n",
      "step 93000 / 188418 (epoch 24.68 / 50):\n",
      "  learning_rate = 5.84e-03, loss_average = 9.21e-01\n",
      "  validation accuracy: 62.54 (33564 / 53664), f1 (weighted): 62.59, loss: 1.14e+00\n",
      "  time: 505s (wall 573s)\n",
      "step 94500 / 188418 (epoch 25.08 / 50):\n",
      "  learning_rate = 5.55e-03, loss_average = 8.61e-01\n",
      "  validation accuracy: 62.79 (33693 / 53664), f1 (weighted): 62.81, loss: 1.14e+00\n",
      "  time: 514s (wall 582s)\n",
      "step 96000 / 188418 (epoch 25.48 / 50):\n",
      "  learning_rate = 5.55e-03, loss_average = 9.30e-01\n",
      "  validation accuracy: 62.57 (33579 / 53664), f1 (weighted): 62.64, loss: 1.14e+00\n",
      "  time: 522s (wall 591s)\n",
      "step 97500 / 188418 (epoch 25.87 / 50):\n",
      "  learning_rate = 5.55e-03, loss_average = 9.07e-01\n",
      "  validation accuracy: 62.53 (33554 / 53664), f1 (weighted): 62.54, loss: 1.14e+00\n",
      "  time: 530s (wall 601s)\n",
      "step 99000 / 188418 (epoch 26.27 / 50):\n",
      "  learning_rate = 5.27e-03, loss_average = 8.83e-01\n",
      "  validation accuracy: 62.32 (33443 / 53664), f1 (weighted): 62.32, loss: 1.16e+00\n",
      "  time: 538s (wall 610s)\n",
      "step 100500 / 188418 (epoch 26.67 / 50):\n",
      "  learning_rate = 5.27e-03, loss_average = 9.06e-01\n",
      "  validation accuracy: 62.68 (33635 / 53664), f1 (weighted): 62.66, loss: 1.14e+00\n",
      "  time: 546s (wall 619s)\n",
      "step 102000 / 188418 (epoch 27.07 / 50):\n",
      "  learning_rate = 5.01e-03, loss_average = 8.69e-01\n",
      "  validation accuracy: 62.27 (33414 / 53664), f1 (weighted): 62.34, loss: 1.15e+00\n",
      "  time: 554s (wall 628s)\n",
      "step 103500 / 188418 (epoch 27.47 / 50):\n",
      "  learning_rate = 5.01e-03, loss_average = 8.76e-01\n",
      "  validation accuracy: 62.77 (33686 / 53664), f1 (weighted): 62.78, loss: 1.14e+00\n",
      "  time: 562s (wall 638s)\n",
      "step 105000 / 188418 (epoch 27.86 / 50):\n",
      "  learning_rate = 5.01e-03, loss_average = 9.22e-01\n",
      "  validation accuracy: 62.45 (33511 / 53664), f1 (weighted): 62.41, loss: 1.14e+00\n",
      "  time: 570s (wall 647s)\n",
      "step 106500 / 188418 (epoch 28.26 / 50):\n",
      "  learning_rate = 4.76e-03, loss_average = 8.66e-01\n",
      "  validation accuracy: 62.56 (33574 / 53664), f1 (weighted): 62.51, loss: 1.15e+00\n",
      "  time: 578s (wall 656s)\n",
      "step 108000 / 188418 (epoch 28.66 / 50):\n",
      "  learning_rate = 4.76e-03, loss_average = 8.52e-01\n",
      "  validation accuracy: 62.42 (33498 / 53664), f1 (weighted): 62.39, loss: 1.15e+00\n",
      "  time: 586s (wall 665s)\n",
      "step 109500 / 188418 (epoch 29.06 / 50):\n",
      "  learning_rate = 4.52e-03, loss_average = 8.80e-01\n",
      "  validation accuracy: 62.36 (33465 / 53664), f1 (weighted): 62.42, loss: 1.15e+00\n",
      "  time: 594s (wall 674s)\n",
      "step 111000 / 188418 (epoch 29.46 / 50):\n",
      "  learning_rate = 4.52e-03, loss_average = 8.56e-01\n",
      "  validation accuracy: 62.59 (33586 / 53664), f1 (weighted): 62.60, loss: 1.14e+00\n",
      "  time: 603s (wall 683s)\n",
      "step 112500 / 188418 (epoch 29.85 / 50):\n",
      "  learning_rate = 4.52e-03, loss_average = 8.75e-01\n",
      "  validation accuracy: 62.61 (33599 / 53664), f1 (weighted): 62.60, loss: 1.14e+00\n",
      "  time: 611s (wall 693s)\n",
      "step 114000 / 188418 (epoch 30.25 / 50):\n",
      "  learning_rate = 4.29e-03, loss_average = 8.75e-01\n",
      "  validation accuracy: 62.19 (33372 / 53664), f1 (weighted): 62.18, loss: 1.15e+00\n",
      "  time: 619s (wall 702s)\n",
      "step 115500 / 188418 (epoch 30.65 / 50):\n",
      "  learning_rate = 4.29e-03, loss_average = 8.75e-01\n",
      "  validation accuracy: 62.42 (33495 / 53664), f1 (weighted): 62.43, loss: 1.15e+00\n",
      "  time: 627s (wall 711s)\n",
      "step 117000 / 188418 (epoch 31.05 / 50):\n",
      "  learning_rate = 4.08e-03, loss_average = 8.57e-01\n",
      "  validation accuracy: 62.49 (33536 / 53664), f1 (weighted): 62.45, loss: 1.15e+00\n",
      "  time: 635s (wall 720s)\n",
      "step 118500 / 188418 (epoch 31.45 / 50):\n",
      "  learning_rate = 4.08e-03, loss_average = 8.26e-01\n",
      "  validation accuracy: 62.46 (33519 / 53664), f1 (weighted): 62.48, loss: 1.15e+00\n",
      "  time: 643s (wall 729s)\n",
      "step 120000 / 188418 (epoch 31.84 / 50):\n",
      "  learning_rate = 4.08e-03, loss_average = 8.64e-01\n",
      "  validation accuracy: 62.58 (33582 / 53664), f1 (weighted): 62.57, loss: 1.15e+00\n",
      "  time: 651s (wall 739s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 121500 / 188418 (epoch 32.24 / 50):\n",
      "  learning_rate = 3.87e-03, loss_average = 8.68e-01\n",
      "  validation accuracy: 62.44 (33506 / 53664), f1 (weighted): 62.39, loss: 1.15e+00\n",
      "  time: 659s (wall 748s)\n",
      "step 123000 / 188418 (epoch 32.64 / 50):\n",
      "  learning_rate = 3.87e-03, loss_average = 8.65e-01\n",
      "  validation accuracy: 62.36 (33465 / 53664), f1 (weighted): 62.36, loss: 1.15e+00\n",
      "  time: 667s (wall 757s)\n",
      "step 124500 / 188418 (epoch 33.04 / 50):\n",
      "  learning_rate = 3.68e-03, loss_average = 8.42e-01\n",
      "  validation accuracy: 62.51 (33547 / 53664), f1 (weighted): 62.54, loss: 1.16e+00\n",
      "  time: 675s (wall 766s)\n",
      "step 126000 / 188418 (epoch 33.44 / 50):\n",
      "  learning_rate = 3.68e-03, loss_average = 8.45e-01\n",
      "  validation accuracy: 62.29 (33426 / 53664), f1 (weighted): 62.30, loss: 1.17e+00\n",
      "  time: 683s (wall 775s)\n",
      "step 127500 / 188418 (epoch 33.83 / 50):\n",
      "  learning_rate = 3.68e-03, loss_average = 8.44e-01\n",
      "  validation accuracy: 62.24 (33400 / 53664), f1 (weighted): 62.18, loss: 1.16e+00\n",
      "  time: 691s (wall 784s)\n",
      "step 129000 / 188418 (epoch 34.23 / 50):\n",
      "  learning_rate = 3.50e-03, loss_average = 8.16e-01\n",
      "  validation accuracy: 62.43 (33500 / 53664), f1 (weighted): 62.41, loss: 1.16e+00\n",
      "  time: 700s (wall 794s)\n",
      "step 130500 / 188418 (epoch 34.63 / 50):\n",
      "  learning_rate = 3.50e-03, loss_average = 8.80e-01\n",
      "  validation accuracy: 62.52 (33549 / 53664), f1 (weighted): 62.52, loss: 1.15e+00\n",
      "  time: 708s (wall 803s)\n",
      "step 132000 / 188418 (epoch 35.03 / 50):\n",
      "  learning_rate = 3.32e-03, loss_average = 8.42e-01\n",
      "  validation accuracy: 62.45 (33513 / 53664), f1 (weighted): 62.46, loss: 1.15e+00\n",
      "  time: 716s (wall 812s)\n",
      "step 133500 / 188418 (epoch 35.43 / 50):\n",
      "  learning_rate = 3.32e-03, loss_average = 8.32e-01\n",
      "  validation accuracy: 62.48 (33527 / 53664), f1 (weighted): 62.49, loss: 1.15e+00\n",
      "  time: 724s (wall 821s)\n",
      "step 135000 / 188418 (epoch 35.82 / 50):\n",
      "  learning_rate = 3.32e-03, loss_average = 8.30e-01\n",
      "  validation accuracy: 62.58 (33583 / 53664), f1 (weighted): 62.56, loss: 1.16e+00\n",
      "  time: 732s (wall 830s)\n",
      "step 136500 / 188418 (epoch 36.22 / 50):\n",
      "  learning_rate = 3.16e-03, loss_average = 8.61e-01\n",
      "  validation accuracy: 62.23 (33397 / 53664), f1 (weighted): 62.20, loss: 1.16e+00\n",
      "  time: 740s (wall 839s)\n",
      "step 138000 / 188418 (epoch 36.62 / 50):\n",
      "  learning_rate = 3.16e-03, loss_average = 8.60e-01\n",
      "  validation accuracy: 62.50 (33538 / 53664), f1 (weighted): 62.52, loss: 1.15e+00\n",
      "  time: 748s (wall 849s)\n",
      "step 139500 / 188418 (epoch 37.02 / 50):\n",
      "  learning_rate = 3.00e-03, loss_average = 8.63e-01\n",
      "  validation accuracy: 62.45 (33512 / 53664), f1 (weighted): 62.46, loss: 1.16e+00\n",
      "  time: 757s (wall 858s)\n",
      "step 141000 / 188418 (epoch 37.42 / 50):\n",
      "  learning_rate = 3.00e-03, loss_average = 8.31e-01\n",
      "  validation accuracy: 62.20 (33380 / 53664), f1 (weighted): 62.18, loss: 1.16e+00\n",
      "  time: 765s (wall 867s)\n",
      "step 142500 / 188418 (epoch 37.81 / 50):\n",
      "  learning_rate = 3.00e-03, loss_average = 8.76e-01\n",
      "  validation accuracy: 62.38 (33477 / 53664), f1 (weighted): 62.36, loss: 1.16e+00\n",
      "  time: 772s (wall 876s)\n",
      "step 144000 / 188418 (epoch 38.21 / 50):\n",
      "  learning_rate = 2.85e-03, loss_average = 8.23e-01\n",
      "  validation accuracy: 62.48 (33527 / 53664), f1 (weighted): 62.47, loss: 1.16e+00\n",
      "  time: 781s (wall 886s)\n",
      "step 145500 / 188418 (epoch 38.61 / 50):\n",
      "  learning_rate = 2.85e-03, loss_average = 8.41e-01\n",
      "  validation accuracy: 62.29 (33427 / 53664), f1 (weighted): 62.26, loss: 1.17e+00\n",
      "  time: 789s (wall 895s)\n",
      "step 147000 / 188418 (epoch 39.01 / 50):\n",
      "  learning_rate = 2.71e-03, loss_average = 8.40e-01\n",
      "  validation accuracy: 62.22 (33388 / 53664), f1 (weighted): 62.26, loss: 1.17e+00\n",
      "  time: 797s (wall 904s)\n",
      "step 148500 / 188418 (epoch 39.41 / 50):\n",
      "  learning_rate = 2.71e-03, loss_average = 8.34e-01\n",
      "  validation accuracy: 62.33 (33451 / 53664), f1 (weighted): 62.37, loss: 1.16e+00\n",
      "  time: 805s (wall 913s)\n",
      "step 150000 / 188418 (epoch 39.80 / 50):\n",
      "  learning_rate = 2.71e-03, loss_average = 8.23e-01\n",
      "  validation accuracy: 62.24 (33401 / 53664), f1 (weighted): 62.24, loss: 1.17e+00\n",
      "  time: 813s (wall 922s)\n",
      "step 151500 / 188418 (epoch 40.20 / 50):\n",
      "  learning_rate = 2.57e-03, loss_average = 8.15e-01\n",
      "  validation accuracy: 62.08 (33313 / 53664), f1 (weighted): 62.05, loss: 1.18e+00\n",
      "  time: 821s (wall 931s)\n",
      "step 153000 / 188418 (epoch 40.60 / 50):\n",
      "  learning_rate = 2.57e-03, loss_average = 8.15e-01\n",
      "  validation accuracy: 62.34 (33456 / 53664), f1 (weighted): 62.33, loss: 1.18e+00\n",
      "  time: 829s (wall 940s)\n",
      "step 154500 / 188418 (epoch 41.00 / 50):\n",
      "  learning_rate = 2.57e-03, loss_average = 8.42e-01\n",
      "  validation accuracy: 62.38 (33474 / 53664), f1 (weighted): 62.33, loss: 1.17e+00\n",
      "  time: 837s (wall 950s)\n",
      "step 156000 / 188418 (epoch 41.40 / 50):\n",
      "  learning_rate = 2.44e-03, loss_average = 7.88e-01\n",
      "  validation accuracy: 62.15 (33354 / 53664), f1 (weighted): 62.16, loss: 1.18e+00\n",
      "  time: 845s (wall 959s)\n",
      "step 157500 / 188418 (epoch 41.80 / 50):\n",
      "  learning_rate = 2.44e-03, loss_average = 8.33e-01\n",
      "  validation accuracy: 62.35 (33462 / 53664), f1 (weighted): 62.38, loss: 1.17e+00\n",
      "  time: 853s (wall 968s)\n",
      "step 159000 / 188418 (epoch 42.19 / 50):\n",
      "  learning_rate = 2.32e-03, loss_average = 7.75e-01\n",
      "  validation accuracy: 62.26 (33411 / 53664), f1 (weighted): 62.26, loss: 1.19e+00\n",
      "  time: 861s (wall 977s)\n",
      "step 160500 / 188418 (epoch 42.59 / 50):\n",
      "  learning_rate = 2.32e-03, loss_average = 7.98e-01\n",
      "  validation accuracy: 62.26 (33411 / 53664), f1 (weighted): 62.26, loss: 1.18e+00\n",
      "  time: 869s (wall 986s)\n",
      "step 162000 / 188418 (epoch 42.99 / 50):\n",
      "  learning_rate = 2.32e-03, loss_average = 8.50e-01\n",
      "  validation accuracy: 62.14 (33348 / 53664), f1 (weighted): 62.12, loss: 1.17e+00\n",
      "  time: 877s (wall 996s)\n",
      "step 163500 / 188418 (epoch 43.39 / 50):\n",
      "  learning_rate = 2.20e-03, loss_average = 7.93e-01\n",
      "  validation accuracy: 62.32 (33441 / 53664), f1 (weighted): 62.29, loss: 1.18e+00\n",
      "  time: 886s (wall 1005s)\n",
      "step 165000 / 188418 (epoch 43.79 / 50):\n",
      "  learning_rate = 2.20e-03, loss_average = 7.79e-01\n",
      "  validation accuracy: 62.21 (33383 / 53664), f1 (weighted): 62.20, loss: 1.18e+00\n",
      "  time: 894s (wall 1014s)\n",
      "step 166500 / 188418 (epoch 44.18 / 50):\n",
      "  learning_rate = 2.09e-03, loss_average = 7.99e-01\n",
      "  validation accuracy: 62.43 (33505 / 53664), f1 (weighted): 62.44, loss: 1.18e+00\n",
      "  time: 902s (wall 1023s)\n",
      "step 168000 / 188418 (epoch 44.58 / 50):\n",
      "  learning_rate = 2.09e-03, loss_average = 7.57e-01\n",
      "  validation accuracy: 62.45 (33513 / 53664), f1 (weighted): 62.43, loss: 1.19e+00\n",
      "  time: 910s (wall 1033s)\n",
      "step 169500 / 188418 (epoch 44.98 / 50):\n",
      "  learning_rate = 2.09e-03, loss_average = 8.38e-01\n",
      "  validation accuracy: 62.19 (33375 / 53664), f1 (weighted): 62.18, loss: 1.18e+00\n",
      "  time: 918s (wall 1042s)\n",
      "step 171000 / 188418 (epoch 45.38 / 50):\n",
      "  learning_rate = 1.99e-03, loss_average = 7.90e-01\n",
      "  validation accuracy: 62.38 (33477 / 53664), f1 (weighted): 62.40, loss: 1.17e+00\n",
      "  time: 926s (wall 1051s)\n",
      "step 172500 / 188418 (epoch 45.78 / 50):\n",
      "  learning_rate = 1.99e-03, loss_average = 7.64e-01\n",
      "  validation accuracy: 62.18 (33367 / 53664), f1 (weighted): 62.19, loss: 1.17e+00\n",
      "  time: 934s (wall 1060s)\n",
      "step 174000 / 188418 (epoch 46.17 / 50):\n",
      "  learning_rate = 1.89e-03, loss_average = 8.12e-01\n",
      "  validation accuracy: 62.10 (33325 / 53664), f1 (weighted): 62.08, loss: 1.19e+00\n",
      "  time: 943s (wall 1069s)\n",
      "step 175500 / 188418 (epoch 46.57 / 50):\n",
      "  learning_rate = 1.89e-03, loss_average = 8.28e-01\n",
      "  validation accuracy: 62.23 (33397 / 53664), f1 (weighted): 62.19, loss: 1.18e+00\n",
      "  time: 951s (wall 1079s)\n",
      "step 177000 / 188418 (epoch 46.97 / 50):\n",
      "  learning_rate = 1.89e-03, loss_average = 8.23e-01\n",
      "  validation accuracy: 62.26 (33412 / 53664), f1 (weighted): 62.28, loss: 1.18e+00\n",
      "  time: 959s (wall 1088s)\n",
      "step 178500 / 188418 (epoch 47.37 / 50):\n",
      "  learning_rate = 1.79e-03, loss_average = 7.86e-01\n",
      "  validation accuracy: 62.21 (33384 / 53664), f1 (weighted): 62.21, loss: 1.18e+00\n",
      "  time: 967s (wall 1097s)\n",
      "step 180000 / 188418 (epoch 47.77 / 50):\n",
      "  learning_rate = 1.79e-03, loss_average = 8.06e-01\n",
      "  validation accuracy: 62.21 (33386 / 53664), f1 (weighted): 62.25, loss: 1.19e+00\n",
      "  time: 975s (wall 1106s)\n",
      "step 181500 / 188418 (epoch 48.16 / 50):\n",
      "  learning_rate = 1.71e-03, loss_average = 7.94e-01\n",
      "  validation accuracy: 62.33 (33449 / 53664), f1 (weighted): 62.30, loss: 1.18e+00\n",
      "  time: 983s (wall 1115s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 183000 / 188418 (epoch 48.56 / 50):\n",
      "  learning_rate = 1.71e-03, loss_average = 8.09e-01\n",
      "  validation accuracy: 62.30 (33435 / 53664), f1 (weighted): 62.31, loss: 1.18e+00\n",
      "  time: 991s (wall 1124s)\n",
      "step 184500 / 188418 (epoch 48.96 / 50):\n",
      "  learning_rate = 1.71e-03, loss_average = 7.79e-01\n",
      "  validation accuracy: 62.18 (33370 / 53664), f1 (weighted): 62.14, loss: 1.19e+00\n",
      "  time: 999s (wall 1134s)\n",
      "step 186000 / 188418 (epoch 49.36 / 50):\n",
      "  learning_rate = 1.62e-03, loss_average = 7.98e-01\n",
      "  validation accuracy: 62.21 (33384 / 53664), f1 (weighted): 62.24, loss: 1.18e+00\n",
      "  time: 1007s (wall 1143s)\n",
      "step 187500 / 188418 (epoch 49.76 / 50):\n",
      "  learning_rate = 1.62e-03, loss_average = 8.12e-01\n",
      "  validation accuracy: 62.06 (33305 / 53664), f1 (weighted): 62.03, loss: 1.19e+00\n",
      "  time: 1015s (wall 1152s)\n",
      "step 188418 / 188418 (epoch 50.00 / 50):\n",
      "  learning_rate = 1.62e-03, loss_average = 7.95e-01\n",
      "  validation accuracy: 62.12 (33338 / 53664), f1 (weighted): 62.12, loss: 1.19e+00\n",
      "  time: 1021s (wall 1158s)\n",
      "validation accuracy: peak = 62.79, mean = 62.21\n",
      "INFO:tensorflow:Restoring parameters from /scratch/yuzhang/HCP/codes/HCP_fmripredict/cnn_graph/lib/../checkpoints/WMsgconv_sgconv_fc_softmax/model-188418\n",
      "train accuracy: 76.67 (369797 / 482352), f1 (weighted): 76.66, loss: 7.31e-01\n",
      "time: 11s (wall 11s)\n",
      "INFO:tensorflow:Restoring parameters from /scratch/yuzhang/HCP/codes/HCP_fmripredict/cnn_graph/lib/../checkpoints/WMsgconv_sgconv_fc_softmax/model-188418\n",
      "test  accuracy: 62.28 (83561 / 134160), f1 (weighted): 62.28, loss: 1.18e+00\n",
      "time: 4s (wall 4s)\n",
      "\n",
      "\n",
      "Accuracy of training:76.70767406375427,testing:62.29166666666666\n",
      "Accuracy of validation: [62.34719738 62.78510733]\n",
      " mean=62.566152\n",
      "[[27.80635062611807, 44.66122540250447, 49.09622838401908, 51.61001788908766, 54.300834824090636, 56.06179189028027, 56.30776684555754, 56.41398330351819, 57.64758497316637, 58.133944543828264, 58.773106738223014, 58.38923673225999, 58.69297853309481, 59.455128205128204, 59.69178592725104, 60.1036076326774, 60.043977340488965, 60.196779964221825, 60.19305307096005, 60.343992248062015, 60.621645796064406, 60.82289803220036, 60.929114490161005, 60.92725104353012, 60.89557245080501, 61.048375074537866, 61.171362552176504, 60.89370900417413, 61.53473464519976, 61.186270125223615, 61.30925760286225, 61.376341681574246, 61.25708109719737, 61.421064400715565, 61.47324090638045, 61.57386702444841, 61.67635658914728, 61.63722420989863, 61.74530411449016, 61.68194692903995, 61.724806201550386, 61.5440518783542, 61.90556052474657, 62.041592128801426, 61.82170542635659, 61.81238819320215, 61.87947227191414, 61.935375670840784, 61.724806201550386, 62.01736732259988, 62.20371198568873, 61.948419797257, 62.0136404293381, 62.00245974955278, 61.79934406678592, 61.86456469886702, 62.1124031007752, 62.097495527728086, 62.207438878950505, 62.07513416815742, 62.00432319618366, 62.037865235539655, 62.1440816935003, 62.03600178890877, 62.157125819916516, 62.07699761478831, 62.23911747167561, 62.226073345259394, 61.87760882528325, 61.847793679189024, 61.87015503875969, 62.1124031007752, 61.788163387000594, 61.95960047704234, 62.047182468694096, 61.90742397137746, 62.3062015503876, 61.87947227191414, 61.81797853309481, 62.142218246869405, 61.76207513416816, 61.987552176505666, 62.01736732259988, 61.98568872987478, 62.18135062611807, 62.08072450805009, 62.000596302921885, 62.18135062611807, 62.006186642814555, 62.213029218843175, 61.97637149672034, 62.07140727489565, 62.03972868217055, 62.09935897435898, 61.82915921288015, 61.95960047704234, 61.9167412045319, 62.06768038163387, 61.74716756112105, 62.000596302921885, 61.93723911747168, 62.05277280858677, 61.94282945736435, 61.68008348240907, 61.858974358974365, 61.9335122242099, 61.991279069767444, 61.72107930828861, 61.91115086463924, 62.08072450805009, 62.10122242098986, 61.819841979725695, 61.80679785330948, 61.84965712581991, 61.87760882528325, 61.83847644603458, 61.79561717352415, 61.86083780560525, 61.97823494335122, 61.99873285629099, 61.991279069767444, 61.87760882528325, 61.903697078115684, 61.75834824090638, 61.79561717352415, 62.1124031007752], [17.205202742993443, 41.888416815742396, 48.19059332140728, 52.156007751937985, 54.77974060822898, 56.03756708407871, 57.07923375074538, 57.710942158616575, 58.5327221228384, 59.09175611210495, 59.391771019677996, 59.40854203935599, 59.72532796660703, 60.11106141920095, 59.842725104353015, 60.757677400119256, 60.498658318425754, 60.92538759689923, 60.757677400119256, 61.23471973762672, 61.50119260584377, 61.46951401311866, 61.51610017889087, 61.73971377459749, 61.36329755515803, 61.89251639833036, 61.687537268932616, 62.065816935002985, 61.37820512820513, 62.09563208109719, 62.091905187835415, 61.77325581395349, 61.82356887298748, 62.22793679189028, 61.89437984496124, 62.317382230172925, 62.045319022063204, 61.87015503875969, 61.995005963029215, 62.41241800834823, 62.33042635658915, 62.58758199165177, 62.08072450805009, 62.341607036374484, 62.170169946332734, 62.322972570065595, 62.147808586762075, 62.41614490161002, 62.44036970781157, 62.59317233154442, 62.47763864042933, 62.658392963625516, 62.59317233154442, 62.6937984496124, 62.75715563506261, 62.56335718545021, 62.41614490161002, 62.54472271914132, 62.378875968992254, 62.29688431723316, 62.66957364341085, 62.438506261180684, 62.60062611806798, 62.829830053667266, 62.55031305903399, 62.59130888491353, 62.585718545020875, 62.70311568276684, 62.567084078711986, 62.585718545020875, 62.71802325581395, 62.6937984496124, 62.574537865235534, 62.74411150864639, 62.732930828861065, 62.35278771615981, 62.56894752534288, 62.934183064997015, 62.76274597495528, 62.768336314847936, 62.77206320810972, 62.5652206320811, 62.82796660703638, 62.621124031007746, 62.829830053667266, 62.8242397137746, 62.68820810971973, 62.58385509838998, 62.8074686940966, 62.749701848539054, 62.72175014907573, 62.68448121645797, 62.72547704233751, 62.71988670244484, 62.66957364341085, 62.70311568276684, 62.63416815742397, 62.58758199165177, 62.80374180083482, 62.755292188431724, 62.671437090041735, 62.768336314847936, 62.658392963625516, 62.79442456768039, 62.82051282051282, 62.65652951699463, 62.55031305903399, 62.55776684555754, 62.92486583184258, 62.65652951699463, 62.621124031007746, 62.66957364341085, 62.5316785927251, 62.44782349433512, 62.516771019677996, 62.542859272510434, 62.48136553369111, 62.630441264162194, 62.46273106738223, 62.574537865235534, 62.5652206320811, 62.55590339892666, 62.632304710793086, 62.34533392963626, 62.671437090041735, 62.548449612403104]] [[2.374888385415575, 1.8789884442720088, 1.6848684417824698, 1.5563834940455965, 1.4462948522186734, 1.3753876723060312, 1.3361935850119548, 1.3126043335056476, 1.278111494788828, 1.2524005584796412, 1.2316399809144123, 1.2382686550445192, 1.2215712451479872, 1.2038450910708132, 1.1953145550629463, 1.1851040532920214, 1.1848355573632565, 1.1820002644987566, 1.177390653602268, 1.1753634432631728, 1.162934783248583, 1.1625263297849278, 1.1535032194287704, 1.1559293941152047, 1.1599742064677894, 1.1553456594208984, 1.1570428435690145, 1.1650479633181168, 1.1466434739072477, 1.1525868970009991, 1.154803791995836, 1.1538222382732566, 1.1499293885489767, 1.1495736167056971, 1.1472685448669862, 1.1474508625023694, 1.1480512435619648, 1.1419059009728292, 1.1400902400645174, 1.1461502283758256, 1.1455486550100802, 1.1510399987318007, 1.1451828276464182, 1.1397350143661227, 1.1407528497949553, 1.1447716278196731, 1.1449926852042573, 1.1464423754418542, 1.1539977628984264, 1.1492711180508954, 1.148792535262088, 1.1426309282465499, 1.1452898247013081, 1.1460244853935855, 1.1520616981196987, 1.1534717653788622, 1.1494795000830362, 1.1525653598560204, 1.1449421042122156, 1.1547335975569633, 1.1503412862156712, 1.1524370754483064, 1.144683535069174, 1.1534469861250658, 1.1486331872024491, 1.1628723155193976, 1.1474609724026603, 1.1563675692199453, 1.1570214223634223, 1.1649919988573059, 1.16281509427848, 1.159811447259565, 1.1692185694786077, 1.16376128620382, 1.1698241686636164, 1.1601230709340933, 1.1497952797331836, 1.1717451607534128, 1.1653066680910478, 1.164771632062017, 1.1725362633123382, 1.1658900057764798, 1.1637469272067593, 1.1651227270909983, 1.1665659700750808, 1.177955336775464, 1.1631243233177444, 1.1640933621974665, 1.1804845385702152, 1.1681738294301178, 1.167726793883454, 1.1774469910452745, 1.1838835226899467, 1.1682632445720385, 1.1773734591017184, 1.1783357249460693, 1.175970662898369, 1.177851712838766, 1.1877524534292567, 1.177802049836447, 1.1832188910931865, 1.1823369710304656, 1.1775417856752126, 1.1854445113976513, 1.1832362099922193, 1.1893023649851482, 1.1861820630395987, 1.179297275463598, 1.190986974081541, 1.185536580847784, 1.187870176192473, 1.1886767289008708, 1.1917766887088155, 1.1905717057135394, 1.1850515374415107, 1.1983683488876533, 1.1975956071183733, 1.1776735902045836, 1.1853388279907464, 1.191550841058516, 1.192511881329008, 1.1927973291457374, 1.2010947868947692, 1.2028154032388185, 1.1963046708132585, 1.1890725120591066], [2.4930082234727817, 1.9381281662783454, 1.6900096647641314, 1.543767934906106, 1.43787663154966, 1.3698317542556644, 1.3250583274491003, 1.2919898264878693, 1.2613322450493374, 1.2354566267578817, 1.216146020570822, 1.2139775081980277, 1.1972271976687046, 1.1844255601499645, 1.189957609330179, 1.1723081273697071, 1.1748692672310945, 1.1620663942577019, 1.1622215129110738, 1.1549048361212424, 1.1449867227494042, 1.1459299431148569, 1.1422214537201427, 1.1409185360639522, 1.1520361305349416, 1.1372926560767578, 1.1395143348685886, 1.1329360768847616, 1.1461034032227955, 1.1297869624733285, 1.1311846697124328, 1.1350412028277994, 1.1392409053670556, 1.1282123227025613, 1.1330755422281664, 1.1258807023081954, 1.1335694482799932, 1.138175224077865, 1.1393921668144231, 1.1221095017186928, 1.1243947383258481, 1.1238980189490049, 1.1339933450689754, 1.1337835298952206, 1.1305136594590361, 1.1326336550726803, 1.134065261253944, 1.130876063447519, 1.127594004874437, 1.1273860675491032, 1.1293732785865815, 1.128399904597424, 1.127579358552422, 1.1317309365787176, 1.1240036216746077, 1.1286339360329816, 1.1350972692242818, 1.1316955521764966, 1.1340258822387077, 1.1416586952402823, 1.1314199952476425, 1.1412762911033971, 1.1377256474611512, 1.1306011580823785, 1.1369973283903045, 1.1469294615423105, 1.1366762827746415, 1.1331401695861087, 1.1380924721452261, 1.1461345164208592, 1.142739652805408, 1.1402934774729774, 1.1422012170013673, 1.1428295869378013, 1.1428369877234625, 1.1545907806340754, 1.1573987453553958, 1.140101343659894, 1.146749604722184, 1.13545796262699, 1.1431675174084177, 1.1488768012308974, 1.1476084446011374, 1.1516758825498887, 1.1481663220399323, 1.1454851457457067, 1.1537522277308847, 1.1575633421780172, 1.1491848870125567, 1.16231769440639, 1.152514159359531, 1.1535158241939603, 1.1573194220582146, 1.1552861273537525, 1.1577217489321032, 1.159866403666151, 1.16179289424, 1.1586551418173647, 1.1540116009857233, 1.1546066451371249, 1.1586237008470683, 1.1684252998270162, 1.1584619728667294, 1.1681183412377865, 1.1655287275587296, 1.1547252907238337, 1.1606118134536698, 1.1671132963188504, 1.1627683859178546, 1.174655684986922, 1.1628211750185198, 1.168834353957634, 1.1688054221402908, 1.1738677518881, 1.1807423158991386, 1.1702512855961982, 1.1698809037552609, 1.1736420156988419, 1.1686188190837807, 1.17341871025595, 1.177989240551393, 1.1765985502397722, 1.1715810856224884, 1.1774707410615615, 1.1758686519479495, 1.1830036045187062]] [0.006207983438052707, 0.00615073356300029]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2b9e6bced828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  accuracy        F1             loss        time [ms]  name\n",
      "test  train   test  train   test     train\n",
      "62.28 76.67   62.28 76.66   1.18e+00 7.31e-01     6   sgconv_sgconv_fc_softmax\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2b9e6d92c780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Common hyper-parameters for LeNet5-like networks (two convolutional layers).\n",
    "common['regularization'] = 5e-4\n",
    "common['dropout']        = 0.5\n",
    "common['learning_rate']  = 0.02  # 0.03 in the paper but sgconv_sgconv_fc_softmax has difficulty to converge\n",
    "common['decay_rate']     = 0.95\n",
    "common['momentum']       = 0.9\n",
    "common['F']              = [32, 64, 128]  # Number of graph convolutional filters.\n",
    "common['K']              = [25, 25, 25]  # Polynomial orders.\n",
    "common['p']              = [4, 4, 4]    # Pooling sizes.\n",
    "common['M']              = [256, C]  # Output dimensionality of fully connected layers.\n",
    "\n",
    "##model#2: two convolutional layers with spline basis as filters\n",
    "name = 'sgconv_sgconv_fc_softmax' #  'Non-Param'\n",
    "params = common.copy()\n",
    "params['dir_name'] += name\n",
    "params['filter'] = 'spline'\n",
    "print(params)    \n",
    "print([L[li].shape for li in range(len(L))])\n",
    "model = models.cgcnn(L, **params)\n",
    "    \n",
    "d = {k: v+1 for v, k in enumerate(sorted(set(Y_test)))}\n",
    "test_labels = np.array([d[x] for x in Y_test])\n",
    "print(np.unique(Y_test))\n",
    "\n",
    "train_acc = []; train_loss = [];\n",
    "test_acc = []; test_loss = [];\n",
    "val_acc = []; val_loss = [];\n",
    "accuracy = []; loss = []; t_step = [];\n",
    "for x_train, y_train, x_val, y_val,tcount in zip(X_train, Y_train, X_val, Y_val,range(2)):\n",
    "    \n",
    "    train_data = coarsening.perm_data(x_train.reshape(-1,Region_Num), perm)\n",
    "    train_labels = np.array([d[x] for x in y_train])\n",
    "    val_data = coarsening.perm_data(x_val.reshape(-1,Region_Num), perm)\n",
    "    val_labels = np.array([d[x] for x in y_val])\n",
    "    test_data = coarsening.perm_data(X_test.reshape(-1,Region_Num), perm)\n",
    "    print('\\nFold #%d: training on %d samples with %d features, validating on %d samples and testing on %d samples' % \n",
    "          (tcount+1,train_data.shape[0],train_data.shape[1],val_data.shape[0],test_data.shape[0]))  \n",
    "    \n",
    "    ###training\n",
    "    model = models.cgcnn(L, **params)\n",
    "    acc, los, tstep = model.fit(train_data, train_labels, val_data, val_labels)\n",
    "    accuracy.append(acc)\n",
    "    loss.append(los)\n",
    "    t_step.append(tstep)\n",
    "\n",
    "    ##evaluation\n",
    "    model_perf.test(model, name, params,\n",
    "                    train_data, train_labels, val_data, val_labels, test_data, test_labels)\n",
    "    train_acc.append(model_perf.train_accuracy[name])\n",
    "    train_loss.append(model_perf.train_loss[name])\n",
    "    test_acc.append(model_perf.test_accuracy[name])\n",
    "    test_loss.append(model_perf.test_loss[name])\n",
    "    val_acc.append(model_perf.fit_accuracies[name])\n",
    "    val_loss.append(model_perf.fit_losses[name])\n",
    "    print('\\n')\n",
    "       \n",
    "print('Accuracy of training:{},testing:{}'.format(np.mean(train_acc),np.mean(test_acc)))\n",
    "print('Accuracy of validation:',np.max(val_acc,axis=1))\n",
    "print(' mean=%2f' % np.mean(np.max(val_acc,axis=1)))\n",
    "\n",
    "###training figures\n",
    "print(accuracy, loss,t_step )\n",
    "fig, ax1 = plt.subplots(figsize=(10, 5))\n",
    "ax1.plot(np.mean(accuracy,axis=0), 'b.-')\n",
    "ax1.set_ylabel('validation accuracy', color='b')\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(np.mean(loss,axis=0), 'g.-')\n",
    "ax2.set_ylabel('training loss', color='g')\n",
    "plt.show()\n",
    "\n",
    "###summarize the results\n",
    "model_perf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dir_name': 'WMcgconv_cgconv_fc_softmax', 'num_epochs': 50, 'batch_size': 128, 'decay_steps': 3768.375, 'eval_frequency': 1500, 'brelu': 'b1relu', 'pool': 'mpool1', 'regularization': 0.0005, 'dropout': 0.5, 'learning_rate': 0.005, 'decay_rate': 0.9, 'momentum': 0.9, 'F': [32, 64, 128], 'K': [25, 25, 25], 'p': [4, 4, 4], 'M': [256, 9], 'filter': 'chebyshev5'}\n",
      "[(512, 512), (256, 256), (128, 128), (64, 64), (32, 32), (16, 16), (8, 8)]\n",
      "NN architecture\n",
      "  input: M_0 = 512\n",
      "  layer 1: cgconv1\n",
      "    representation: M_0 * F_1 / p_1 = 512 * 32 / 4 = 4096\n",
      "    weights: F_0 * F_1 * K_1 = 1 * 32 * 25 = 800\n",
      "    biases: F_1 = 32\n",
      "  layer 2: cgconv2\n",
      "    representation: M_1 * F_2 / p_2 = 128 * 64 / 4 = 2048\n",
      "    weights: F_1 * F_2 * K_2 = 32 * 64 * 25 = 51200\n",
      "    biases: F_2 = 64\n",
      "  layer 3: cgconv3\n",
      "    representation: M_2 * F_3 / p_3 = 32 * 128 / 4 = 1024\n",
      "    weights: F_2 * F_3 * K_3 = 64 * 128 * 25 = 204800\n",
      "    biases: F_3 = 128\n",
      "  layer 4: fc1\n",
      "    representation: M_4 = 256\n",
      "    weights: M_3 * M_4 = 1024 * 256 = 262144\n",
      "    biases: M_4 = 256\n",
      "  layer 5: logits (softmax)\n",
      "    representation: M_5 = 9\n",
      "    weights: M_4 * M_5 = 256 * 9 = 2304\n",
      "    biases: M_5 = 9\n",
      "['body0b_wm' 'body2b_wm' 'face0b_wm' 'face2b_wm' 'place0b_wm' 'place2b_wm'\n",
      " 'tool0b_wm' 'tool2b_wm']\n",
      "\n",
      "Fold #1: training on 482352 samples with 512 features, validating on 53664 samples and testing on 134160 samples\n",
      "step 1500 / 188418 (epoch 0.40 / 50):\n",
      "  learning_rate = 5.00e-03, loss_average = 2.12e+00\n",
      "  validation accuracy: 42.10 (22594 / 53664), f1 (weighted): 41.58, loss: 2.08e+00\n",
      "  time: 41s (wall 73s)\n",
      "step 3000 / 188418 (epoch 0.80 / 50):\n",
      "  learning_rate = 5.00e-03, loss_average = 1.98e+00\n",
      "  validation accuracy: 45.90 (24632 / 53664), f1 (weighted): 45.58, loss: 1.94e+00\n",
      "  time: 76s (wall 140s)\n",
      "step 4500 / 188418 (epoch 1.19 / 50):\n",
      "  learning_rate = 4.50e-03, loss_average = 1.91e+00\n",
      "  validation accuracy: 47.83 (25665 / 53664), f1 (weighted): 47.89, loss: 1.86e+00\n",
      "  time: 111s (wall 206s)\n",
      "step 6000 / 188418 (epoch 1.59 / 50):\n",
      "  learning_rate = 4.50e-03, loss_average = 1.84e+00\n",
      "  validation accuracy: 48.87 (26226 / 53664), f1 (weighted): 48.86, loss: 1.80e+00\n",
      "  time: 145s (wall 272s)\n",
      "step 7500 / 188418 (epoch 1.99 / 50):\n",
      "  learning_rate = 4.50e-03, loss_average = 1.75e+00\n",
      "  validation accuracy: 50.77 (27245 / 53664), f1 (weighted): 50.87, loss: 1.74e+00\n",
      "  time: 179s (wall 338s)\n",
      "step 9000 / 188418 (epoch 2.39 / 50):\n",
      "  learning_rate = 4.05e-03, loss_average = 1.69e+00\n",
      "  validation accuracy: 50.58 (27143 / 53664), f1 (weighted): 50.49, loss: 1.71e+00\n",
      "  time: 213s (wall 404s)\n",
      "step 10500 / 188418 (epoch 2.79 / 50):\n",
      "  learning_rate = 4.05e-03, loss_average = 1.70e+00\n",
      "  validation accuracy: 51.54 (27659 / 53664), f1 (weighted): 51.66, loss: 1.66e+00\n",
      "  time: 247s (wall 470s)\n",
      "step 12000 / 188418 (epoch 3.18 / 50):\n",
      "  learning_rate = 3.64e-03, loss_average = 1.66e+00\n",
      "  validation accuracy: 52.20 (28010 / 53664), f1 (weighted): 52.11, loss: 1.64e+00\n",
      "  time: 281s (wall 536s)\n",
      "step 13500 / 188418 (epoch 3.58 / 50):\n",
      "  learning_rate = 3.64e-03, loss_average = 1.60e+00\n",
      "  validation accuracy: 52.92 (28397 / 53664), f1 (weighted): 52.90, loss: 1.60e+00\n",
      "  time: 315s (wall 602s)\n",
      "step 15000 / 188418 (epoch 3.98 / 50):\n",
      "  learning_rate = 3.64e-03, loss_average = 1.59e+00\n",
      "  validation accuracy: 53.16 (28527 / 53664), f1 (weighted): 53.31, loss: 1.58e+00\n",
      "  time: 349s (wall 668s)\n",
      "step 16500 / 188418 (epoch 4.38 / 50):\n",
      "  learning_rate = 3.28e-03, loss_average = 1.54e+00\n",
      "  validation accuracy: 53.69 (28810 / 53664), f1 (weighted): 53.73, loss: 1.55e+00\n",
      "  time: 383s (wall 734s)\n",
      "step 18000 / 188418 (epoch 4.78 / 50):\n",
      "  learning_rate = 3.28e-03, loss_average = 1.54e+00\n",
      "  validation accuracy: 54.15 (29059 / 53664), f1 (weighted): 54.15, loss: 1.53e+00\n",
      "  time: 417s (wall 800s)\n",
      "step 19500 / 188418 (epoch 5.17 / 50):\n",
      "  learning_rate = 2.95e-03, loss_average = 1.51e+00\n",
      "  validation accuracy: 54.33 (29153 / 53664), f1 (weighted): 54.40, loss: 1.51e+00\n",
      "  time: 451s (wall 866s)\n",
      "step 21000 / 188418 (epoch 5.57 / 50):\n",
      "  learning_rate = 2.95e-03, loss_average = 1.49e+00\n",
      "  validation accuracy: 54.51 (29250 / 53664), f1 (weighted): 54.51, loss: 1.50e+00\n",
      "  time: 484s (wall 932s)\n",
      "step 22500 / 188418 (epoch 5.97 / 50):\n",
      "  learning_rate = 2.95e-03, loss_average = 1.48e+00\n",
      "  validation accuracy: 54.97 (29501 / 53664), f1 (weighted): 54.99, loss: 1.48e+00\n",
      "  time: 518s (wall 998s)\n",
      "step 24000 / 188418 (epoch 6.37 / 50):\n",
      "  learning_rate = 2.66e-03, loss_average = 1.42e+00\n",
      "  validation accuracy: 55.21 (29626 / 53664), f1 (weighted): 55.25, loss: 1.47e+00\n",
      "  time: 552s (wall 1064s)\n",
      "step 25500 / 188418 (epoch 6.77 / 50):\n",
      "  learning_rate = 2.66e-03, loss_average = 1.43e+00\n",
      "  validation accuracy: 55.00 (29515 / 53664), f1 (weighted): 55.01, loss: 1.46e+00\n",
      "  time: 586s (wall 1130s)\n",
      "step 27000 / 188418 (epoch 7.16 / 50):\n",
      "  learning_rate = 2.39e-03, loss_average = 1.44e+00\n",
      "  validation accuracy: 55.16 (29603 / 53664), f1 (weighted): 55.18, loss: 1.45e+00\n",
      "  time: 620s (wall 1196s)\n",
      "step 28500 / 188418 (epoch 7.56 / 50):\n",
      "  learning_rate = 2.39e-03, loss_average = 1.43e+00\n",
      "  validation accuracy: 55.77 (29926 / 53664), f1 (weighted): 55.73, loss: 1.43e+00\n",
      "  time: 654s (wall 1262s)\n",
      "step 30000 / 188418 (epoch 7.96 / 50):\n",
      "  learning_rate = 2.39e-03, loss_average = 1.43e+00\n",
      "  validation accuracy: 55.70 (29893 / 53664), f1 (weighted): 55.68, loss: 1.42e+00\n",
      "  time: 688s (wall 1328s)\n",
      "step 31500 / 188418 (epoch 8.36 / 50):\n",
      "  learning_rate = 2.15e-03, loss_average = 1.38e+00\n",
      "  validation accuracy: 55.74 (29914 / 53664), f1 (weighted): 55.77, loss: 1.41e+00\n",
      "  time: 722s (wall 1394s)\n",
      "step 33000 / 188418 (epoch 8.76 / 50):\n",
      "  learning_rate = 2.15e-03, loss_average = 1.39e+00\n",
      "  validation accuracy: 55.95 (30026 / 53664), f1 (weighted): 55.94, loss: 1.40e+00\n",
      "  time: 756s (wall 1460s)\n",
      "step 34500 / 188418 (epoch 9.16 / 50):\n",
      "  learning_rate = 1.94e-03, loss_average = 1.37e+00\n",
      "  validation accuracy: 56.07 (30089 / 53664), f1 (weighted): 56.06, loss: 1.40e+00\n",
      "  time: 790s (wall 1526s)\n",
      "step 36000 / 188418 (epoch 9.55 / 50):\n",
      "  learning_rate = 1.94e-03, loss_average = 1.37e+00\n",
      "  validation accuracy: 56.43 (30282 / 53664), f1 (weighted): 56.44, loss: 1.39e+00\n",
      "  time: 824s (wall 1592s)\n",
      "step 37500 / 188418 (epoch 9.95 / 50):\n",
      "  learning_rate = 1.94e-03, loss_average = 1.34e+00\n",
      "  validation accuracy: 56.47 (30306 / 53664), f1 (weighted): 56.51, loss: 1.38e+00\n",
      "  time: 859s (wall 1658s)\n",
      "step 39000 / 188418 (epoch 10.35 / 50):\n",
      "  learning_rate = 1.74e-03, loss_average = 1.37e+00\n",
      "  validation accuracy: 56.44 (30286 / 53664), f1 (weighted): 56.45, loss: 1.38e+00\n",
      "  time: 892s (wall 1724s)\n",
      "step 40500 / 188418 (epoch 10.75 / 50):\n",
      "  learning_rate = 1.74e-03, loss_average = 1.33e+00\n",
      "  validation accuracy: 56.54 (30341 / 53664), f1 (weighted): 56.64, loss: 1.37e+00\n",
      "  time: 926s (wall 1789s)\n",
      "step 42000 / 188418 (epoch 11.15 / 50):\n",
      "  learning_rate = 1.57e-03, loss_average = 1.34e+00\n",
      "  validation accuracy: 56.84 (30500 / 53664), f1 (weighted): 56.90, loss: 1.36e+00\n",
      "  time: 960s (wall 1855s)\n",
      "step 43500 / 188418 (epoch 11.54 / 50):\n",
      "  learning_rate = 1.57e-03, loss_average = 1.33e+00\n",
      "  validation accuracy: 56.92 (30548 / 53664), f1 (weighted): 57.00, loss: 1.35e+00\n",
      "  time: 993s (wall 1921s)\n",
      "step 45000 / 188418 (epoch 11.94 / 50):\n",
      "  learning_rate = 1.57e-03, loss_average = 1.34e+00\n",
      "  validation accuracy: 57.06 (30619 / 53664), f1 (weighted): 57.11, loss: 1.35e+00\n",
      "  time: 1028s (wall 1987s)\n",
      "step 46500 / 188418 (epoch 12.34 / 50):\n",
      "  learning_rate = 1.41e-03, loss_average = 1.33e+00\n",
      "  validation accuracy: 57.15 (30667 / 53664), f1 (weighted): 57.21, loss: 1.34e+00\n",
      "  time: 1062s (wall 2053s)\n",
      "step 48000 / 188418 (epoch 12.74 / 50):\n",
      "  learning_rate = 1.41e-03, loss_average = 1.32e+00\n",
      "  validation accuracy: 57.08 (30629 / 53664), f1 (weighted): 57.16, loss: 1.34e+00\n",
      "  time: 1096s (wall 2119s)\n",
      "step 49500 / 188418 (epoch 13.14 / 50):\n",
      "  learning_rate = 1.27e-03, loss_average = 1.34e+00\n",
      "  validation accuracy: 57.38 (30795 / 53664), f1 (weighted): 57.41, loss: 1.33e+00\n",
      "  time: 1129s (wall 2185s)\n",
      "step 51000 / 188418 (epoch 13.53 / 50):\n",
      "  learning_rate = 1.27e-03, loss_average = 1.28e+00\n",
      "  validation accuracy: 57.35 (30774 / 53664), f1 (weighted): 57.37, loss: 1.33e+00\n",
      "  time: 1163s (wall 2251s)\n",
      "step 52500 / 188418 (epoch 13.93 / 50):\n",
      "  learning_rate = 1.27e-03, loss_average = 1.32e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  validation accuracy: 57.60 (30911 / 53664), f1 (weighted): 57.61, loss: 1.33e+00\n",
      "  time: 1197s (wall 2316s)\n",
      "step 54000 / 188418 (epoch 14.33 / 50):\n",
      "  learning_rate = 1.14e-03, loss_average = 1.28e+00\n",
      "  validation accuracy: 57.67 (30950 / 53664), f1 (weighted): 57.65, loss: 1.32e+00\n",
      "  time: 1231s (wall 2382s)\n",
      "step 55500 / 188418 (epoch 14.73 / 50):\n",
      "  learning_rate = 1.14e-03, loss_average = 1.34e+00\n",
      "  validation accuracy: 57.60 (30912 / 53664), f1 (weighted): 57.60, loss: 1.32e+00\n",
      "  time: 1265s (wall 2448s)\n",
      "step 57000 / 188418 (epoch 15.13 / 50):\n",
      "  learning_rate = 1.03e-03, loss_average = 1.29e+00\n",
      "  validation accuracy: 57.75 (30991 / 53664), f1 (weighted): 57.81, loss: 1.31e+00\n",
      "  time: 1299s (wall 2514s)\n",
      "step 58500 / 188418 (epoch 15.52 / 50):\n",
      "  learning_rate = 1.03e-03, loss_average = 1.22e+00\n",
      "  validation accuracy: 57.72 (30977 / 53664), f1 (weighted): 57.77, loss: 1.31e+00\n",
      "  time: 1332s (wall 2580s)\n",
      "step 60000 / 188418 (epoch 15.92 / 50):\n",
      "  learning_rate = 1.03e-03, loss_average = 1.25e+00\n",
      "  validation accuracy: 57.86 (31050 / 53664), f1 (weighted): 57.87, loss: 1.31e+00\n",
      "  time: 1366s (wall 2646s)\n",
      "step 61500 / 188418 (epoch 16.32 / 50):\n",
      "  learning_rate = 9.27e-04, loss_average = 1.26e+00\n",
      "  validation accuracy: 57.93 (31086 / 53664), f1 (weighted): 57.94, loss: 1.30e+00\n",
      "  time: 1400s (wall 2712s)\n",
      "step 63000 / 188418 (epoch 16.72 / 50):\n",
      "  learning_rate = 9.27e-04, loss_average = 1.29e+00\n",
      "  validation accuracy: 57.62 (30920 / 53664), f1 (weighted): 57.66, loss: 1.31e+00\n",
      "  time: 1434s (wall 2778s)\n",
      "step 64500 / 188418 (epoch 17.12 / 50):\n",
      "  learning_rate = 8.34e-04, loss_average = 1.30e+00\n",
      "  validation accuracy: 57.77 (31004 / 53664), f1 (weighted): 57.87, loss: 1.30e+00\n",
      "  time: 1468s (wall 2844s)\n",
      "step 66000 / 188418 (epoch 17.51 / 50):\n",
      "  learning_rate = 8.34e-04, loss_average = 1.24e+00\n",
      "  validation accuracy: 57.95 (31098 / 53664), f1 (weighted): 57.94, loss: 1.30e+00\n",
      "  time: 1501s (wall 2909s)\n",
      "step 67500 / 188418 (epoch 17.91 / 50):\n",
      "  learning_rate = 8.34e-04, loss_average = 1.26e+00\n",
      "  validation accuracy: 57.96 (31104 / 53664), f1 (weighted): 57.96, loss: 1.30e+00\n",
      "  time: 1535s (wall 2975s)\n",
      "step 69000 / 188418 (epoch 18.31 / 50):\n",
      "  learning_rate = 7.50e-04, loss_average = 1.27e+00\n",
      "  validation accuracy: 58.17 (31219 / 53664), f1 (weighted): 58.19, loss: 1.29e+00\n",
      "  time: 1569s (wall 3041s)\n",
      "step 70500 / 188418 (epoch 18.71 / 50):\n",
      "  learning_rate = 7.50e-04, loss_average = 1.29e+00\n",
      "  validation accuracy: 57.97 (31111 / 53664), f1 (weighted): 58.06, loss: 1.30e+00\n",
      "  time: 1603s (wall 3107s)\n",
      "step 72000 / 188418 (epoch 19.11 / 50):\n",
      "  learning_rate = 6.75e-04, loss_average = 1.25e+00\n",
      "  validation accuracy: 58.17 (31218 / 53664), f1 (weighted): 58.16, loss: 1.29e+00\n",
      "  time: 1637s (wall 3173s)\n",
      "step 73500 / 188418 (epoch 19.50 / 50):\n",
      "  learning_rate = 6.75e-04, loss_average = 1.26e+00\n",
      "  validation accuracy: 58.03 (31143 / 53664), f1 (weighted): 58.10, loss: 1.29e+00\n",
      "  time: 1671s (wall 3239s)\n",
      "step 75000 / 188418 (epoch 19.90 / 50):\n",
      "  learning_rate = 6.75e-04, loss_average = 1.22e+00\n",
      "  validation accuracy: 58.34 (31308 / 53664), f1 (weighted): 58.35, loss: 1.29e+00\n",
      "  time: 1705s (wall 3305s)\n",
      "step 76500 / 188418 (epoch 20.30 / 50):\n",
      "  learning_rate = 6.08e-04, loss_average = 1.25e+00\n",
      "  validation accuracy: 58.20 (31230 / 53664), f1 (weighted): 58.20, loss: 1.29e+00\n",
      "  time: 1739s (wall 3371s)\n",
      "step 78000 / 188418 (epoch 20.70 / 50):\n",
      "  learning_rate = 6.08e-04, loss_average = 1.25e+00\n",
      "  validation accuracy: 58.28 (31273 / 53664), f1 (weighted): 58.30, loss: 1.28e+00\n",
      "  time: 1772s (wall 3437s)\n",
      "step 79500 / 188418 (epoch 21.10 / 50):\n",
      "  learning_rate = 5.47e-04, loss_average = 1.20e+00\n",
      "  validation accuracy: 58.47 (31376 / 53664), f1 (weighted): 58.46, loss: 1.28e+00\n",
      "  time: 1806s (wall 3503s)\n",
      "step 81000 / 188418 (epoch 21.49 / 50):\n",
      "  learning_rate = 5.47e-04, loss_average = 1.20e+00\n",
      "  validation accuracy: 58.40 (31341 / 53664), f1 (weighted): 58.42, loss: 1.28e+00\n",
      "  time: 1840s (wall 3569s)\n",
      "step 82500 / 188418 (epoch 21.89 / 50):\n",
      "  learning_rate = 5.47e-04, loss_average = 1.23e+00\n",
      "  validation accuracy: 58.39 (31335 / 53664), f1 (weighted): 58.39, loss: 1.28e+00\n",
      "  time: 1874s (wall 3635s)\n",
      "step 84000 / 188418 (epoch 22.29 / 50):\n",
      "  learning_rate = 4.92e-04, loss_average = 1.24e+00\n",
      "  validation accuracy: 58.45 (31364 / 53664), f1 (weighted): 58.43, loss: 1.28e+00\n",
      "  time: 1908s (wall 3701s)\n",
      "step 85500 / 188418 (epoch 22.69 / 50):\n",
      "  learning_rate = 4.92e-04, loss_average = 1.23e+00\n",
      "  validation accuracy: 58.53 (31407 / 53664), f1 (weighted): 58.56, loss: 1.28e+00\n",
      "  time: 1942s (wall 3767s)\n",
      "step 87000 / 188418 (epoch 23.09 / 50):\n",
      "  learning_rate = 4.43e-04, loss_average = 1.19e+00\n",
      "  validation accuracy: 58.48 (31383 / 53664), f1 (weighted): 58.53, loss: 1.27e+00\n",
      "  time: 1976s (wall 3833s)\n",
      "step 88500 / 188418 (epoch 23.48 / 50):\n",
      "  learning_rate = 4.43e-04, loss_average = 1.21e+00\n",
      "  validation accuracy: 58.55 (31422 / 53664), f1 (weighted): 58.55, loss: 1.27e+00\n",
      "  time: 2010s (wall 3898s)\n",
      "step 90000 / 188418 (epoch 23.88 / 50):\n",
      "  learning_rate = 4.43e-04, loss_average = 1.18e+00\n",
      "  validation accuracy: 58.49 (31390 / 53664), f1 (weighted): 58.49, loss: 1.27e+00\n",
      "  time: 2043s (wall 3964s)\n",
      "step 91500 / 188418 (epoch 24.28 / 50):\n",
      "  learning_rate = 3.99e-04, loss_average = 1.22e+00\n",
      "  validation accuracy: 58.66 (31480 / 53664), f1 (weighted): 58.67, loss: 1.27e+00\n",
      "  time: 2077s (wall 4030s)\n",
      "step 93000 / 188418 (epoch 24.68 / 50):\n",
      "  learning_rate = 3.99e-04, loss_average = 1.18e+00\n",
      "  validation accuracy: 58.48 (31384 / 53664), f1 (weighted): 58.50, loss: 1.27e+00\n",
      "  time: 2111s (wall 4096s)\n",
      "step 94500 / 188418 (epoch 25.08 / 50):\n",
      "  learning_rate = 3.59e-04, loss_average = 1.24e+00\n",
      "  validation accuracy: 58.66 (31480 / 53664), f1 (weighted): 58.66, loss: 1.27e+00\n",
      "  time: 2145s (wall 4162s)\n",
      "step 96000 / 188418 (epoch 25.48 / 50):\n",
      "  learning_rate = 3.59e-04, loss_average = 1.23e+00\n",
      "  validation accuracy: 58.60 (31445 / 53664), f1 (weighted): 58.63, loss: 1.27e+00\n",
      "  time: 2179s (wall 4228s)\n",
      "step 97500 / 188418 (epoch 25.87 / 50):\n",
      "  learning_rate = 3.59e-04, loss_average = 1.25e+00\n",
      "  validation accuracy: 58.55 (31422 / 53664), f1 (weighted): 58.59, loss: 1.27e+00\n",
      "  time: 2213s (wall 4294s)\n",
      "step 99000 / 188418 (epoch 26.27 / 50):\n",
      "  learning_rate = 3.23e-04, loss_average = 1.22e+00\n",
      "  validation accuracy: 58.69 (31495 / 53664), f1 (weighted): 58.67, loss: 1.27e+00\n",
      "  time: 2246s (wall 4360s)\n",
      "step 100500 / 188418 (epoch 26.67 / 50):\n",
      "  learning_rate = 3.23e-04, loss_average = 1.21e+00\n",
      "  validation accuracy: 58.65 (31476 / 53664), f1 (weighted): 58.65, loss: 1.27e+00\n",
      "  time: 2280s (wall 4426s)\n",
      "step 102000 / 188418 (epoch 27.07 / 50):\n",
      "  learning_rate = 2.91e-04, loss_average = 1.21e+00\n",
      "  validation accuracy: 58.80 (31557 / 53664), f1 (weighted): 58.83, loss: 1.26e+00\n",
      "  time: 2314s (wall 4492s)\n",
      "step 103500 / 188418 (epoch 27.47 / 50):\n",
      "  learning_rate = 2.91e-04, loss_average = 1.20e+00\n",
      "  validation accuracy: 58.81 (31559 / 53664), f1 (weighted): 58.83, loss: 1.26e+00\n",
      "  time: 2348s (wall 4558s)\n",
      "step 105000 / 188418 (epoch 27.86 / 50):\n",
      "  learning_rate = 2.91e-04, loss_average = 1.25e+00\n",
      "  validation accuracy: 58.68 (31489 / 53664), f1 (weighted): 58.70, loss: 1.26e+00\n",
      "  time: 2382s (wall 4624s)\n",
      "step 106500 / 188418 (epoch 28.26 / 50):\n",
      "  learning_rate = 2.62e-04, loss_average = 1.17e+00\n",
      "  validation accuracy: 58.62 (31460 / 53664), f1 (weighted): 58.65, loss: 1.26e+00\n",
      "  time: 2416s (wall 4689s)\n",
      "step 108000 / 188418 (epoch 28.66 / 50):\n",
      "  learning_rate = 2.62e-04, loss_average = 1.21e+00\n",
      "  validation accuracy: 58.81 (31561 / 53664), f1 (weighted): 58.83, loss: 1.26e+00\n",
      "  time: 2450s (wall 4755s)\n",
      "step 109500 / 188418 (epoch 29.06 / 50):\n",
      "  learning_rate = 2.36e-04, loss_average = 1.20e+00\n",
      "  validation accuracy: 58.72 (31512 / 53664), f1 (weighted): 58.73, loss: 1.26e+00\n",
      "  time: 2483s (wall 4821s)\n",
      "step 111000 / 188418 (epoch 29.46 / 50):\n",
      "  learning_rate = 2.36e-04, loss_average = 1.21e+00\n",
      "  validation accuracy: 58.90 (31609 / 53664), f1 (weighted): 58.92, loss: 1.26e+00\n",
      "  time: 2517s (wall 4887s)\n",
      "step 112500 / 188418 (epoch 29.85 / 50):\n",
      "  learning_rate = 2.36e-04, loss_average = 1.22e+00\n",
      "  validation accuracy: 58.79 (31547 / 53664), f1 (weighted): 58.77, loss: 1.26e+00\n",
      "  time: 2551s (wall 4953s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 114000 / 188418 (epoch 30.25 / 50):\n",
      "  learning_rate = 2.12e-04, loss_average = 1.22e+00\n",
      "  validation accuracy: 58.70 (31503 / 53664), f1 (weighted): 58.75, loss: 1.26e+00\n",
      "  time: 2584s (wall 5018s)\n",
      "step 115500 / 188418 (epoch 30.65 / 50):\n",
      "  learning_rate = 2.12e-04, loss_average = 1.21e+00\n",
      "  validation accuracy: 58.80 (31557 / 53664), f1 (weighted): 58.81, loss: 1.26e+00\n",
      "  time: 2618s (wall 5084s)\n",
      "step 117000 / 188418 (epoch 31.05 / 50):\n",
      "  learning_rate = 1.91e-04, loss_average = 1.20e+00\n",
      "  validation accuracy: 58.81 (31562 / 53664), f1 (weighted): 58.83, loss: 1.26e+00\n",
      "  time: 2652s (wall 5150s)\n",
      "step 118500 / 188418 (epoch 31.45 / 50):\n",
      "  learning_rate = 1.91e-04, loss_average = 1.18e+00\n",
      "  validation accuracy: 58.94 (31627 / 53664), f1 (weighted): 58.95, loss: 1.26e+00\n",
      "  time: 2686s (wall 5216s)\n",
      "step 120000 / 188418 (epoch 31.84 / 50):\n",
      "  learning_rate = 1.91e-04, loss_average = 1.20e+00\n",
      "  validation accuracy: 58.98 (31653 / 53664), f1 (weighted): 59.00, loss: 1.26e+00\n",
      "  time: 2720s (wall 5282s)\n",
      "step 121500 / 188418 (epoch 32.24 / 50):\n",
      "  learning_rate = 1.72e-04, loss_average = 1.20e+00\n",
      "  validation accuracy: 58.83 (31568 / 53664), f1 (weighted): 58.86, loss: 1.26e+00\n",
      "  time: 2754s (wall 5348s)\n",
      "step 123000 / 188418 (epoch 32.64 / 50):\n",
      "  learning_rate = 1.72e-04, loss_average = 1.24e+00\n",
      "  validation accuracy: 58.87 (31592 / 53664), f1 (weighted): 58.89, loss: 1.26e+00\n",
      "  time: 2788s (wall 5414s)\n",
      "step 124500 / 188418 (epoch 33.04 / 50):\n",
      "  learning_rate = 1.55e-04, loss_average = 1.20e+00\n",
      "  validation accuracy: 58.95 (31636 / 53664), f1 (weighted): 58.97, loss: 1.26e+00\n",
      "  time: 2821s (wall 5480s)\n",
      "step 126000 / 188418 (epoch 33.44 / 50):\n",
      "  learning_rate = 1.55e-04, loss_average = 1.20e+00\n",
      "  validation accuracy: 58.91 (31616 / 53664), f1 (weighted): 58.95, loss: 1.26e+00\n",
      "  time: 2855s (wall 5546s)\n",
      "step 127500 / 188418 (epoch 33.83 / 50):\n",
      "  learning_rate = 1.55e-04, loss_average = 1.23e+00\n",
      "  validation accuracy: 58.88 (31596 / 53664), f1 (weighted): 58.89, loss: 1.25e+00\n",
      "  time: 2889s (wall 5611s)\n",
      "step 129000 / 188418 (epoch 34.23 / 50):\n",
      "  learning_rate = 1.39e-04, loss_average = 1.18e+00\n",
      "  validation accuracy: 58.99 (31658 / 53664), f1 (weighted): 59.00, loss: 1.25e+00\n",
      "  time: 2923s (wall 5677s)\n",
      "step 130500 / 188418 (epoch 34.63 / 50):\n",
      "  learning_rate = 1.39e-04, loss_average = 1.21e+00\n",
      "  validation accuracy: 59.01 (31667 / 53664), f1 (weighted): 59.04, loss: 1.25e+00\n",
      "  time: 2957s (wall 5743s)\n",
      "step 132000 / 188418 (epoch 35.03 / 50):\n",
      "  learning_rate = 1.25e-04, loss_average = 1.20e+00\n",
      "  validation accuracy: 58.98 (31652 / 53664), f1 (weighted): 59.00, loss: 1.25e+00\n",
      "  time: 2991s (wall 5809s)\n",
      "step 133500 / 188418 (epoch 35.43 / 50):\n",
      "  learning_rate = 1.25e-04, loss_average = 1.21e+00\n",
      "  validation accuracy: 58.94 (31631 / 53664), f1 (weighted): 58.96, loss: 1.25e+00\n",
      "  time: 3025s (wall 5875s)\n",
      "step 135000 / 188418 (epoch 35.82 / 50):\n",
      "  learning_rate = 1.25e-04, loss_average = 1.20e+00\n",
      "  validation accuracy: 58.98 (31653 / 53664), f1 (weighted): 58.99, loss: 1.25e+00\n",
      "  time: 3059s (wall 5941s)\n",
      "step 136500 / 188418 (epoch 36.22 / 50):\n",
      "  learning_rate = 1.13e-04, loss_average = 1.20e+00\n",
      "  validation accuracy: 59.02 (31671 / 53664), f1 (weighted): 59.03, loss: 1.25e+00\n",
      "  time: 3092s (wall 6007s)\n",
      "step 138000 / 188418 (epoch 36.62 / 50):\n",
      "  learning_rate = 1.13e-04, loss_average = 1.16e+00\n",
      "  validation accuracy: 59.03 (31676 / 53664), f1 (weighted): 59.06, loss: 1.25e+00\n",
      "  time: 3126s (wall 6073s)\n",
      "step 139500 / 188418 (epoch 37.02 / 50):\n",
      "  learning_rate = 1.01e-04, loss_average = 1.21e+00\n",
      "  validation accuracy: 59.07 (31698 / 53664), f1 (weighted): 59.09, loss: 1.25e+00\n",
      "  time: 3160s (wall 6139s)\n",
      "step 141000 / 188418 (epoch 37.42 / 50):\n",
      "  learning_rate = 1.01e-04, loss_average = 1.18e+00\n",
      "  validation accuracy: 59.02 (31671 / 53664), f1 (weighted): 59.04, loss: 1.25e+00\n",
      "  time: 3194s (wall 6204s)\n",
      "step 142500 / 188418 (epoch 37.81 / 50):\n",
      "  learning_rate = 1.01e-04, loss_average = 1.19e+00\n",
      "  validation accuracy: 58.99 (31658 / 53664), f1 (weighted): 59.02, loss: 1.25e+00\n",
      "  time: 3228s (wall 6270s)\n",
      "step 144000 / 188418 (epoch 38.21 / 50):\n",
      "  learning_rate = 9.12e-05, loss_average = 1.16e+00\n",
      "  validation accuracy: 58.96 (31638 / 53664), f1 (weighted): 58.97, loss: 1.25e+00\n",
      "  time: 3262s (wall 6336s)\n",
      "step 145500 / 188418 (epoch 38.61 / 50):\n",
      "  learning_rate = 9.12e-05, loss_average = 1.23e+00\n",
      "  validation accuracy: 58.93 (31622 / 53664), f1 (weighted): 58.96, loss: 1.25e+00\n",
      "  time: 3296s (wall 6402s)\n",
      "step 147000 / 188418 (epoch 39.01 / 50):\n",
      "  learning_rate = 8.21e-05, loss_average = 1.22e+00\n",
      "  validation accuracy: 59.03 (31677 / 53664), f1 (weighted): 59.05, loss: 1.25e+00\n",
      "  time: 3329s (wall 6468s)\n",
      "step 148500 / 188418 (epoch 39.41 / 50):\n",
      "  learning_rate = 8.21e-05, loss_average = 1.19e+00\n",
      "  validation accuracy: 59.07 (31700 / 53664), f1 (weighted): 59.07, loss: 1.25e+00\n",
      "  time: 3363s (wall 6534s)\n",
      "step 150000 / 188418 (epoch 39.80 / 50):\n",
      "  learning_rate = 8.21e-05, loss_average = 1.22e+00\n",
      "  validation accuracy: 58.97 (31646 / 53664), f1 (weighted): 59.00, loss: 1.25e+00\n",
      "  time: 3397s (wall 6600s)\n",
      "step 151500 / 188418 (epoch 40.20 / 50):\n",
      "  learning_rate = 7.39e-05, loss_average = 1.21e+00\n",
      "  validation accuracy: 58.97 (31648 / 53664), f1 (weighted): 58.98, loss: 1.25e+00\n",
      "  time: 3431s (wall 6666s)\n",
      "step 153000 / 188418 (epoch 40.60 / 50):\n",
      "  learning_rate = 7.39e-05, loss_average = 1.15e+00\n",
      "  validation accuracy: 59.05 (31686 / 53664), f1 (weighted): 59.06, loss: 1.25e+00\n",
      "  time: 3465s (wall 6732s)\n",
      "step 154500 / 188418 (epoch 41.00 / 50):\n",
      "  learning_rate = 7.39e-05, loss_average = 1.19e+00\n",
      "  validation accuracy: 59.05 (31691 / 53664), f1 (weighted): 59.06, loss: 1.25e+00\n",
      "  time: 3498s (wall 6797s)\n",
      "step 156000 / 188418 (epoch 41.40 / 50):\n",
      "  learning_rate = 6.65e-05, loss_average = 1.18e+00\n",
      "  validation accuracy: 59.02 (31670 / 53664), f1 (weighted): 59.05, loss: 1.25e+00\n",
      "  time: 3532s (wall 6863s)\n",
      "step 157500 / 188418 (epoch 41.80 / 50):\n",
      "  learning_rate = 6.65e-05, loss_average = 1.20e+00\n",
      "  validation accuracy: 59.10 (31714 / 53664), f1 (weighted): 59.13, loss: 1.25e+00\n",
      "  time: 3566s (wall 6929s)\n",
      "step 159000 / 188418 (epoch 42.19 / 50):\n",
      "  learning_rate = 5.99e-05, loss_average = 1.18e+00\n",
      "  validation accuracy: 59.07 (31698 / 53664), f1 (weighted): 59.09, loss: 1.25e+00\n",
      "  time: 3600s (wall 6995s)\n",
      "step 160500 / 188418 (epoch 42.59 / 50):\n",
      "  learning_rate = 5.99e-05, loss_average = 1.16e+00\n",
      "  validation accuracy: 59.09 (31710 / 53664), f1 (weighted): 59.11, loss: 1.25e+00\n",
      "  time: 3634s (wall 7061s)\n",
      "step 162000 / 188418 (epoch 42.99 / 50):\n",
      "  learning_rate = 5.99e-05, loss_average = 1.20e+00\n",
      "  validation accuracy: 59.06 (31696 / 53664), f1 (weighted): 59.07, loss: 1.25e+00\n",
      "  time: 3668s (wall 7127s)\n",
      "step 163500 / 188418 (epoch 43.39 / 50):\n",
      "  learning_rate = 5.39e-05, loss_average = 1.17e+00\n",
      "  validation accuracy: 59.10 (31718 / 53664), f1 (weighted): 59.12, loss: 1.25e+00\n",
      "  time: 3702s (wall 7193s)\n",
      "step 165000 / 188418 (epoch 43.79 / 50):\n",
      "  learning_rate = 5.39e-05, loss_average = 1.21e+00\n",
      "  validation accuracy: 58.99 (31657 / 53664), f1 (weighted): 59.01, loss: 1.25e+00\n",
      "  time: 3735s (wall 7259s)\n",
      "step 166500 / 188418 (epoch 44.18 / 50):\n",
      "  learning_rate = 4.85e-05, loss_average = 1.18e+00\n",
      "  validation accuracy: 59.10 (31716 / 53664), f1 (weighted): 59.12, loss: 1.25e+00\n",
      "  time: 3769s (wall 7324s)\n",
      "step 168000 / 188418 (epoch 44.58 / 50):\n",
      "  learning_rate = 4.85e-05, loss_average = 1.20e+00\n",
      "  validation accuracy: 59.02 (31674 / 53664), f1 (weighted): 59.04, loss: 1.25e+00\n",
      "  time: 3803s (wall 7390s)\n",
      "step 169500 / 188418 (epoch 44.98 / 50):\n",
      "  learning_rate = 4.85e-05, loss_average = 1.19e+00\n",
      "  validation accuracy: 59.07 (31697 / 53664), f1 (weighted): 59.08, loss: 1.25e+00\n",
      "  time: 3837s (wall 7456s)\n",
      "step 171000 / 188418 (epoch 45.38 / 50):\n",
      "  learning_rate = 4.36e-05, loss_average = 1.19e+00\n",
      "  validation accuracy: 59.07 (31698 / 53664), f1 (weighted): 59.09, loss: 1.25e+00\n",
      "  time: 3870s (wall 7522s)\n",
      "step 172500 / 188418 (epoch 45.78 / 50):\n",
      "  learning_rate = 4.36e-05, loss_average = 1.18e+00\n",
      "  validation accuracy: 59.02 (31674 / 53664), f1 (weighted): 59.04, loss: 1.25e+00\n",
      "  time: 3904s (wall 7588s)\n",
      "step 174000 / 188418 (epoch 46.17 / 50):\n",
      "  learning_rate = 3.93e-05, loss_average = 1.14e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  validation accuracy: 59.03 (31677 / 53664), f1 (weighted): 59.05, loss: 1.25e+00\n",
      "  time: 3938s (wall 7654s)\n",
      "step 175500 / 188418 (epoch 46.57 / 50):\n",
      "  learning_rate = 3.93e-05, loss_average = 1.17e+00\n",
      "  validation accuracy: 59.09 (31711 / 53664), f1 (weighted): 59.12, loss: 1.25e+00\n",
      "  time: 3972s (wall 7720s)\n",
      "step 177000 / 188418 (epoch 46.97 / 50):\n",
      "  learning_rate = 3.93e-05, loss_average = 1.20e+00\n",
      "  validation accuracy: 59.11 (31719 / 53664), f1 (weighted): 59.12, loss: 1.25e+00\n",
      "  time: 4006s (wall 7786s)\n",
      "step 178500 / 188418 (epoch 47.37 / 50):\n",
      "  learning_rate = 3.53e-05, loss_average = 1.18e+00\n",
      "  validation accuracy: 59.12 (31724 / 53664), f1 (weighted): 59.14, loss: 1.25e+00\n",
      "  time: 4040s (wall 7851s)\n",
      "step 180000 / 188418 (epoch 47.77 / 50):\n",
      "  learning_rate = 3.53e-05, loss_average = 1.17e+00\n",
      "  validation accuracy: 59.13 (31730 / 53664), f1 (weighted): 59.14, loss: 1.25e+00\n",
      "  time: 4073s (wall 7917s)\n",
      "step 181500 / 188418 (epoch 48.16 / 50):\n",
      "  learning_rate = 3.18e-05, loss_average = 1.18e+00\n",
      "  validation accuracy: 59.09 (31711 / 53664), f1 (weighted): 59.10, loss: 1.25e+00\n",
      "  time: 4107s (wall 7983s)\n",
      "step 183000 / 188418 (epoch 48.56 / 50):\n",
      "  learning_rate = 3.18e-05, loss_average = 1.20e+00\n",
      "  validation accuracy: 59.10 (31713 / 53664), f1 (weighted): 59.11, loss: 1.25e+00\n",
      "  time: 4141s (wall 8049s)\n",
      "step 184500 / 188418 (epoch 48.96 / 50):\n",
      "  learning_rate = 3.18e-05, loss_average = 1.15e+00\n",
      "  validation accuracy: 59.03 (31679 / 53664), f1 (weighted): 59.04, loss: 1.25e+00\n",
      "  time: 4175s (wall 8115s)\n",
      "step 186000 / 188418 (epoch 49.36 / 50):\n",
      "  learning_rate = 2.86e-05, loss_average = 1.19e+00\n",
      "  validation accuracy: 59.14 (31736 / 53664), f1 (weighted): 59.16, loss: 1.25e+00\n",
      "  time: 4209s (wall 8181s)\n",
      "step 187500 / 188418 (epoch 49.76 / 50):\n",
      "  learning_rate = 2.86e-05, loss_average = 1.17e+00\n",
      "  validation accuracy: 59.07 (31697 / 53664), f1 (weighted): 59.10, loss: 1.25e+00\n",
      "  time: 4243s (wall 8247s)\n",
      "step 188418 / 188418 (epoch 50.00 / 50):\n",
      "  learning_rate = 2.86e-05, loss_average = 1.19e+00\n",
      "  validation accuracy: 59.14 (31737 / 53664), f1 (weighted): 59.16, loss: 1.25e+00\n",
      "  time: 4266s (wall 8292s)\n",
      "validation accuracy: peak = 59.14, mean = 59.10\n",
      "step 1500 / 188418 (epoch 0.40 / 50):\n",
      "  learning_rate = 5.00e-03, loss_average = 2.15e+00\n",
      "  validation accuracy: 43.58 (23386 / 53664), f1 (weighted): 43.52, loss: 2.07e+00\n",
      "  time: 39s (wall 71s)\n",
      "step 3000 / 188418 (epoch 0.80 / 50):\n",
      "  learning_rate = 5.00e-03, loss_average = 1.95e+00\n",
      "  validation accuracy: 47.15 (25305 / 53664), f1 (weighted): 46.86, loss: 1.91e+00\n",
      "  time: 74s (wall 138s)\n",
      "step 4500 / 188418 (epoch 1.19 / 50):\n",
      "  learning_rate = 4.50e-03, loss_average = 1.87e+00\n",
      "  validation accuracy: 49.83 (26742 / 53664), f1 (weighted): 49.88, loss: 1.82e+00\n",
      "  time: 108s (wall 205s)\n",
      "step 6000 / 188418 (epoch 1.59 / 50):\n",
      "  learning_rate = 4.50e-03, loss_average = 1.75e+00\n",
      "  validation accuracy: 51.00 (27367 / 53664), f1 (weighted): 51.10, loss: 1.75e+00\n",
      "  time: 142s (wall 271s)\n",
      "step 7500 / 188418 (epoch 1.99 / 50):\n",
      "  learning_rate = 4.50e-03, loss_average = 1.72e+00\n",
      "  validation accuracy: 51.79 (27794 / 53664), f1 (weighted): 51.90, loss: 1.70e+00\n",
      "  time: 176s (wall 337s)\n",
      "step 9000 / 188418 (epoch 2.39 / 50):\n",
      "  learning_rate = 4.05e-03, loss_average = 1.74e+00\n",
      "  validation accuracy: 52.22 (28022 / 53664), f1 (weighted): 52.14, loss: 1.67e+00\n",
      "  time: 210s (wall 403s)\n",
      "step 10500 / 188418 (epoch 2.79 / 50):\n",
      "  learning_rate = 4.05e-03, loss_average = 1.67e+00\n",
      "  validation accuracy: 53.07 (28480 / 53664), f1 (weighted): 53.15, loss: 1.63e+00\n",
      "  time: 244s (wall 469s)\n",
      "step 12000 / 188418 (epoch 3.18 / 50):\n",
      "  learning_rate = 3.64e-03, loss_average = 1.61e+00\n",
      "  validation accuracy: 53.47 (28693 / 53664), f1 (weighted): 53.48, loss: 1.61e+00\n",
      "  time: 277s (wall 535s)\n",
      "step 13500 / 188418 (epoch 3.58 / 50):\n",
      "  learning_rate = 3.64e-03, loss_average = 1.59e+00\n",
      "  validation accuracy: 54.02 (28991 / 53664), f1 (weighted): 54.08, loss: 1.57e+00\n",
      "  time: 311s (wall 601s)\n",
      "step 15000 / 188418 (epoch 3.98 / 50):\n",
      "  learning_rate = 3.64e-03, loss_average = 1.60e+00\n",
      "  validation accuracy: 54.53 (29262 / 53664), f1 (weighted): 54.55, loss: 1.54e+00\n",
      "  time: 345s (wall 667s)\n",
      "step 16500 / 188418 (epoch 4.38 / 50):\n",
      "  learning_rate = 3.28e-03, loss_average = 1.48e+00\n",
      "  validation accuracy: 54.85 (29435 / 53664), f1 (weighted): 54.89, loss: 1.52e+00\n",
      "  time: 379s (wall 733s)\n",
      "step 18000 / 188418 (epoch 4.78 / 50):\n",
      "  learning_rate = 3.28e-03, loss_average = 1.50e+00\n",
      "  validation accuracy: 55.03 (29531 / 53664), f1 (weighted): 55.04, loss: 1.50e+00\n",
      "  time: 413s (wall 799s)\n",
      "step 19500 / 188418 (epoch 5.17 / 50):\n",
      "  learning_rate = 2.95e-03, loss_average = 1.52e+00\n",
      "  validation accuracy: 54.98 (29502 / 53664), f1 (weighted): 54.95, loss: 1.49e+00\n",
      "  time: 447s (wall 865s)\n",
      "step 21000 / 188418 (epoch 5.57 / 50):\n",
      "  learning_rate = 2.95e-03, loss_average = 1.46e+00\n",
      "  validation accuracy: 55.70 (29893 / 53664), f1 (weighted): 55.76, loss: 1.46e+00\n",
      "  time: 481s (wall 931s)\n",
      "step 22500 / 188418 (epoch 5.97 / 50):\n",
      "  learning_rate = 2.95e-03, loss_average = 1.42e+00\n",
      "  validation accuracy: 55.97 (30036 / 53664), f1 (weighted): 56.06, loss: 1.45e+00\n",
      "  time: 514s (wall 997s)\n",
      "step 24000 / 188418 (epoch 6.37 / 50):\n",
      "  learning_rate = 2.66e-03, loss_average = 1.45e+00\n",
      "  validation accuracy: 56.29 (30207 / 53664), f1 (weighted): 56.33, loss: 1.44e+00\n",
      "  time: 548s (wall 1063s)\n",
      "step 25500 / 188418 (epoch 6.77 / 50):\n",
      "  learning_rate = 2.66e-03, loss_average = 1.42e+00\n",
      "  validation accuracy: 56.28 (30202 / 53664), f1 (weighted): 56.33, loss: 1.43e+00\n",
      "  time: 582s (wall 1129s)\n",
      "step 27000 / 188418 (epoch 7.16 / 50):\n",
      "  learning_rate = 2.39e-03, loss_average = 1.40e+00\n",
      "  validation accuracy: 56.53 (30338 / 53664), f1 (weighted): 56.53, loss: 1.41e+00\n",
      "  time: 616s (wall 1195s)\n",
      "step 28500 / 188418 (epoch 7.56 / 50):\n",
      "  learning_rate = 2.39e-03, loss_average = 1.41e+00\n",
      "  validation accuracy: 56.76 (30459 / 53664), f1 (weighted): 56.80, loss: 1.40e+00\n",
      "  time: 650s (wall 1261s)\n",
      "step 30000 / 188418 (epoch 7.96 / 50):\n",
      "  learning_rate = 2.39e-03, loss_average = 1.36e+00\n",
      "  validation accuracy: 56.93 (30550 / 53664), f1 (weighted): 56.94, loss: 1.39e+00\n",
      "  time: 684s (wall 1327s)\n",
      "step 31500 / 188418 (epoch 8.36 / 50):\n",
      "  learning_rate = 2.15e-03, loss_average = 1.37e+00\n",
      "  validation accuracy: 57.08 (30631 / 53664), f1 (weighted): 57.15, loss: 1.38e+00\n",
      "  time: 718s (wall 1393s)\n",
      "step 33000 / 188418 (epoch 8.76 / 50):\n",
      "  learning_rate = 2.15e-03, loss_average = 1.33e+00\n",
      "  validation accuracy: 57.28 (30737 / 53664), f1 (weighted): 57.31, loss: 1.37e+00\n",
      "  time: 752s (wall 1459s)\n",
      "step 34500 / 188418 (epoch 9.16 / 50):\n",
      "  learning_rate = 1.94e-03, loss_average = 1.31e+00\n",
      "  validation accuracy: 57.19 (30690 / 53664), f1 (weighted): 57.21, loss: 1.36e+00\n",
      "  time: 786s (wall 1525s)\n",
      "step 36000 / 188418 (epoch 9.55 / 50):\n",
      "  learning_rate = 1.94e-03, loss_average = 1.34e+00\n",
      "  validation accuracy: 57.36 (30779 / 53664), f1 (weighted): 57.42, loss: 1.36e+00\n",
      "  time: 819s (wall 1592s)\n",
      "step 37500 / 188418 (epoch 9.95 / 50):\n",
      "  learning_rate = 1.94e-03, loss_average = 1.33e+00\n",
      "  validation accuracy: 57.48 (30846 / 53664), f1 (weighted): 57.45, loss: 1.35e+00\n",
      "  time: 853s (wall 1658s)\n",
      "step 39000 / 188418 (epoch 10.35 / 50):\n",
      "  learning_rate = 1.74e-03, loss_average = 1.36e+00\n",
      "  validation accuracy: 57.47 (30843 / 53664), f1 (weighted): 57.45, loss: 1.35e+00\n",
      "  time: 887s (wall 1724s)\n",
      "step 40500 / 188418 (epoch 10.75 / 50):\n",
      "  learning_rate = 1.74e-03, loss_average = 1.33e+00\n",
      "  validation accuracy: 57.63 (30925 / 53664), f1 (weighted): 57.64, loss: 1.34e+00\n",
      "  time: 921s (wall 1790s)\n",
      "step 42000 / 188418 (epoch 11.15 / 50):\n",
      "  learning_rate = 1.57e-03, loss_average = 1.29e+00\n",
      "  validation accuracy: 57.44 (30827 / 53664), f1 (weighted): 57.45, loss: 1.33e+00\n",
      "  time: 955s (wall 1856s)\n",
      "step 43500 / 188418 (epoch 11.54 / 50):\n",
      "  learning_rate = 1.57e-03, loss_average = 1.30e+00\n",
      "  validation accuracy: 57.81 (31025 / 53664), f1 (weighted): 57.90, loss: 1.33e+00\n",
      "  time: 988s (wall 1922s)\n",
      "step 45000 / 188418 (epoch 11.94 / 50):\n",
      "  learning_rate = 1.57e-03, loss_average = 1.30e+00\n",
      "  validation accuracy: 57.87 (31057 / 53664), f1 (weighted): 57.93, loss: 1.32e+00\n",
      "  time: 1022s (wall 1988s)\n",
      "step 46500 / 188418 (epoch 12.34 / 50):\n",
      "  learning_rate = 1.41e-03, loss_average = 1.31e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  validation accuracy: 57.90 (31074 / 53664), f1 (weighted): 57.91, loss: 1.32e+00\n",
      "  time: 1056s (wall 2054s)\n",
      "step 48000 / 188418 (epoch 12.74 / 50):\n",
      "  learning_rate = 1.41e-03, loss_average = 1.29e+00\n",
      "  validation accuracy: 57.82 (31031 / 53664), f1 (weighted): 57.86, loss: 1.31e+00\n",
      "  time: 1090s (wall 2120s)\n",
      "step 49500 / 188418 (epoch 13.14 / 50):\n",
      "  learning_rate = 1.27e-03, loss_average = 1.26e+00\n",
      "  validation accuracy: 57.99 (31119 / 53664), f1 (weighted): 57.94, loss: 1.31e+00\n",
      "  time: 1124s (wall 2186s)\n"
     ]
    }
   ],
   "source": [
    "# Common hyper-parameters for LeNet5-like networks (two convolutional layers).\n",
    "common['regularization'] = 5e-4\n",
    "common['dropout']        = 0.5\n",
    "common['learning_rate']  = 0.005  # 0.03 in the paper but sgconv_sgconv_fc_softmax has difficulty to converge\n",
    "common['decay_rate']     = 0.9 ##0.95\n",
    "common['momentum']       = 0.9\n",
    "common['F']              = [32, 64, 128]  # Number of graph convolutional filters.\n",
    "common['K']              = [ 25,25,25]  # Polynomial orders.\n",
    "common['p']              = [4,4,4]    # Pooling sizes.\n",
    "common['M']              = [256, C]  # Output dimensionality of fully connected layers.\n",
    "\n",
    "##model#3: two convolutional layers with Chebyshev polynomial as filters\n",
    "name = 'cgconv_cgconv_fc_softmax' #  'Non-Param'\n",
    "params = common.copy()\n",
    "params['dir_name'] += name\n",
    "params['filter'] = 'chebyshev5'\n",
    "print(params)    \n",
    "print([L[li].shape for li in range(len(L))])\n",
    "model = models.cgcnn(L, **params)\n",
    "    \n",
    "d = {k: v+1 for v, k in enumerate(sorted(set(Y_test)))}\n",
    "test_labels = np.array([d[x] for x in Y_test])\n",
    "print(np.unique(Y_test))\n",
    "\n",
    "train_acc = []; train_loss = [];\n",
    "test_acc = []; test_loss = [];\n",
    "val_acc = []; val_loss = [];\n",
    "accuracy = []; loss = []; t_step = [];\n",
    "for x_train, y_train, x_val, y_val,tcount in zip(X_train, Y_train, X_val, Y_val,range(2)):\n",
    "    \n",
    "    train_data = coarsening.perm_data(x_train.reshape(-1,Region_Num), perm)\n",
    "    train_labels = np.array([d[x] for x in y_train])\n",
    "    val_data = coarsening.perm_data(x_val.reshape(-1,Region_Num), perm)\n",
    "    val_labels = np.array([d[x] for x in y_val])\n",
    "    test_data = coarsening.perm_data(X_test.reshape(-1,Region_Num), perm)\n",
    "    print('\\nFold #%d: training on %d samples with %d features, validating on %d samples and testing on %d samples' % \n",
    "          (tcount+1,train_data.shape[0],train_data.shape[1],val_data.shape[0],test_data.shape[0]))  \n",
    "    \n",
    "    ###training\n",
    "    acc, los, tstep = model.fit(train_data, train_labels, val_data, val_labels)\n",
    "    accuracy.append(acc)\n",
    "    loss.append(los)\n",
    "    t_step.append(tstep)\n",
    "\n",
    "    ##evaluation\n",
    "    model_perf.test(model, name, params,\n",
    "                    train_data, train_labels, val_data, val_labels, test_data, test_labels)\n",
    "    train_acc.append(model_perf.train_accuracy[name])\n",
    "    train_loss.append(model_perf.train_loss[name])\n",
    "    test_acc.append(model_perf.test_accuracy[name])\n",
    "    test_loss.append(model_perf.test_loss[name])\n",
    "    val_acc.append(model_perf.fit_accuracies[name])\n",
    "    val_loss.append(model_perf.fit_losses[name])\n",
    "    print('\\n')\n",
    "       \n",
    "print('Accuracy of training:{},testing:{}'.format(np.mean(train_acc),np.mean(test_acc)))\n",
    "print('Accuracy of validation:',np.max(val_acc,axis=1))\n",
    "print(' mean=%2f' % np.mean(np.max(val_acc,axis=1)))\n",
    "\n",
    "###training figures\n",
    "print(accuracy, loss,t_step )\n",
    "fig, ax1 = plt.subplots(figsize=(10, 5))\n",
    "ax1.plot(np.mean(accuracy,axis=0), 'b.-')\n",
    "ax1.set_ylabel('validation accuracy', color='b')\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(np.mean(loss,axis=0), 'g.-')\n",
    "ax2.set_ylabel('training loss', color='g')\n",
    "plt.show()\n",
    "\n",
    "###summarize the results\n",
    "model_perf.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
